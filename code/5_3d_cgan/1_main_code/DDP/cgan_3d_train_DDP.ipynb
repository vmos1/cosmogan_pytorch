{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing cosmogan\n",
    "Aug 25, 2020\n",
    "\n",
    "Borrowing pieces of code from : \n",
    "\n",
    "- https://github.com/pytorch/tutorials/blob/11569e0db3599ac214b03e01956c2971b02c64ce/beginner_source/dcgan_faces_tutorial.py\n",
    "- https://github.com/exalearn/epiCorvid/tree/master/cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "#from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "# import torch.fft\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections\n",
    "import socket\n",
    "import shutil\n",
    "\n",
    "# # Import modules from other files\n",
    "# from utils import *\n",
    "# from spec_loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mod for 3D\n",
    "def f_get_model(model_name,gdict):\n",
    "    ''' Module to define Generator and Discriminator'''\n",
    "#     print(\"Model name\",model_name)\n",
    "    \n",
    "    if model_name==2: #### Concatenate sigma input\n",
    "        class Generator(nn.Module):\n",
    "            def __init__(self, gdict):\n",
    "                super(Generator, self).__init__()\n",
    "\n",
    "                ## Define new variables from dict\n",
    "                keys=['ngpu','nz','nc','ngf','kernel_size','stride','g_padding']\n",
    "                ngpu, nz,nc,ngf,kernel_size,stride,g_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "\n",
    "                self.main = nn.Sequential(\n",
    "                    # nn.ConvTranspose3d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "                    nn.Linear(nz+1,nc*ngf*8**3),# 262144 \n",
    "                    nn.BatchNorm3d(nc,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    View(shape=[-1,ngf*8,4,4,4]),\n",
    "                    nn.ConvTranspose3d(ngf * 8, ngf * 4, kernel_size, stride, g_padding, output_padding=1, bias=False),\n",
    "                    nn.BatchNorm3d(ngf*4,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    # state size. (ngf*4) x 8 x 8\n",
    "                    nn.ConvTranspose3d( ngf * 4, ngf * 2, kernel_size, stride, g_padding, 1, bias=False),\n",
    "                    nn.BatchNorm3d(ngf*2,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    # state size. (ngf*2) x 16 x 16\n",
    "                    nn.ConvTranspose3d( ngf * 2, ngf, kernel_size, stride, g_padding, 1, bias=False),\n",
    "                    nn.BatchNorm3d(ngf,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    # state size. (ngf) x 32 x 32\n",
    "                    nn.ConvTranspose3d( ngf, nc, kernel_size, stride,g_padding, 1, bias=False),\n",
    "                    nn.Tanh()\n",
    "                )\n",
    "\n",
    "            def forward(self, noise,labels):\n",
    "                x=labels.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).float()\n",
    "                gen_input=torch.cat((noise,x),-1)\n",
    "                img=self.main(gen_input)\n",
    "\n",
    "                return img\n",
    "\n",
    "        class Discriminator(nn.Module):\n",
    "            def __init__(self, gdict):\n",
    "                super(Discriminator, self).__init__()\n",
    "\n",
    "                ## Define new variables from dict\n",
    "                keys=['ngpu','nz','nc','ndf','kernel_size','stride','d_padding']\n",
    "                ngpu, nz,nc,ndf,kernel_size,stride,d_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "\n",
    "                self.linear_transf=nn.Linear(4,4)\n",
    "                self.main = nn.Sequential(\n",
    "                    # input is (nc) x 64 x 64\n",
    "                    # nn.Conv3d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "                    nn.Conv3d(nc+1, ndf,kernel_size, stride, d_padding,  bias=True),\n",
    "                    nn.BatchNorm3d(ndf,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf) x 32 x 32\n",
    "                    nn.Conv3d(ndf, ndf * 2, kernel_size, stride, d_padding, bias=True),\n",
    "                    nn.BatchNorm3d(ndf * 2,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf*2) x 16 x 16\n",
    "                    nn.Conv3d(ndf * 2, ndf * 4, kernel_size, stride, d_padding, bias=True),\n",
    "                    nn.BatchNorm3d(ndf * 4,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf*4) x 8 x 8\n",
    "                    nn.Conv3d(ndf * 4, ndf * 8, kernel_size, stride, d_padding, bias=True),\n",
    "                    nn.BatchNorm3d(ndf * 8,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf*8) x 4 x 4\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(nc*ndf*8*8*8, 1)\n",
    "        #             nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "            def forward(self, img,labels):\n",
    "                img_size=gdict['image_size']\n",
    "                x=labels.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).repeat(1,1,1,1,4).float() # get to size (batch,1,1,1,4)\n",
    "                x=self.linear_transf(x)\n",
    "                x=torch.repeat_interleave(x,int((img_size*img_size*img_size)/4)) # get to size (batch* img^3)\n",
    "                x=x.view(labels.size(0),1,img_size,img_size,img_size) ## Get to size (batch,1,img,img,img)\n",
    "                \n",
    "                ip=torch.cat((img,x),axis=1)\n",
    "                \n",
    "                results=[ip]\n",
    "                lst_idx=[]\n",
    "                for i,submodel in enumerate(self.main.children()):\n",
    "                    mid_output=submodel(results[-1])\n",
    "                    results.append(mid_output)\n",
    "                    ## Select indices in list corresponding to output of Conv layers\n",
    "                    if submodel.__class__.__name__.startswith('Conv'):\n",
    "        #                 print(submodel.__class__.__name__)\n",
    "        #                 print(mid_output.shape)\n",
    "                        lst_idx.append(i)\n",
    "\n",
    "                FMloss=True\n",
    "                if FMloss:\n",
    "                    ans=[results[1:][i] for i in lst_idx + [-1]]\n",
    "                else :\n",
    "                    ans=results[-1]\n",
    "                \n",
    "                return ans                \n",
    "                \n",
    "\n",
    "    elif model_name==3:#### Model 3: with ConditionalInstanceNorm2d,\n",
    "        class ConditionalInstanceNorm2d(nn.Module):\n",
    "            def __init__(self, num_features, num_params):\n",
    "                super().__init__()\n",
    "                self.num_features = num_features\n",
    "                self.InstNorm = nn.InstanceNorm2d(num_features, affine=False)\n",
    "                self.affine = nn.Linear(num_params, num_features * 2)\n",
    "                self.affine.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
    "                self.affine.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
    "\n",
    "            def forward(self, x, y):\n",
    "                out = self.InstNorm(x)\n",
    "                gamma, beta = self.affine(y).chunk(2, 1)\n",
    "                out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
    "                return out\n",
    "\n",
    "        class ConditionalSequential(nn.Sequential):\n",
    "            def __init__(self,*args):\n",
    "                super(ConditionalSequential, self).__init__(*args)\n",
    "\n",
    "            def forward(self, inputs, labels):\n",
    "                for module in self:\n",
    "                    if module.__class__ is ConditionalInstanceNorm2d:\n",
    "                        inputs = module(inputs, labels.float())\n",
    "                    else:\n",
    "                        inputs = module(inputs)\n",
    "\n",
    "                return inputs\n",
    "\n",
    "        class Generator(nn.Module):\n",
    "            def __init__(self, gdict):\n",
    "                super(Generator, self).__init__()\n",
    "\n",
    "                ## Define new variables from dict\n",
    "                keys=['ngpu','nz','nc','ngf','kernel_size','stride','g_padding']\n",
    "                ngpu, nz,nc,ngf,kernel_size,stride,g_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "\n",
    "                self.main = ConditionalSequential(\n",
    "                    # nn.ConvTranspose3d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "                    nn.Linear(nz,nc*ngf*8**3),# 262144\n",
    "                    nn.BatchNorm3d(nc,eps=1e-05, momentum=0.9, affine=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    View(shape=[-1,ngf*8,4,4,4]),\n",
    "                    nn.ConvTranspose3d(ngf * 8, ngf * 4, kernel_size, stride, g_padding, output_padding=1, bias=False),\n",
    "                    ConditionalInstanceNorm2d(ngf*4,1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    # state size. (ngf*4) x 8 x 8\n",
    "                    nn.ConvTranspose3d( ngf * 4, ngf * 2, kernel_size, stride, g_padding, 1, bias=False),\n",
    "                    ConditionalInstanceNorm2d(ngf*2,1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    # state size. (ngf*2) x 16 x 16\n",
    "                    nn.ConvTranspose3d( ngf * 2, ngf, kernel_size, stride, g_padding, 1, bias=False),\n",
    "                    ConditionalInstanceNorm2d(ngf,1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    # state size. (ngf) x 32 x 32\n",
    "                    nn.ConvTranspose3d( ngf, nc, kernel_size, stride,g_padding, 1, bias=False),\n",
    "                    nn.Tanh()\n",
    "                )\n",
    "                \n",
    "                \n",
    "            def forward(self, noise,labels):\n",
    "                img=self.main(noise,labels)\n",
    "\n",
    "                return img\n",
    "\n",
    "        class Discriminator(nn.Module):\n",
    "            def __init__(self, gdict):\n",
    "                super(Discriminator, self).__init__()\n",
    "\n",
    "                ## Define new variables from dict\n",
    "                keys=['ngpu','nz','nc','ndf','kernel_size','stride','d_padding']\n",
    "                ngpu, nz,nc,ndf,kernel_size,stride,d_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "                \n",
    "                self.main = nn.Sequential(\n",
    "                    # input is (nc) x 64 x 64\n",
    "                    # nn.Conv3d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "                    nn.Conv3d(nc, ndf,kernel_size, stride, d_padding,  bias=True),\n",
    "                    ConditionalInstanceNorm2d(ndf,1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf) x 32 x 32\n",
    "                    nn.Conv3d(ndf, ndf * 2, kernel_size, stride, d_padding, bias=True),\n",
    "                    ConditionalInstanceNorm2d(ndf*2,1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf*2) x 16 x 16\n",
    "                    nn.Conv3d(ndf * 2, ndf * 4, kernel_size, stride, d_padding, bias=True),\n",
    "                    ConditionalInstanceNorm2d(ndf*4,1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf*4) x 8 x 8\n",
    "                    nn.Conv3d(ndf * 4, ndf * 8, kernel_size, stride, d_padding, bias=True),\n",
    "                    ConditionalInstanceNorm2d(ndf*8,1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    # state size. (ndf*8) x 4 x 4\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(nc*ndf*8*8*8, 1)\n",
    "        #             nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "            def forward(self, ip,labels):   \n",
    "                results=[ip]\n",
    "                lst_idx=[]\n",
    "                for i,submodel in enumerate(self.main.children()):\n",
    "                    mid_output=submodel(results[-1])\n",
    "                    results.append(mid_output)\n",
    "                    ## Select indices in list corresponding to output of Conv layers\n",
    "                    if submodel.__class__.__name__.startswith('Conv'):\n",
    "        #                 print(submodel.__class__.__name__)\n",
    "        #                 print(mid_output.shape)\n",
    "                        lst_idx.append(i)\n",
    "\n",
    "                FMloss=True\n",
    "                if FMloss:\n",
    "                    ans=[results[1:][i] for i in lst_idx + [-1]]\n",
    "                else :\n",
    "                    ans=results[-1]\n",
    "                return ans\n",
    "\n",
    "    return Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4.) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s)\n",
    "\n",
    "        \n",
    "# Generator Code\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "def f_gen_images(gdict,netG,optimizerG,sigma,ip_fname,op_loc,op_strg='inf_img_',op_size=500):\n",
    "    '''Generate images for best saved models\n",
    "     Arguments: gdict, netG, optimizerG, sigma (parameter value),\n",
    "                 ip_fname: name of input file\n",
    "                op_strg: [string name for output file]\n",
    "                op_size: Number of images to generate\n",
    "    '''\n",
    "\n",
    "    nz,device=gdict['nz'],gdict['device']\n",
    "\n",
    "    try:# handling cpu vs gpu\n",
    "        if torch.cuda.is_available(): checkpoint=torch.load(ip_fname)\n",
    "        else: checkpoint=torch.load(ip_fname,map_location=torch.device('cpu'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        return\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "    \n",
    "    ## Load other stuff\n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(op_size, 1, 1, 1, nz, device=device) ## Mod for 3D\n",
    "    tnsr_cosm_params=(torch.ones(op_size,device=device)*sigma).view(op_size,1)\n",
    "    \n",
    "    # Generate fake image batch with G\n",
    "    netG.eval() ## This is required before running inference\n",
    "    with torch.no_grad(): ## This is important. fails without it for multi-gpu\n",
    "        gen = netG(noise,tnsr_cosm_params)\n",
    "        gen_images=gen.detach().cpu().numpy()\n",
    "        print(gen_images.shape)\n",
    "    \n",
    "    op_fname='%s_epoch-%s_step-%s.npy'%(op_strg,epoch,iters)\n",
    "    np.save(op_loc+op_fname,gen_images)\n",
    "\n",
    "    print(\"Image saved in \",op_fname)\n",
    "    \n",
    "def f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,netG,netD,optimizerG,optimizerD,save_loc):\n",
    "    ''' Checkpoint model '''\n",
    "    \n",
    "    if gdict['multi-gpu']: ## Dataparallel\n",
    "        torch.save({'epoch':epoch,'iters':iters,'best_chi1':best_chi1,'best_chi2':best_chi2,\n",
    "                'G_state':netG.module.state_dict(),'D_state':netD.module.state_dict(),'optimizerG_state_dict':optimizerG.state_dict(),\n",
    "                'optimizerD_state_dict':optimizerD.state_dict()}, save_loc) \n",
    "    else :\n",
    "        torch.save({'epoch':epoch,'iters':iters,'best_chi1':best_chi1,'best_chi2':best_chi2,\n",
    "                'G_state':netG.state_dict(),'D_state':netD.state_dict(),'optimizerG_state_dict':optimizerG.state_dict(),\n",
    "                'optimizerD_state_dict':optimizerD.state_dict()}, save_loc)\n",
    "    \n",
    "def f_load_checkpoint(ip_fname,netG,netD,optimizerG,optimizerD,gdict):\n",
    "    ''' Load saved checkpoint\n",
    "    Also loads step, epoch, best_chi1, best_chi2'''\n",
    "    \n",
    "    print(\"torch device\",torch.device('cuda',torch.cuda.current_device()))\n",
    "\n",
    "    try:\n",
    "        checkpoint=torch.load(ip_fname,map_location=torch.device('cuda',torch.cuda.current_device()))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        raise SystemError\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "        netD.module.load_state_dict(checkpoint['D_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "        netD.load_state_dict(checkpoint['D_state'])\n",
    "    \n",
    "    optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    best_chi1=checkpoint['best_chi1']\n",
    "    best_chi2=checkpoint['best_chi2']\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    \n",
    "    return iters,epoch,best_chi1,best_chi2,netD,optimizerD,netG,optimizerG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### Pytorch code ###\n",
    "####################\n",
    "\n",
    "## Mod for 3D\n",
    "\n",
    "def f_get_rad(img):\n",
    "    ''' Get the radial tensor for use in f_torch_get_azimuthalAverage '''\n",
    "    \n",
    "    height,width,depth=img.shape[-3:]\n",
    "    # Create a grid of points with x and y and z coordinates\n",
    "    z,y,x = np.indices([height,width,depth])\n",
    "    \n",
    "    center=[]\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0, (z.max()-z.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r= torch.tensor(np.sqrt((x-center[0])**2 + (y-center[1])**2 + (z-center[2])**2))\n",
    "        \n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "\n",
    "    return r.detach(),ind.detach()\n",
    "\n",
    "def f_torch_get_azimuthalAverage(image,r,ind):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 3D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "#     height,width,depth=img.shape[-3:]\n",
    "#     # Create a grid of points with x and y coordinates\n",
    "#     z,y,x = np.indices([height,width,depth])\n",
    "    \n",
    "#     center=[]\n",
    "#     if not center:\n",
    "#         center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0, (z.max()-z.min())/2.0])\n",
    "\n",
    "#     # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "#     r= torch.tensor(np.sqrt((x-center[0])**2 + (y-center[1])**2 + (z-center[2])**2))\n",
    "        \n",
    "#     # Get sorted radii\n",
    "#     ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "\n",
    "    r_sorted = torch.gather(torch.reshape(r, ( -1,)),0, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, ( -1,)),0, ind)\n",
    "    \n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[0], (-1,))    # location of changes in radius\n",
    "    nr = (rind[1:] - rind[:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    \n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    tbin = torch.gather(csum, 0, rind[1:]) - torch.gather(csum, 0, rind[:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "def f_torch_fftshift(real, imag):\n",
    "    for dim in range(0, len(real.size())):\n",
    "        real = torch.roll(real, dims=dim, shifts=real.size(dim)//2)\n",
    "        imag = torch.roll(imag, dims=dim, shifts=imag.size(dim)//2)\n",
    "    return real, imag\n",
    "\n",
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    \n",
    "    y1=torch.rfft(arr,signal_ndim=3,onesided=False)\n",
    "    real,imag=f_torch_fftshift(y1[:,:,:,0],y1[:,:,:,1])    ## last index is real/imag part  ## Mod for 3D\n",
    "    \n",
    "#     # For pytorch 1.8\n",
    "#     y1=torch.fft.fftn(arr,dim=(-3,-2,-1))\n",
    "#     real,imag=f_torch_fftshift(y1.real,y1.imag)    \n",
    "    \n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    return z1\n",
    "\n",
    "\n",
    "def f_torch_compute_batch_spectrum(arr,r,ind):\n",
    "    \n",
    "    batch_pk=torch.stack([f_torch_compute_spectrum(i,r,ind) for i in arr])\n",
    "    \n",
    "    return batch_pk\n",
    "\n",
    "def f_torch_image_spectrum(x,num_channels,r,ind):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    var=[[] for i in range(num_channels)] \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:,:] # Mod for 3D\n",
    "        batch_pk=f_torch_compute_batch_spectrum(arr,r,ind)\n",
    "        mean[i]=torch.mean(batch_pk,axis=0)\n",
    "#         var[i]=torch.std(batch_pk,axis=0)/np.sqrt(batch_pk.shape[0])\n",
    "#         var[i]=torch.std(batch_pk,axis=0)\n",
    "        var[i]=torch.var(batch_pk,axis=0)\n",
    "    \n",
    "    mean=torch.stack(mean)\n",
    "    var=torch.stack(var)\n",
    "        \n",
    "    if (torch.isnan(mean).any() or torch.isnan(var).any()):\n",
    "        print(\"Nans in spectrum\",mean,var)\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"Nans in Input image\")\n",
    "\n",
    "    return mean,var\n",
    "\n",
    "def f_compute_hist(data,bins):\n",
    "    \n",
    "    try: \n",
    "        hist_data=torch.histc(data,bins=bins)\n",
    "        ## A kind of normalization of histograms: divide by total sum\n",
    "        hist_data=(hist_data*bins)/torch.sum(hist_data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        hist_data=torch.zeros(bins)\n",
    "\n",
    "    return hist_data\n",
    "\n",
    "### Losses \n",
    "def loss_spectrum(spec_mean,spec_mean_ref,spec_var,spec_var_ref,image_size,lambda_spec_mean,lambda_spec_var):\n",
    "    ''' Loss function for the spectrum : mean + variance \n",
    "    Log(sum( batch value - expect value) ^ 2 )) '''\n",
    "    \n",
    "    if (torch.isnan(spec_mean).any() or torch.isnan(spec_var).any()):\n",
    "        ans=torch.tensor(float(\"inf\"))\n",
    "        return ans\n",
    "    \n",
    "    idx=int(image_size/2) ### For the spectrum, use only N/2 indices for loss calc.\n",
    "    ### Warning: the first index is the channel number.For multiple channels, you are averaging over them, which is fine.\n",
    "        \n",
    "    loss_mean=torch.log(torch.mean(torch.pow(spec_mean[:,:idx]-spec_mean_ref[:,:idx],2)))\n",
    "    loss_var=torch.log(torch.mean(torch.pow(spec_var[:,:idx]-spec_var_ref[:,:idx],2)))\n",
    "    \n",
    "    ans=lambda_spec_mean*loss_mean+lambda_spec_var*loss_var\n",
    "    \n",
    "    if (torch.isnan(ans).any()) :    \n",
    "        print(\"loss spec mean %s, loss spec var %s\"%(loss_mean,loss_var))\n",
    "        print(\"spec mean %s, ref %s\"%(spec_mean, spec_mean_ref))\n",
    "        print(\"spec var %s, ref %s\"%(spec_var, spec_var_ref))\n",
    "#         raise SystemExit\n",
    "        \n",
    "    return ans\n",
    "    \n",
    "def loss_hist(hist_sample,hist_ref):\n",
    "    \n",
    "    lambda1=1.0\n",
    "    return lambda1*torch.log(torch.mean(torch.pow(hist_sample-hist_ref,2)))\n",
    "\n",
    "def f_FM_loss(real_output,fake_output,lambda_fm,gdict):\n",
    "    '''\n",
    "    Module to implement Feature-Matching loss. Reads all but last elements of Discriminator ouput\n",
    "    '''\n",
    "    FM=torch.Tensor([0.0]).to(gdict['device'])\n",
    "    for i,j in zip(real_output[:-1],fake_output[:-1]):\n",
    "        real_mean=torch.mean(i)\n",
    "        fake_mean=torch.mean(j)\n",
    "        FM=FM.clone()+torch.sum(torch.square(real_mean-fake_mean))\n",
    "    return lambda_fm*FM\n",
    "\n",
    "def f_gp_loss(grads,l=1.0):\n",
    "    '''\n",
    "    Module to implement gradient penalty loss.\n",
    "    '''\n",
    "    loss=torch.mean(torch.sum(torch.square(grads),dim=[1,2,3]))\n",
    "    return l*loss\n",
    "\n",
    "def f_get_loss_cond(loss_type,img_tensor,cosm_params,gdict,bins=None,hist_val_tnsr=None,spec_mean_tnsr=None,spec_var_tnsr=None,r=None,ind=None,real_output=None,fake_output=None,grads=None):\n",
    "    ''' Module to compute one of the losses for conditional GAN '''\n",
    "    \n",
    "    loss_tensor=torch.zeros(len(gdict['sigma_list']),device=gdict['device'])\n",
    "    \n",
    "    for count,i in enumerate(gdict['sigma_list']):\n",
    "        idxs=torch.where(cosm_params==i)[0] ## Get indices for that category\n",
    "        if idxs.size(0)>1: \n",
    "            num_frac=idxs.size(0)/img_tensor.shape[0] ## Fraction of points in the category\n",
    "            img=img_tensor[idxs]\n",
    "            if loss_type=='hist':\n",
    "                loss_tensor[count]=loss_hist(f_compute_hist(img,bins),hist_val_tnsr[count])*num_frac\n",
    "            elif loss_type=='spec':\n",
    "                mean,var=f_torch_image_spectrum(f_invtransform(img),1,r,ind)\n",
    "                loss_tensor[count]=loss_spectrum(mean,spec_mean_tnsr[count],var,spec_var_tnsr[count],gdict['image_size'],gdict['lambda_spec_mean'],gdict['lambda_spec_var'])*num_frac\n",
    "            elif loss_type=='fm':\n",
    "                loss_tensor[count]=f_FM_loss(real_output,fake_output,gdict['lambda_fm'],gdict)\n",
    "            elif loss_type=='gp':\n",
    "                loss_tensor[count]=f_gp_loss(grads,gdict['lambda_gp'])\n",
    "\n",
    "    loss=loss_tensor.sum()\n",
    "            \n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########## Modules\n",
    "### Setup modules ###\n",
    "def f_manual_add_argparse():\n",
    "    ''' use only in jpt notebook'''\n",
    "    args=argparse.Namespace()\n",
    "    args.config='config_3d_Cgan.yaml'\n",
    "    args.mode='fresh'\n",
    "    args.local_rank=0\n",
    "    args.facility='cori'\n",
    "    args.distributed=False\n",
    "\n",
    "#     args.mode='continue'\n",
    "    \n",
    "    return args\n",
    "\n",
    "def f_parse_args():\n",
    "    \"\"\"Parse command line arguments.Only for .py file\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Run script to train GAN using pytorch\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    add_arg = parser.add_argument\n",
    "    \n",
    "    add_arg('--config','-cfile',  type=str, default='config_3d_Cgan.yaml', help='Name of config file')\n",
    "    add_arg('--mode','-m',  type=str, choices=['fresh','continue','fresh_load'],default='fresh', help='Whether to start fresh run or continue previous run or fresh run loading a config file.')\n",
    "    add_arg(\"--local_rank\", default=0, type=int,help='Local rank of GPU on node. Using for pytorch DDP. ')\n",
    "    add_arg(\"--facility\", default='cori', choices=['cori','summit'],type=str,help='Facility: cori or summit ')\n",
    "    add_arg(\"--ddp\", dest='distributed' ,default=False,action='store_true',help='use Distributed DataParallel for Pytorch or DataParallel')\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def try_barrier(rank):\n",
    "    \"\"\"\n",
    "    Used in Distributed data parallel\n",
    "    Attempt a barrier but ignore any exceptions\n",
    "    \"\"\"\n",
    "    print('BAR %d'%rank)\n",
    "    try:\n",
    "        dist.barrier()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def f_init_gdict(args,gdict):\n",
    "    ''' Create global dictionary gdict from args and config file'''\n",
    "    \n",
    "    ## read config file\n",
    "    config_file=args.config\n",
    "    with open(config_file) as f:\n",
    "        config_dict= yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        \n",
    "    gdict=config_dict['parameters']\n",
    "\n",
    "    args_dict=vars(args)\n",
    "    ## Add args variables to gdict\n",
    "    for key in args_dict.keys():\n",
    "        gdict[key]=args_dict[key]\n",
    "\n",
    "    if gdict['distributed']: \n",
    "        assert not gdict['lambda_gp'],\"GP couplings is %s. Cannot use Gradient penalty loss in pytorch DDP\"%(gdict['lambda_gp'])\n",
    "    else : print(\"Not using DDP\")\n",
    "    return gdict\n",
    "\n",
    "\n",
    "def f_get_img_samples(ip_arr,rank=0,num_ranks=1):\n",
    "    '''\n",
    "    Module to get part of the numpy image file\n",
    "    '''\n",
    "    \n",
    "    data_size=ip_arr.shape[0]\n",
    "    size=data_size//num_ranks\n",
    "    \n",
    "    if gdict['batch_size']>size:\n",
    "        print(\"Caution: batchsize %s is greater than samples per GPU %s\"%(gdict['batch_size'],size))\n",
    "        raise SystemExit\n",
    "        \n",
    "    ### Get a set of random indices from numpy array\n",
    "    random=False\n",
    "    if random:\n",
    "        idxs=np.arange(ip_arr.shape[0])\n",
    "        np.random.shuffle(idxs)\n",
    "        rnd_idxs=idxs[rank*(size):(rank+1)*size]\n",
    "        arr=ip_arr[rnd_idxs].copy()\n",
    "        \n",
    "    else: arr=ip_arr[rank*(size):(rank+1)*size].copy()\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def f_setup(gdict,metrics_df,log):\n",
    "    ''' \n",
    "    Set up directories, Initialize random seeds, add GPU info, add logging info.\n",
    "    '''\n",
    "    \n",
    "    torch.backends.cudnn.benchmark=True\n",
    "#     torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    ## New additions. Code taken from Jan B.\n",
    "    os.environ['MASTER_PORT'] = \"8885\"\n",
    "\n",
    "    if gdict['facility']=='summit':\n",
    "        get_master = \"echo $(cat {} | sort | uniq | grep -v batch | grep -v login | head -1)\".format(os.environ['LSB_DJOB_HOSTFILE'])\n",
    "        os.environ['MASTER_ADDR'] = str(subprocess.check_output(get_master, shell=True))[2:-3]\n",
    "        os.environ['WORLD_SIZE'] = os.environ['OMPI_COMM_WORLD_SIZE']\n",
    "        os.environ['RANK'] = os.environ['OMPI_COMM_WORLD_RANK']\n",
    "        gdict['local_rank'] = int(os.environ['OMPI_COMM_WORLD_LOCAL_RANK'])\n",
    "    else:\n",
    "        if gdict['distributed']:\n",
    "            os.environ['WORLD_SIZE'] = os.environ['SLURM_NTASKS']\n",
    "            os.environ['RANK'] = os.environ['SLURM_PROCID']\n",
    "            gdict['local_rank'] = int(os.environ['SLURM_LOCALID'])\n",
    "\n",
    "    ## Special declarations\n",
    "    gdict['ngpu']=torch.cuda.device_count()\n",
    "    gdict['device']=torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "    gdict['multi-gpu']=True if (gdict['device'].type == 'cuda') and (gdict['ngpu'] > 1) else False \n",
    "    \n",
    "    ########################\n",
    "    ###### Set up Distributed Data parallel ######\n",
    "    if gdict['distributed']:\n",
    "#         gdict['local_rank']=args.local_rank  ## This is needed when using pytorch -m torch.distributed.launch\n",
    "        gdict['world_size']=int(os.environ['WORLD_SIZE'])\n",
    "        torch.cuda.set_device(gdict['local_rank']) ## Very important\n",
    "        dist.init_process_group(backend='nccl', init_method=\"env://\")  \n",
    "        gdict['world_rank']= dist.get_rank()\n",
    "\n",
    "        print(\"World size %s, world rank %s, local rank %s device %s, hostname %s, GPUs on node %s\\n\"%(gdict['world_size'],gdict['world_rank'],gdict['local_rank'],device,socket.gethostname(),gdict['ngpu']))\n",
    "        device = torch.cuda.current_device()\n",
    "        \n",
    "        # Divide batch size by number of GPUs\n",
    "#         gdict['batch_size']=gdict['batch_size']//gdict['world_size']\n",
    "    else:\n",
    "        gdict['world_size'],gdict['world_rank'],gdict['local_rank']=1,0,0\n",
    "    \n",
    "    ########################\n",
    "    ###### Set up directories #######\n",
    "    ### sync up so that time is the same for each GPU for DDP\n",
    "    if gdict['mode'] in ['fresh','fresh_load']:\n",
    "        ### Create prefix for foldername      \n",
    "        if gdict['world_rank']==0: ### For rank=0, create directory name string and make directories\n",
    "            dt_strg=datetime.now().strftime('%Y%m%d_%H%M%S') ## time format\n",
    "            dt_lst=[int(i) for i in dt_strg.split('_')] # List storing day and time            \n",
    "            dt_tnsr=torch.LongTensor(dt_lst).to(gdict['device'])  ## Create list to pass to other GPUs \n",
    "\n",
    "        else: dt_tnsr=torch.Tensor([0,0]).long().to(gdict['device'])\n",
    "        ### Pass directory name to other ranks\n",
    "        if gdict['distributed']: dist.broadcast(dt_tnsr, src=0)\n",
    "\n",
    "        gdict['save_dir']=gdict['op_loc']+str(int(dt_tnsr[0]))+'_'+str(int(dt_tnsr[1]))+'_'+gdict['run_suffix']\n",
    "        \n",
    "        if gdict['world_rank']==0: # Create directories for rank 0\n",
    "            ### Create directories\n",
    "            if not os.path.exists(gdict['save_dir']):\n",
    "                os.makedirs(gdict['save_dir']+'/models')\n",
    "                os.makedirs(gdict['save_dir']+'/images')\n",
    "                shutil.copy(gdict['config'],gdict['save_dir'])    \n",
    "    \n",
    "    elif gdict['mode']=='continue': ## For checkpointed runs\n",
    "        gdict['save_dir']=gdict['ip_fldr']\n",
    "        ### Read loss data\n",
    "        metrics_df=pd.read_pickle(gdict['save_dir']+'/df_metrics.pkle').astype(np.float64)\n",
    "   \n",
    "    ########################\n",
    "    ### Initialize random seed\n",
    "    \n",
    "    manualSeed = np.random.randint(1, 10000) if gdict['seed']=='random' else int(gdict['seed'])\n",
    "#     print(\"Seed\",manualSeed,gdict['world_rank'])\n",
    "    random.seed(manualSeed)\n",
    "    np.random.seed(manualSeed)\n",
    "    torch.manual_seed(manualSeed)\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "    \n",
    "    if gdict['deterministic']:\n",
    "        logging.info(\"Running with deterministic sequence. Performance will be slower\")\n",
    "        torch.backends.cudnn.deterministic=True\n",
    "#         torch.backends.cudnn.enabled = False\n",
    "        torch.backends.cudnn.benchmark = False        \n",
    "    \n",
    "    ########################\n",
    "    if log:\n",
    "        ### Write all logging.info statements to stdout and log file\n",
    "        logfile=gdict['save_dir']+'/log.log'\n",
    "        if gdict['world_rank']==0:\n",
    "            logging.basicConfig(level=logging.DEBUG, filename=logfile, filemode=\"a+\", format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n",
    "            Lg = logging.getLogger()\n",
    "            Lg.setLevel(logging.DEBUG)\n",
    "            lg_handler_file = logging.FileHandler(logfile)\n",
    "            lg_handler_stdout = logging.StreamHandler(sys.stdout)\n",
    "            Lg.addHandler(lg_handler_file)\n",
    "            Lg.addHandler(lg_handler_stdout)\n",
    "\n",
    "            logging.info('Args: {0}'.format(args))\n",
    "            logging.info('Start: %s'%(datetime.now().strftime('%Y-%m-%d  %H:%M:%S')))\n",
    "        \n",
    "        if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "\n",
    "        if gdict['world_rank']!=0:\n",
    "                logging.basicConfig(level=logging.DEBUG, filename=logfile, filemode=\"a+\", format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n",
    "        return metrics_df\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self,gdict):\n",
    "        '''\n",
    "        Load training dataset and compute spectrum and histogram for a small batch of training and validation dataset.\n",
    "        '''\n",
    "        \n",
    "        ## Load training dataset\n",
    "        t0a=time.time()\n",
    "        for count,sigma in enumerate(gdict['sigma_list']):\n",
    "            fname=gdict['ip_fname']+'/norm_1_sig_%s_train_val.npy'%(sigma)\n",
    "            x=np.load(fname,mmap_mode='r')[:gdict['num_imgs']].transpose(0,1,2,3,4) ## Mod for 3D\n",
    "            x=f_get_img_samples(x,gdict['world_rank'],gdict['world_size'])\n",
    "            size=x.shape[0]\n",
    "            y=sigma*np.ones(size)\n",
    "\n",
    "            if count==0:\n",
    "                img=x[:]\n",
    "                c_pars=y[:]\n",
    "            else: \n",
    "                img=np.vstack([img,x]) # Store images\n",
    "                c_pars=np.hstack([c_pars,y]) # Store cosmological parameters\n",
    "\n",
    "        ### Manually shuffling numpy arrays to mix sigma values\n",
    "        size=img.shape[0]\n",
    "        idxs=np.random.choice(size,size=size,replace=False)\n",
    "        img=img[idxs]\n",
    "        c_pars=c_pars[idxs]\n",
    "        ## convert to tensors\n",
    "        t_img=torch.from_numpy(img)\n",
    "        cosm_params=torch.Tensor(c_pars).view(size,1)\n",
    "\n",
    "        dataset=TensorDataset(t_img,cosm_params)\n",
    "        self.train_dataloader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)\n",
    "        logging.info(\"Size of dataset for GPU %s : %s\"%(gdict['world_rank'],len(self.train_dataloader.dataset)))\n",
    "\n",
    "        t0b=time.time()\n",
    "        logging.info(\"Time for creating dataloader %s for rank %s\"%(t0b-t0a,gdict['world_rank']))\n",
    "\n",
    "\n",
    "        # Precompute spectrum and histogram for small training and validation data for computing losses           \n",
    "        def f_compute_summary_stats(idx1=-50,idx2=None):\n",
    "            # Compute hist and spec for given dataset\n",
    "            with torch.no_grad():\n",
    "                spec_mean_list=[];spec_var_list=[];hist_val_list=[]\n",
    "                for count,sigma in enumerate(gdict['sigma_list']):\n",
    "                    ip_fname=gdict['ip_fname']+'/norm_1_sig_%s_train_val.npy'%(sigma)\n",
    "                    val_img=np.load(ip_fname,mmap_mode='r')[idx1:idx2].transpose(0,1,2,3,4).copy() ## Mod for 3D\n",
    "                    t_val_img=torch.from_numpy(val_img).to(gdict['device'])\n",
    "\n",
    "                    # Precompute radial coordinates\n",
    "                    if count==0: \n",
    "                        r,ind=f_get_rad(val_img)\n",
    "                        r=r.to(gdict['device']); ind=ind.to(gdict['device'])\n",
    "                    # Stored mean and std of spectrum for full input data once\n",
    "                    mean_spec_val,var_spec_val=f_torch_image_spectrum(f_invtransform(t_val_img),1,r,ind)\n",
    "                    hist_val=f_compute_hist(t_val_img,bins=gdict['bns'])\n",
    "\n",
    "                    spec_mean_list.append(mean_spec_val)\n",
    "                    spec_var_list.append(var_spec_val)\n",
    "                    hist_val_list.append(hist_val)\n",
    "    #             del val_img; del t_val_img; del img; del spec_mean_list; del spec_var_list; del hist_val_list   \n",
    "                return torch.stack(spec_mean_list),torch.stack(spec_var_list),torch.stack(hist_val_list),r,ind\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.train_spec_mean,self.train_spec_var,self.train_hist,self.r,self.ind=f_compute_summary_stats(-50,None)\n",
    "            ## Compute for validation data\n",
    "            self.val_spec_mean,self.val_spec_var,self.val_hist,_,_=f_compute_summary_stats(-100,-50)\n",
    "\n",
    "class GAN_model():\n",
    "    def __init__(self,gdict,print_model=False):\n",
    "    \n",
    "        def weights_init(m):\n",
    "            '''custom weights initialization called on netG and netD '''\n",
    "            classname = m.__class__.__name__\n",
    "            if classname.find('Conv') != -1:\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            elif classname.find('BatchNorm') != -1:\n",
    "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "        ## Choose model\n",
    "        Generator, Discriminator=f_get_model(gdict['model'],gdict) ## Mod for cGAN\n",
    "\n",
    "        # Create Generator\n",
    "        self.netG = Generator(gdict).to(gdict['device'])\n",
    "        self.netG.apply(weights_init)\n",
    "        # Create Discriminator\n",
    "        self.netD = Discriminator(gdict).to(gdict['device'])\n",
    "        self.netD.apply(weights_init)\n",
    "\n",
    "        if print_model:\n",
    "            if gdict['world_rank']==0:\n",
    "                print(self.netG)\n",
    "            #     summary(netG,(1,1,64))\n",
    "                print(self.netD)\n",
    "            #     summary(netD,(1,128,128))\n",
    "                print(\"Number of GPUs used %s\"%(gdict['ngpu']))\n",
    "\n",
    "        if (gdict['multi-gpu']):\n",
    "            if not gdict['distributed']:\n",
    "                self.netG = nn.DataParallel(self.netG, list(range(gdict['ngpu'])))\n",
    "                self.netD = nn.DataParallel(self.netD, list(range(gdict['ngpu'])))\n",
    "            else:\n",
    "                self.netG=DistributedDataParallel(self.netG,device_ids=[gdict['local_rank']],output_device=[gdict['local_rank']])\n",
    "                self.netD=DistributedDataParallel(self.netD,device_ids=[gdict['local_rank']],output_device=[gdict['local_rank']])\n",
    "\n",
    "        #### Initialize networks ####\n",
    "        # self.criterion = nn.BCELoss()\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.optimizerD = optim.Adam(self.netD.parameters(), lr=gdict['learn_rate_d'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n",
    "        self.optimizerG = optim.Adam(self.netG.parameters(), lr=gdict['learn_rate_g'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n",
    "        \n",
    "        if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "\n",
    "        if gdict['mode']=='fresh':\n",
    "            iters,start_epoch,best_chi1,best_chi2=0,0,1e10,1e10 \n",
    "            \n",
    "        elif gdict['mode']=='continue':\n",
    "            iters,start_epoch,best_chi1,best_chi2,self.netD,self.optimizerD,self.netG,self.optimizerG=f_load_checkpoint(gdict['save_dir']+'/models/checkpoint_last.tar',\\\n",
    "                                                                                                                        self.netG,self.netD,self.optimizerG,self.optimizerD,gdict) \n",
    "            if gdict['world_rank']==0: logging.info(\"\\nContinuing existing run. Loading checkpoint with epoch {0} and step {1}\\n\".format(start_epoch,iters))\n",
    "            if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "            start_epoch+=1  ## Start with the next epoch \n",
    "        \n",
    "        elif gdict['mode']=='fresh_load':\n",
    "            iters,start_epoch,best_chi1,best_chi2,self.netD,self.optimizerD,self.netG,self.optimizerG=f_load_checkpoint(gdict['chkpt_file'],\\\n",
    "                                                                                                                        self.netG,self.netD,self.optimizerG,self.optimizerD,gdict) \n",
    "            if gdict['world_rank']==0: logging.info(\"Fresh run loading checkpoint file {0}\".format(gdict['chkpt_file']))\n",
    "            if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "            iters,start_epoch,best_chi1,best_chi2=0,0,1e10,1e10 \n",
    "        \n",
    "        ## Add to gdict\n",
    "        for key,val in zip(['best_chi1','best_chi2','iters','start_epoch'],[best_chi1,best_chi2,iters,start_epoch]): gdict[key]=val\n",
    "        \n",
    "        ## Set up learn rate scheduler\n",
    "        lr_stepsize=int((gdict['num_imgs']*len(gdict['sigma_list']))/(gdict['batch_size']*gdict['world_size'])) # convert epoch number to step \n",
    "        lr_d_epochs=[i*lr_stepsize for i in gdict['lr_d_epochs']] \n",
    "        lr_g_epochs=[i*lr_stepsize for i in gdict['lr_g_epochs']]\n",
    "        self.schedulerD = optim.lr_scheduler.MultiStepLR(self.optimizerD, milestones=lr_d_epochs,gamma=gdict['lr_d_gamma'])\n",
    "        self.schedulerG = optim.lr_scheduler.MultiStepLR(self.optimizerG, milestones=lr_g_epochs,gamma=gdict['lr_g_gamma'])\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f_train_loop(gan_model,Dset,metrics_df,gdict,fixed_noise,fixed_cosm_params):\n",
    "    ''' Train single epoch '''\n",
    "\n",
    "    ## Define new variables from dict\n",
    "    keys=['image_size','start_epoch','epochs','iters','best_chi1','best_chi2','save_dir','device','flip_prob','nz','batch_size','bns']\n",
    "    image_size,start_epoch,epochs,iters,best_chi1,best_chi2,save_dir,device,flip_prob,nz,batchsize,bns=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "    \n",
    "    for epoch in range(start_epoch,epochs):\n",
    "        t_epoch_start=time.time()\n",
    "        for count, data in enumerate(Dset.train_dataloader):\n",
    "\n",
    "            ####### Train GAN ########\n",
    "            gan_model.netG.train(); gan_model.netD.train();  ### Need to add these after inference and before training\n",
    "\n",
    "            tme1=time.time()\n",
    "            ### Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            gan_model.netD.zero_grad()\n",
    "\n",
    "            real_cpu = data[0].to(device)\n",
    "            real_cosm_params=data[1].to(device)\n",
    "            real_cpu.requires_grad=True\n",
    "            \n",
    "            b_size = real_cpu.size(0)\n",
    "            real_label = torch.full((b_size,), 1, device=device,dtype=float)\n",
    "            fake_label = torch.full((b_size,), 0, device=device,dtype=float)\n",
    "            g_label = torch.full((b_size,), 1, device=device,dtype=float) ## No flipping for Generator labels\n",
    "            # Flip labels with probability flip_prob\n",
    "            for idx in np.random.choice(np.arange(b_size),size=int(np.ceil(b_size*flip_prob))):\n",
    "                real_label[idx]=0; fake_label[idx]=1\n",
    "\n",
    "            # Generate fake image batch with G\n",
    "            noise = torch.randn(b_size, 1, 1, 1, nz, device=device) ### Mod for 3D\n",
    "            rnd_idx=torch.randint(len(gdict['sigma_list']),(gdict['batch_size'],1),device=gdict['device'])\n",
    "            fake_cosm_params=torch.tensor([gdict['sigma_list'][i] for i in rnd_idx.long()],device=gdict['device']).unsqueeze(-1)\n",
    "\n",
    "            fake = gan_model.netG(noise,fake_cosm_params)         \n",
    "\n",
    "            # Forward pass real batch through D\n",
    "            real_output = gan_model.netD(real_cpu,real_cosm_params)\n",
    "            errD_real = gan_model.criterion(real_output[-1].view(-1), real_label.float())\n",
    "            errD_real.backward(retain_graph=True)\n",
    "            D_x = real_output[-1].mean().item()\n",
    "\n",
    "            # Forward pass fake batch through D\n",
    "            fake_output = gan_model.netD(fake.detach(),fake_cosm_params)  # The detach is important\n",
    "            errD_fake = gan_model.criterion(fake_output[-1].view(-1), fake_label.float())\n",
    "            errD_fake.backward(retain_graph=True)\n",
    "            D_G_z1 = fake_output[-1].mean().item()\n",
    "            \n",
    "            errD = errD_real + errD_fake \n",
    "\n",
    "            if gdict['lambda_gp']: ## Add gradient - penalty loss                \n",
    "                grads=torch.autograd.grad(outputs=real_output[-1],inputs=real_cpu,grad_outputs=torch.ones_like(real_output[-1]),allow_unused=False,create_graph=True)[0]\n",
    "                gp_loss=f_get_loss_cond('gp',fake,fake_cosm_params,gdict,grads=grads)\n",
    "                gp_loss.backward(retain_graph=True)\n",
    "                errD = errD + gp_loss\n",
    "            else:\n",
    "                gp_loss=torch.Tensor([np.nan])\n",
    "\n",
    "            ### Implement Gradient clipping\n",
    "            if gdict['grad_clip']:\n",
    "                nn.utils.clip_grad_norm_(gan_model.netD.parameters(),gdict['grad_clip'])\n",
    "                \n",
    "            gan_model.optimizerD.step()\n",
    "            lr_d=gan_model.optimizerD.param_groups[0]['lr']\n",
    "            gan_model.schedulerD.step()\n",
    "            \n",
    "            ###Update G network: maximize log(D(G(z)))\n",
    "            gan_model.netG.zero_grad()\n",
    "            output = gan_model.netD(fake,fake_cosm_params)\n",
    "            errG_adv = gan_model.criterion(output[-1].view(-1), g_label.float())\n",
    "            # Histogram pixel intensity loss\n",
    "            hist_loss=f_get_loss_cond('hist',fake,fake_cosm_params,gdict,bins=gdict['bns'],hist_val_tnsr=Dset.train_hist)\n",
    "\n",
    "            # Add spectral loss\n",
    "            mean,var=f_torch_image_spectrum(f_invtransform(fake),1,Dset.r.to(device),Dset.ind.to(device))\n",
    "            spec_loss=f_get_loss_cond('spec',fake,fake_cosm_params,gdict,spec_mean_tnsr=Dset.train_spec_mean,spec_var_tnsr=Dset.train_spec_var,r=Dset.r,ind=Dset.ind)\n",
    "            \n",
    "            errG=errG_adv\n",
    "            if gdict['lambda_spec_mean']: errG = errG+ spec_loss \n",
    "            if gdict['lambda_fm']:## Add feature matching loss\n",
    "                fm_loss=f_get_loss_cond('fm',fake,fake_cosm_params,gdict,real_output=[i.detach() for i in real_output],fake_output=output)\n",
    "                errG= errG+ fm_loss\n",
    "            else: \n",
    "                fm_loss=torch.Tensor([np.nan])\n",
    "\n",
    "            if torch.isnan(errG).any():\n",
    "                logging.info(errG)\n",
    "                raise SystemError\n",
    "            \n",
    "            # Calculate gradients for G\n",
    "            errG.backward()\n",
    "            D_G_z2 = output[-1].mean().item()\n",
    "\n",
    "            ### Implement Gradient clipping\n",
    "            if gdict['grad_clip']:\n",
    "                nn.utils.clip_grad_norm_(gan_model.netG.parameters(),gdict['grad_clip'])\n",
    "\n",
    "            gan_model.optimizerG.step()\n",
    "            lr_g=gan_model.optimizerG.param_groups[0]['lr']\n",
    "            gan_model.schedulerG.step()\n",
    "            \n",
    "            tme2=time.time()\n",
    "            ####### Store metrics ########\n",
    "            # Output training stats\n",
    "            if gdict['world_rank']==0:\n",
    "                if ((count % gdict['checkpoint_size'] == 0)):\n",
    "                    logging.info('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_adv: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                          % (epoch, epochs, count, len(Dset.train_dataloader), errD.item(), errG_adv.item(),errG.item(), D_x, D_G_z1, D_G_z2)),\n",
    "                    logging.info(\"Spec loss: %s,\\t hist loss: %s\"%(spec_loss.item(),hist_loss.item())),\n",
    "                    logging.info(\"Training time for step %s : %s\"%(iters, tme2-tme1))\n",
    "\n",
    "                # Save metrics\n",
    "                cols=['step','epoch','Dreal','Dfake','Dfull','G_adv','G_full','spec_loss','hist_loss','fm_loss','gp_loss','D(x)','D_G_z1','D_G_z2','lr_d','lr_g','time']\n",
    "                vals=[iters,epoch,errD_real.item(),errD_fake.item(),errD.item(),errG_adv.item(),errG.item(),spec_loss.item(),hist_loss.item(),fm_loss.item(),gp_loss.item(),D_x,D_G_z1,D_G_z2,lr_d,lr_g,tme2-tme1]\n",
    "                for col,val in zip(cols,vals):  metrics_df.loc[iters,col]=val\n",
    "\n",
    "                ### Checkpoint the best model\n",
    "                checkpoint=True\n",
    "                iters += 1  ### Model has been updated, so update iters before saving metrics and model.\n",
    "\n",
    "                ### Compute validation metrics for updated model\n",
    "                gan_model.netG.eval()\n",
    "                with torch.no_grad():\n",
    "                    fake = gan_model.netG(fixed_noise,fixed_cosm_params)\n",
    "                    hist_chi=f_get_loss_cond('hist',fake,fixed_cosm_params,gdict,bins=gdict['bns'],hist_val_tnsr=Dset.val_hist)\n",
    "                    spec_chi=f_get_loss_cond('spec',fake,fixed_cosm_params,gdict,spec_mean_tnsr=Dset.val_spec_mean,spec_var_tnsr=Dset.val_spec_var,r=Dset.r,ind=Dset.ind)\n",
    "\n",
    "                # Storing chi for next step\n",
    "                for col,val in zip(['spec_chi','hist_chi'],[spec_chi.item(),hist_chi.item()]):  metrics_df.loc[iters,col]=val            \n",
    "\n",
    "                # Checkpoint model for continuing run\n",
    "                if count == len(Dset.train_dataloader)-1: ## Checkpoint at last step of epoch\n",
    "                    f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,gan_model.netG,gan_model.netD,gan_model.optimizerG,gan_model.optimizerD,save_loc=save_dir+'/models/checkpoint_last.tar')  \n",
    "                    shutil.copy(save_dir+'/models/checkpoint_last.tar',save_dir+'/models/checkpoint_%s_%s.tar'%(epoch,iters)) # Store last step for each epoch\n",
    "                    \n",
    "                if (checkpoint and (epoch > 1)): # Choose best models by metric\n",
    "                    if hist_chi< best_chi1:\n",
    "                        f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,gan_model.netG,gan_model.netD,gan_model.optimizerG,gan_model.optimizerD,save_loc=save_dir+'/models/checkpoint_best_hist.tar')\n",
    "                        best_chi1=hist_chi.item()\n",
    "                        logging.info(\"Saving best hist model at epoch %s, step %s.\"%(epoch,iters))\n",
    "\n",
    "                    if  spec_chi< best_chi2:\n",
    "                        f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,gan_model.netG,gan_model.netD,gan_model.optimizerG,gan_model.optimizerD,save_loc=save_dir+'/models/checkpoint_best_spec.tar')\n",
    "                        best_chi2=spec_chi.item()\n",
    "                        logging.info(\"Saving best spec model at epoch %s, step %s\"%(epoch,iters))\n",
    "\n",
    "#                    if (iters in gdict['save_steps_list']) :\n",
    "                    if ((gdict['save_steps_list']=='all') and (iters % gdict['checkpoint_size'] == 0)):                        \n",
    "                        f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,gan_model.netG,gan_model.netD,gan_model.optimizerG,gan_model.optimizerD,save_loc=save_dir+'/models/checkpoint_{0}.tar'.format(iters))\n",
    "                        logging.info(\"Saving given-step at epoch %s, step %s.\"%(epoch,iters))\n",
    "\n",
    "                # Save G's output on fixed_noise\n",
    "                if ((iters % gdict['checkpoint_size'] == 0) or ((epoch == epochs-1) and (count == len(Dset.train_dataloader)-1))):\n",
    "                    gan_model.netG.eval()\n",
    "                    with torch.no_grad():\n",
    "                        for c_pars in gdict['sigma_list']:\n",
    "                            tnsr_cosm_params=(torch.ones(gdict['op_size'],device=device)*c_pars).view(gdict['op_size'],1)\n",
    "                            fake = gan_model.netG(fixed_noise,tnsr_cosm_params).detach().cpu()\n",
    "                            img_arr=np.array(fake)\n",
    "                            fname='gen_img_label-%s_epoch-%s_step-%s'%(c_pars,epoch,iters)\n",
    "                            np.save(save_dir+'/images/'+fname,img_arr)\n",
    "        \n",
    "        t_epoch_end=time.time()\n",
    "        if gdict['world_rank']==0:\n",
    "            logging.info(\"Time taken for epoch %s, count %s: %s for rank %s\"%(epoch,count,t_epoch_end-t_epoch_start,gdict['world_rank']))\n",
    "            # Save Metrics to file after each epoch\n",
    "            metrics_df.to_pickle(save_dir+'/df_metrics.pkle')\n",
    "            logging.info(\"best chis: {0}, {1}\".format(best_chi1,best_chi2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using DDP\n",
      "Model name 2\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=65, out_features=32768, bias=True)\n",
      "    (1): BatchNorm3d(1, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): View()\n",
      "    (4): ConvTranspose3d(512, 256, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
      "    (5): BatchNorm3d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): ConvTranspose3d(256, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
      "    (8): BatchNorm3d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ConvTranspose3d(128, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
      "    (11): BatchNorm3d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ConvTranspose3d(64, 1, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
      "    (14): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (linear_transf): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (main): Sequential(\n",
      "    (0): Conv3d(2, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv3d(64, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (4): BatchNorm3d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv3d(128, 256, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (7): BatchNorm3d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv3d(256, 512, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (10): BatchNorm3d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=32768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of GPUs used 1\n",
      "Size of dataset for GPU 0 : 150\n",
      "Time for creating dataloader 0.1992959976196289 0\n",
      "{'ip_fname': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/raw_data/3d_data/64cube/dataset2a_3dcgan_4univs_64cube_simple_splicing', 'op_loc': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/results_pytorch/3d/', 'image_size': 64, 'num_imgs': 50, 'ip_fldr': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/results_pytorch/3d/20210526_105905_nb_test', 'workers': 2, 'nc': 1, 'nz': 64, 'ngf': 64, 'ndf': 64, 'beta1': 0.5, 'kernel_size': 5, 'stride': 2, 'g_padding': 2, 'd_padding': 2, 'flip_prob': 0.01, 'bns': 50, 'checkpoint_size': 10, 'sigma_list': [0.5, 0.8, 1.1], 'model': 2, 'batch_size': 16, 'epochs': 5, 'op_size': 32, 'learn_rate_d': 0.001, 'learn_rate_g': 0.0015, 'lr_d_epochs': [10, 40, 60, 70, 100, 140, 180], 'lr_d_gamma': 0.5, 'lr_g_epochs': [10, 40, 60, 70, 100, 140, 180], 'lr_g_gamma': 0.5, 'deterministic': False, 'seed': 234373, 'lambda_spec_mean': 0.1, 'lambda_spec_var': 0.1, 'lambda_fm': 0.0, 'lambda_gp': 0.0, 'grad_clip': 0.5, 'save_steps_list': ' ', 'run_suffix': 'nb_test', 'description': '3d conditional GAN: DDP with new loss', 'config': 'config_3d_cgan_summit.yaml', 'mode': 'fresh', 'local_rank': 0, 'facility': 'cori', 'distributed': False, 'ngpu': 1, 'device': device(type='cuda'), 'multi-gpu': False, 'world_size': 1, 'world_rank': 0, 'save_dir': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/results_pytorch/3d/20210526_110921_nb_test', 'best_chi1': 10000000000.0, 'best_chi2': 10000000000.0, 'iters': 0, 'start_epoch': 0}\n",
      "Nans in spectrum tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan]], device='cuda:0') tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan]], device='cuda:0')\n",
      "Nans in spectrum tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan]], device='cuda:0') tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan]], device='cuda:0')\n",
      "Nans in spectrum tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan]], device='cuda:0') tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-119032c1a7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m########## Train loop and save metrics and images ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Training Loop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mf_train_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfixed_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfixed_cosm_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'world_rank'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## Generate images for best saved models ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-a18f221c4ae0>\u001b[0m in \u001b[0;36mf_train_loop\u001b[0;34m(gan_model, Dset, metrics_df, gdict, fixed_noise, fixed_cosm_params)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Choose best models by metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhist_chi\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mbest_chi1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                         \u001b[0mf_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_chi1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_chi2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/models/checkpoint_best_hist.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                         \u001b[0mbest_chi1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist_chi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving best hist model at epoch %s, step %s.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e1108a934d58>\u001b[0m in \u001b[0;36mf_save_checkpoint\u001b[0;34m(gdict, epoch, iters, best_chi1, best_chi2, netG, netD, optimizerG, optimizerD, save_loc)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 'optimizerD_state_dict':optimizerD.state_dict()}, save_loc) \n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         torch.save({'epoch':epoch,'iters':iters,'best_chi1':best_chi1,'best_chi2':best_chi2,\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;34m'G_state'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'D_state'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'optimizerG_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 'optimizerD_state_dict':optimizerD.state_dict()}, save_loc)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################\n",
    "### Main code #######\n",
    "#########################\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    jpt=False\n",
    "    jpt=True ##(different for jupyter notebook)\n",
    "    t0=time.time()\n",
    "    args=f_parse_args() if not jpt else f_manual_add_argparse()\n",
    "\n",
    "    #################################\n",
    "    ### Set up global dictionary###\n",
    "    gdict={}\n",
    "    gdict=f_init_gdict(args,gdict)\n",
    "#     gdict['num_imgs']=200\n",
    "\n",
    "    if jpt: ## override for jpt nbks\n",
    "        gdict['num_imgs']=50\n",
    "        gdict['run_suffix']='nb_test'\n",
    "        \n",
    "    ### Set up metrics dataframe\n",
    "    cols=['step','epoch','Dreal','Dfake','Dfull','G_adv','G_full','spec_loss','hist_loss','spec_chi','hist_chi','gp_loss','fm_loss','D(x)','D_G_z1','D_G_z2','time']\n",
    "    metrics_df=pd.DataFrame(columns=cols)\n",
    "    \n",
    "    # Setup\n",
    "    metrics_df=f_setup(gdict,metrics_df,log=(not jpt))\n",
    "    \n",
    "    ## Build GAN\n",
    "    gan_model=GAN_model(gdict,True)\n",
    "\n",
    "    fixed_noise = torch.randn(gdict['op_size'], 1, 1, 1, gdict['nz'], device=gdict['device']) #Latent vectors to view G progress    # Mod for 3D\n",
    "    rnd_idx=torch.randint(len(gdict['sigma_list']),(gdict['op_size'],1),device=gdict['device'])\n",
    "    fixed_cosm_params=torch.tensor([gdict['sigma_list'][i] for i in rnd_idx.long()],device=gdict['device']).unsqueeze(-1)\n",
    "    \n",
    "    if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "\n",
    "    ## Load data and precompute\n",
    "    Dset=Dataset(gdict)\n",
    "    \n",
    "    if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "        \n",
    "    print(gdict)\n",
    "    #################################\n",
    "    ########## Train loop and save metrics and images ######    \n",
    "    if gdict['world_rank']==0: \n",
    "        logging.info(gdict)\n",
    "        logging.info(\"Starting Training Loop...\")\n",
    "    \n",
    "    f_train_loop(gan_model,Dset,metrics_df,gdict,fixed_noise,fixed_cosm_params)\n",
    "    \n",
    "    if gdict['world_rank']==0: ## Generate images for best saved models ######\n",
    "        for cl in gdict['sigma_list']:\n",
    "            op_loc=gdict['save_dir']+'/images/'\n",
    "            ip_fname=gdict['save_dir']+'/models/checkpoint_best_spec.tar'\n",
    "            f_gen_images(gdict,gan_model.netG,gan_model.optimizerG,cl,ip_fname,op_loc,op_strg='gen_img_best_spec',op_size=100)\n",
    "\n",
    "            ip_fname=gdict['save_dir']+'/models/checkpoint_best_hist.tar'\n",
    "            f_gen_images(gdict,gan_model.netG,gan_model.optimizerG,cl,ip_fname,op_loc,op_strg='gen_img_best_hist',op_size=100)\n",
    "    \n",
    "    tf=time.time()\n",
    "    logging.info(\"Total time %s\"%(tf-t0))\n",
    "    logging.info('End: %s'%(datetime.now().strftime('%Y-%m-%d  %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Dreal</th>\n",
       "      <th>Dfake</th>\n",
       "      <th>Dfull</th>\n",
       "      <th>G_adv</th>\n",
       "      <th>G_full</th>\n",
       "      <th>spec_loss</th>\n",
       "      <th>hist_loss</th>\n",
       "      <th>spec_chi</th>\n",
       "      <th>hist_chi</th>\n",
       "      <th>gp_loss</th>\n",
       "      <th>fm_loss</th>\n",
       "      <th>D(x)</th>\n",
       "      <th>D_G_z1</th>\n",
       "      <th>D_G_z2</th>\n",
       "      <th>time</th>\n",
       "      <th>lr_d</th>\n",
       "      <th>lr_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728506</td>\n",
       "      <td>0.746371</td>\n",
       "      <td>1.474877</td>\n",
       "      <td>14.509315</td>\n",
       "      <td>26.122162</td>\n",
       "      <td>11.612848</td>\n",
       "      <td>1.651923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>-14.509306</td>\n",
       "      <td>0.441112</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>4.647748</td>\n",
       "      <td>4.898575</td>\n",
       "      <td>25.735403</td>\n",
       "      <td>36.79097</td>\n",
       "      <td>11.055567</td>\n",
       "      <td>0.892253</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.397771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.503948</td>\n",
       "      <td>4.927641</td>\n",
       "      <td>-25.735403</td>\n",
       "      <td>0.433086</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22.924406</td>\n",
       "      <td>1.883293</td>\n",
       "      <td>24.807699</td>\n",
       "      <td>7.844212</td>\n",
       "      <td>19.099453</td>\n",
       "      <td>11.25524</td>\n",
       "      <td>0.703364</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.2136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.005779</td>\n",
       "      <td>-24.15218</td>\n",
       "      <td>-7.842451</td>\n",
       "      <td>0.429931</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.236542</td>\n",
       "      <td>0.438876</td>\n",
       "      <td>7.675418</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>11.359185</td>\n",
       "      <td>11.358482</td>\n",
       "      <td>0.509159</td>\n",
       "      <td>11.22778</td>\n",
       "      <td>0.57816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.886631</td>\n",
       "      <td>-7.582302</td>\n",
       "      <td>9.825704</td>\n",
       "      <td>0.431104</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.551666</td>\n",
       "      <td>9.374983</td>\n",
       "      <td>9.926649</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>11.809747</td>\n",
       "      <td>11.791882</td>\n",
       "      <td>0.618098</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.728068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.681259</td>\n",
       "      <td>9.774035</td>\n",
       "      <td>4.711203</td>\n",
       "      <td>0.432009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389854</td>\n",
       "      <td>4.512754</td>\n",
       "      <td>4.902609</td>\n",
       "      <td>6.950334</td>\n",
       "      <td>18.112038</td>\n",
       "      <td>11.161703</td>\n",
       "      <td>0.725781</td>\n",
       "      <td>11.244907</td>\n",
       "      <td>0.630511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.663035</td>\n",
       "      <td>4.684094</td>\n",
       "      <td>-6.935911</td>\n",
       "      <td>0.429138</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6.010461</td>\n",
       "      <td>0.210055</td>\n",
       "      <td>6.220516</td>\n",
       "      <td>3.059958</td>\n",
       "      <td>14.631554</td>\n",
       "      <td>11.571596</td>\n",
       "      <td>0.694973</td>\n",
       "      <td>11.926919</td>\n",
       "      <td>0.663331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.699506</td>\n",
       "      <td>-6.860959</td>\n",
       "      <td>-2.91362</td>\n",
       "      <td>0.43052</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.573465</td>\n",
       "      <td>0.455787</td>\n",
       "      <td>3.029252</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>11.197329</td>\n",
       "      <td>11.190165</td>\n",
       "      <td>0.701539</td>\n",
       "      <td>11.201015</td>\n",
       "      <td>0.771183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.749347</td>\n",
       "      <td>-2.971327</td>\n",
       "      <td>6.906721</td>\n",
       "      <td>0.429944</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235767</td>\n",
       "      <td>6.32336</td>\n",
       "      <td>6.559128</td>\n",
       "      <td>0.069099</td>\n",
       "      <td>11.43123</td>\n",
       "      <td>11.362131</td>\n",
       "      <td>0.780931</td>\n",
       "      <td>11.255711</td>\n",
       "      <td>1.517829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.87323</td>\n",
       "      <td>6.858871</td>\n",
       "      <td>3.369638</td>\n",
       "      <td>0.431231</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198923</td>\n",
       "      <td>3.270876</td>\n",
       "      <td>3.4698</td>\n",
       "      <td>5.814818</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.791889</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.910129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.241093</td>\n",
       "      <td>3.405826</td>\n",
       "      <td>-5.783303</td>\n",
       "      <td>0.431008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5.458124</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>5.625625</td>\n",
       "      <td>2.866939</td>\n",
       "      <td>14.280901</td>\n",
       "      <td>11.413962</td>\n",
       "      <td>0.792963</td>\n",
       "      <td>11.659573</td>\n",
       "      <td>0.774343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.75184</td>\n",
       "      <td>-5.706443</td>\n",
       "      <td>-2.725498</td>\n",
       "      <td>0.429602</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.629046</td>\n",
       "      <td>0.467429</td>\n",
       "      <td>3.096475</td>\n",
       "      <td>0.061128</td>\n",
       "      <td>11.14465</td>\n",
       "      <td>11.083523</td>\n",
       "      <td>0.848135</td>\n",
       "      <td>11.26811</td>\n",
       "      <td>0.832122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.618498</td>\n",
       "      <td>-2.519015</td>\n",
       "      <td>5.240973</td>\n",
       "      <td>0.430113</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376757</td>\n",
       "      <td>4.935814</td>\n",
       "      <td>5.312572</td>\n",
       "      <td>0.433808</td>\n",
       "      <td>11.52385</td>\n",
       "      <td>11.090042</td>\n",
       "      <td>0.729256</td>\n",
       "      <td>11.239315</td>\n",
       "      <td>0.569851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.535579</td>\n",
       "      <td>5.230655</td>\n",
       "      <td>1.509949</td>\n",
       "      <td>0.429375</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423494</td>\n",
       "      <td>2.11884</td>\n",
       "      <td>2.542333</td>\n",
       "      <td>7.295842</td>\n",
       "      <td>18.328707</td>\n",
       "      <td>11.032866</td>\n",
       "      <td>0.722343</td>\n",
       "      <td>11.220885</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.191289</td>\n",
       "      <td>1.69677</td>\n",
       "      <td>-7.279261</td>\n",
       "      <td>0.431503</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6.185926</td>\n",
       "      <td>0.438595</td>\n",
       "      <td>6.624521</td>\n",
       "      <td>0.720296</td>\n",
       "      <td>11.88194</td>\n",
       "      <td>11.161644</td>\n",
       "      <td>1.222511</td>\n",
       "      <td>11.291883</td>\n",
       "      <td>0.923218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.553688</td>\n",
       "      <td>-6.78219</td>\n",
       "      <td>1.19825</td>\n",
       "      <td>0.431849</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718768</td>\n",
       "      <td>2.218099</td>\n",
       "      <td>2.936867</td>\n",
       "      <td>1.156283</td>\n",
       "      <td>12.301946</td>\n",
       "      <td>11.145662</td>\n",
       "      <td>1.55882</td>\n",
       "      <td>11.2599</td>\n",
       "      <td>1.343122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92716</td>\n",
       "      <td>1.507074</td>\n",
       "      <td>0.400125</td>\n",
       "      <td>0.42721</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.308647</td>\n",
       "      <td>1.878297</td>\n",
       "      <td>3.186944</td>\n",
       "      <td>3.86048</td>\n",
       "      <td>14.973657</td>\n",
       "      <td>11.113177</td>\n",
       "      <td>1.757249</td>\n",
       "      <td>11.265967</td>\n",
       "      <td>1.556691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425656</td>\n",
       "      <td>0.410834</td>\n",
       "      <td>-3.832962</td>\n",
       "      <td>0.430531</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3.941227</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>4.261311</td>\n",
       "      <td>0.227981</td>\n",
       "      <td>11.794756</td>\n",
       "      <td>11.566774</td>\n",
       "      <td>1.840482</td>\n",
       "      <td>11.848233</td>\n",
       "      <td>1.738811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.214372</td>\n",
       "      <td>-3.878893</td>\n",
       "      <td>1.859454</td>\n",
       "      <td>0.43031</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.317079</td>\n",
       "      <td>2.055341</td>\n",
       "      <td>2.372419</td>\n",
       "      <td>2.75735</td>\n",
       "      <td>13.589986</td>\n",
       "      <td>10.832636</td>\n",
       "      <td>1.958683</td>\n",
       "      <td>11.228112</td>\n",
       "      <td>1.747882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.859533</td>\n",
       "      <td>1.906775</td>\n",
       "      <td>-2.682537</td>\n",
       "      <td>0.430745</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2.516878</td>\n",
       "      <td>0.204068</td>\n",
       "      <td>2.720947</td>\n",
       "      <td>0.139553</td>\n",
       "      <td>12.627217</td>\n",
       "      <td>12.487664</td>\n",
       "      <td>1.866193</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.939406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.550848</td>\n",
       "      <td>-2.545221</td>\n",
       "      <td>2.505056</td>\n",
       "      <td>0.429946</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.737724</td>\n",
       "      <td>1.816528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step epoch      Dreal     Dfake      Dfull      G_adv     G_full  \\\n",
       "0     0     0   0.728506  0.746371   1.474877  14.509315  26.122162   \n",
       "1     1     0   0.250827  4.647748   4.898575  25.735403   36.79097   \n",
       "2     2     0  22.924406  1.883293  24.807699   7.844212  19.099453   \n",
       "3     3     0   7.236542  0.438876   7.675418   0.000703  11.359185   \n",
       "4     4     0   0.551666  9.374983   9.926649   0.017865  11.809747   \n",
       "5     5     0   0.389854  4.512754   4.902609   6.950334  18.112038   \n",
       "6     6     0   6.010461  0.210055   6.220516   3.059958  14.631554   \n",
       "7     7     0   2.573465  0.455787   3.029252   0.007164  11.197329   \n",
       "8     8     0   0.235767   6.32336   6.559128   0.069099   11.43123   \n",
       "9     9     1   0.198923  3.270876     3.4698   5.814818        inf   \n",
       "10   10     1   5.458124  0.167502   5.625625   2.866939  14.280901   \n",
       "11   11     1   2.629046  0.467429   3.096475   0.061128   11.14465   \n",
       "12   12     1   0.376757  4.935814   5.312572   0.433808   11.52385   \n",
       "13   13     1   0.423494   2.11884   2.542333   7.295842  18.328707   \n",
       "14   14     1   6.185926  0.438595   6.624521   0.720296   11.88194   \n",
       "15   15     1   0.718768  2.218099   2.936867   1.156283  12.301946   \n",
       "16   16     1   1.308647  1.878297   3.186944    3.86048  14.973657   \n",
       "17   17     1   3.941227  0.320084   4.261311   0.227981  11.794756   \n",
       "18   18     2   0.317079  2.055341   2.372419    2.75735  13.589986   \n",
       "19   19     2   2.516878  0.204068   2.720947   0.139553  12.627217   \n",
       "20  NaN   NaN        NaN       NaN        NaN        NaN        NaN   \n",
       "\n",
       "    spec_loss hist_loss   spec_chi  hist_chi gp_loss fm_loss       D(x)  \\\n",
       "0   11.612848  1.651923        NaN       NaN     NaN     NaN   0.007352   \n",
       "1   11.055567  0.892253        inf  2.397771     NaN     NaN   3.503948   \n",
       "2    11.25524  0.703364        inf    1.2136     NaN     NaN -24.005779   \n",
       "3   11.358482  0.509159   11.22778   0.57816     NaN     NaN  -7.886631   \n",
       "4   11.791882  0.618098        inf  0.728068     NaN     NaN   9.681259   \n",
       "5   11.161703  0.725781  11.244907  0.630511     NaN     NaN   4.663035   \n",
       "6   11.571596  0.694973  11.926919  0.663331     NaN     NaN  -6.699506   \n",
       "7   11.190165  0.701539  11.201015  0.771183     NaN     NaN  -2.749347   \n",
       "8   11.362131  0.780931  11.255711  1.517829     NaN     NaN    6.87323   \n",
       "9         inf  0.791889        inf  0.910129     NaN     NaN   3.241093   \n",
       "10  11.413962  0.792963  11.659573  0.774343     NaN     NaN   -5.75184   \n",
       "11  11.083523  0.848135   11.26811  0.832122     NaN     NaN  -2.618498   \n",
       "12  11.090042  0.729256  11.239315  0.569851     NaN     NaN   5.535579   \n",
       "13  11.032866  0.722343  11.220885  0.727162     NaN     NaN   2.191289   \n",
       "14  11.161644  1.222511  11.291883  0.923218     NaN     NaN  -6.553688   \n",
       "15  11.145662   1.55882    11.2599  1.343122     NaN     NaN    0.92716   \n",
       "16  11.113177  1.757249  11.265967  1.556691     NaN     NaN   0.425656   \n",
       "17  11.566774  1.840482  11.848233  1.738811     NaN     NaN  -4.214372   \n",
       "18  10.832636  1.958683  11.228112  1.747882     NaN     NaN   1.859533   \n",
       "19  12.487664  1.866193        inf  1.939406     NaN     NaN  -2.550848   \n",
       "20        NaN       NaN  11.737724  1.816528     NaN     NaN        NaN   \n",
       "\n",
       "      D_G_z1     D_G_z2      time   lr_d    lr_g  \n",
       "0     0.0957 -14.509306  0.441112  0.001  0.0015  \n",
       "1   4.927641 -25.735403  0.433086  0.001  0.0015  \n",
       "2  -24.15218  -7.842451  0.429931  0.001  0.0015  \n",
       "3  -7.582302   9.825704  0.431104  0.001  0.0015  \n",
       "4   9.774035   4.711203  0.432009  0.001  0.0015  \n",
       "5   4.684094  -6.935911  0.429138  0.001  0.0015  \n",
       "6  -6.860959   -2.91362   0.43052  0.001  0.0015  \n",
       "7  -2.971327   6.906721  0.429944  0.001  0.0015  \n",
       "8   6.858871   3.369638  0.431231  0.001  0.0015  \n",
       "9   3.405826  -5.783303  0.431008  0.001  0.0015  \n",
       "10 -5.706443  -2.725498  0.429602  0.001  0.0015  \n",
       "11 -2.519015   5.240973  0.430113  0.001  0.0015  \n",
       "12  5.230655   1.509949  0.429375  0.001  0.0015  \n",
       "13   1.69677  -7.279261  0.431503  0.001  0.0015  \n",
       "14  -6.78219    1.19825  0.431849  0.001  0.0015  \n",
       "15  1.507074   0.400125   0.42721  0.001  0.0015  \n",
       "16  0.410834  -3.832962  0.430531  0.001  0.0015  \n",
       "17 -3.878893   1.859454   0.43031  0.001  0.0015  \n",
       "18  1.906775  -2.682537  0.430745  0.001  0.0015  \n",
       "19 -2.545221   2.505056  0.429946  0.001  0.0015  \n",
       "20       NaN        NaN       NaN    NaN     NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics_df.plot('step','time')\n",
    "# metrics_df.plot(x='step',y=['hist_loss','spec_chi'],kind='line')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in iter(dataloader):\n",
    "#     print(i[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matching loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netG = Generator(gdict).to(gdict['device'])\n",
    "# netG.apply(weights_init)\n",
    "# # # #     print(netG)\n",
    "# # summary(netG,(1,1,64))\n",
    "# # Create Discriminator\n",
    "# netD = Discriminator(gdict).to(gdict['device'])\n",
    "# netD.apply(weights_init)\n",
    "# #     print(netD)\n",
    "# summary(netD,(1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = torch.randn(gdict['batchsize'], 1, 1, gdict['nz'], device=gdict['device'])\n",
    "# fake = netG(noise)            \n",
    "# # Forward pass real batch through D\n",
    "# output = netD(fake)\n",
    "# print([i.shape for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Read data and precompute ######\n",
    "img=np.load(gdict['ip_fname'],mmap_mode='r')[:gdict['num_imgs']].transpose(0,1,2,3).copy()\n",
    "t_img=torch.from_numpy(img)\n",
    "print(\"%s, %s\"%(img.shape,t_img.shape))\n",
    "\n",
    "dataset=TensorDataset(t_img)\n",
    "data_loader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sample_data(ip_tensor,rank=0,num_ranks=1):\n",
    "    \n",
    "    data_size=ip_tensor.shape[0]\n",
    "    size=data_size//num_ranks\n",
    "    print(size)\n",
    "    print(rank*(size),(rank+1)*size)\n",
    "    dataset=TensorDataset(ip_tensor[rank*(size):(rank+1)*size])\n",
    "    data_loader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)\n",
    "    print(len(data_loader.dataset))\n",
    "    return data_loader\n",
    "\n",
    "f_sample_data(t_img,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
