{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images\n",
    "Sep 2, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/5_3d_cgan/1_main_code/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_load_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    return config\n",
    "\n",
    "def f_init_gdict(gdict,config_dict):\n",
    "    ''' Initialize the global dictionary gdict with values in config file'''\n",
    "    keys1=['workers','nc','nz','ngf','ndf','beta1','kernel_size','stride','g_padding','d_padding','flip_prob']\n",
    "    keys2=['image_size','checkpoint_size','num_imgs','ip_fname','op_loc']\n",
    "    for key in keys1: gdict[key]=config_dict['training'][key]\n",
    "    for key in keys2: gdict[key]=config_dict['data'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_gen_images(gdict,netG,optimizerG,sigma,ip_fname,op_loc,op_strg='inf_img_',op_size=500):\n",
    "    '''Generate images for best saved models\n",
    "     Arguments: gdict, netG, optimizerG, \n",
    "                 sigma : sigma input value\n",
    "                 ip_fname: name of input file\n",
    "                op_strg: [string name for output file]\n",
    "                op_size: Number of images to generate\n",
    "    '''\n",
    "\n",
    "    nz,device=gdict['nz'],gdict['device']\n",
    "\n",
    "    try:\n",
    "        if torch.cuda.is_available(): checkpoint=torch.load(ip_fname)\n",
    "        else: checkpoint=torch.load(ip_fname,map_location=torch.device('cpu'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        return\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "    \n",
    "    ## Load other stuff\n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(op_size, 1, 1, 1, nz, device=device)\n",
    "    tnsr_cosm_params=(torch.ones(op_size,device=device)*sigma).view(op_size,1)\n",
    "\n",
    "    # Generate fake image batch with G\n",
    "    netG.eval() ## This is required before running inference\n",
    "    gen = netG(noise,tnsr_cosm_params)\n",
    "    gen_images=gen.detach().cpu().numpy()\n",
    "    print(gen_images.shape)\n",
    "\n",
    "    op_fname='%s_label-%s_epoch-%s_step-%s.npy'%(op_strg,sigma,epoch,iters)\n",
    "    np.save(op_loc+op_fname,gen_images)\n",
    "    \n",
    "    print(\"Image saved in \",op_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name 2\n",
      "Building GAN networks\n",
      "Number of GPUs used 1\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    t0=time.time()\n",
    "    #################################\n",
    "#     args=f_parse_args()\n",
    "    # Manually add args ( different for jupyter notebook)\n",
    "    args=argparse.Namespace()\n",
    "    args.config='1_main_code/config_128.yaml'\n",
    "    args.ngpu=1\n",
    "    args.batchsize=128\n",
    "#     args.spec_loss_flag=True\n",
    "#     args.checkpoint_size=50\n",
    "    args.epochs=1\n",
    "    args.learn_rate=0.0002\n",
    "#     args.mode='fresh'\n",
    "#     args.run_suffix='_nb_test'\n",
    "#     args.deterministic=False\n",
    "#     args.seed='36723705'\n",
    "#     args.lambda1=5.0\n",
    "#     args.save_steps_list=[5,10]\n",
    "\n",
    "    ### Set up ###\n",
    "    config_file=args.config\n",
    "    config_dict=f_load_config(config_file)\n",
    "\n",
    "    # Initilize variables    \n",
    "    gdict={}\n",
    "    f_init_gdict(gdict,config_dict)\n",
    "    \n",
    "    ## Add args variables to gdict\n",
    "    for key in ['ngpu','batchsize','epochs','learn_rate']:\n",
    "        gdict[key]=vars(args)[key]\n",
    "    \n",
    "    gdict['device']=torch.device(\"cuda\" if (torch.cuda.is_available() and gdict['ngpu'] > 0) else \"cpu\")\n",
    "    gdict['ngpu']=torch.cuda.device_count()\n",
    "    gdict['multi-gpu']=True if (gdict['device'].type == 'cuda') and (gdict['ngpu'] > 1) else False \n",
    "    gdict['model']=2\n",
    "    gdict['model_float']=True\n",
    "    gdict['num_classes']=3\n",
    "#     gdict['sigma_list']=[0.5,0.65,0.8,1.1]\n",
    "    # Define Models\n",
    "    Generator, Discriminator=f_get_model(gdict['model'],gdict)\n",
    "    print(\"Building GAN networks\")\n",
    "    # Create Generator\n",
    "    netG = Generator(gdict).to(gdict['device'])\n",
    "    netG.apply(weights_init)\n",
    "    #     print(netG)\n",
    "    # summary(netG,(1,1,64))\n",
    "    \n",
    "    print(\"Number of GPUs used %s\"%(gdict['ngpu']))\n",
    "    if (gdict['multi-gpu']):\n",
    "        netG = nn.DataParallel(netG, list(range(gdict['ngpu'])))\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=gdict['learn_rate'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m20210223_210217_3dcgan_predict_0.8_m2\u001b[0m/  \u001b[01;34m20210225_074719_3dcgan_predict_0.8_m2\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## For single checkpoint\n",
    "# main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/'\n",
    "# fldr='20210119_134802_cgan_predict_0.65_m2'\n",
    "# param_label=1.1\n",
    "# op_loc=main_dir+fldr+'/images/'\n",
    "# ip_fname=main_dir+fldr+'/models/checkpoint_best_spec.tar'\n",
    "# f_gen_images(gdict,netG,optimizerG,param_label,ip_fname,op_loc,op_strg='inference_spec',op_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): Linear(in_features=65, out_features=32768, bias=True)\n",
       "    (1): BatchNorm3d(1, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): View()\n",
       "    (4): ConvTranspose3d(512, 256, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): ConvTranspose3d(256, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
       "    (8): BatchNorm3d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ConvTranspose3d(128, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
       "    (11): BatchNorm3d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): ConvTranspose3d(64, 1, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2), output_padding=(1, 1, 1), bias=False)\n",
       "    (14): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-0.5_epoch-13_step-17910.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-0.65_epoch-13_step-17910.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-0.8_epoch-13_step-17910.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-1.1_epoch-13_step-17910.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-0.5_epoch-14_step-20080.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-0.65_epoch-14_step-20080.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-0.8_epoch-14_step-20080.npy\n",
      "(100, 1, 64, 64, 64)\n",
      "Image saved in  inference_label-1.1_epoch-14_step-20080.npy\n"
     ]
    }
   ],
   "source": [
    "## For multiple checkpoints \n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/'\n",
    "fldr='20210225_074719_3dcgan_predict_0.8_m2'\n",
    "\n",
    "param_list=[0.5,0.65,0.8,1.1]\n",
    "op_loc=main_dir+fldr+'/images/'\n",
    "step_list=[17910, 20080]\n",
    "for step in step_list:\n",
    "    for param_label in param_list:\n",
    "    #     ip_fname=main_dir+fldr+'/models/checkpoint_{0}.tar'.format(step)\n",
    "    #     f_gen_images(gdict,netG,optimizerG,param_label,ip_fname,op_loc,op_strg='inference_spec',op_size=1000)\n",
    "        ip_fname=main_dir+fldr+'/models/checkpoint_{0}.tar'.format(step)\n",
    "        f_gen_images(gdict,netG,optimizerG,param_label,ip_fname,op_loc,op_strg='inference',op_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/'\n",
    "# fldr='20201220_073758_lambda2.0'\n",
    "# param_label=1.1\n",
    "# for step in [22010, 33550, 35970, 50810, 60320, 79050]:\n",
    "#     for count in range(2): # Repeat inference\n",
    "#         op_loc=main_dir+fldr+'/images/'\n",
    "#         ip_fname=main_dir+fldr+'/models/checkpoint_{0}.tar'.format(step)\n",
    "#         f_gen_images(gdict,netG,optimizerG,param_label,ip_fname,op_loc,op_strg='inference_%s'%(count),op_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname=op_loc+'inference_spec_epoch-11_step-37040.npy'\n",
    "# a1=np.load(fname)\n",
    "# print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
