{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test spectral and histogram loss for 3D images\n",
    "Jan 6, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## numpy code\n",
    "def f_radial_profile(data, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image '''\n",
    "    y, x = np.indices((data.shape)) # Get a grid of x and y values\n",
    "    \n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "        \n",
    "    # get radial values of every pair of points\n",
    "    r = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r = r.astype(np.int)\n",
    "    \n",
    "    # Compute histogram of r values\n",
    "    tbin = np.bincount(r.ravel(), data.ravel())\n",
    "    nr = np.bincount(r.ravel()) \n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile\n",
    "\n",
    "def f_compute_spectrum(arr):\n",
    "#     GLOBAL_MEAN=1.0\n",
    "#     arr=((arr - GLOBAL_MEAN)/GLOBAL_MEAN)\n",
    "    y1=np.fft.fft2(arr)\n",
    "    y1=np.fft.fftshift(y1)\n",
    "    y2=abs(y1)**2\n",
    "    z1=f_radial_profile(y2)\n",
    "    return(z1)\n",
    "   \n",
    "def f_compute_batch_spectrum(arr):\n",
    "    batch_pk=np.array([f_compute_spectrum(i) for i in arr])\n",
    "    return batch_pk\n",
    "\n",
    "\n",
    "### Code ###\n",
    "def f_image_spectrum(x):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    print(x.shape)\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    sdev=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "#         print(i,arr.shape)\n",
    "        batch_pk=f_compute_batch_spectrum(arr)\n",
    "#         print(batch_pk)\n",
    "        mean[i]=np.mean(batch_pk,axis=0)\n",
    "        sdev[i]=np.std(batch_pk,axis=0)\n",
    "    mean=np.array(mean)\n",
    "    sdev=np.array(sdev)\n",
    "    return mean,sdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Pytorch code ###\n",
    "####################\n",
    "\n",
    "def f_torch_radial_profile(img, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image \n",
    "    Bincount causes issues with backprop, so not using this code\n",
    "    '''\n",
    "    \n",
    "    y,x=torch.meshgrid(torch.arange(0,img.shape[0]),torch.arange(0,img.shape[1])) # Get a grid of x and y values\n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = torch.Tensor([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "\n",
    "    # get radial values of every pair of points\n",
    "    r = torch.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r= r.int()\n",
    "    \n",
    "#     print(r.shape,img.shape)\n",
    "    # Compute histogram of r values\n",
    "    tbin=torch.bincount(torch.reshape(r,(-1,)),weights=torch.reshape(img,(-1,)).type(torch.DoubleTensor))\n",
    "    nr = torch.bincount(torch.reshape(r,(-1,)))\n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile[1:-1]\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage_with_batch(image, center=None): ### Not used in this code.\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile. Only use if you need to combine batches\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, channel, height, width = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (batch, channel,-1)))\n",
    "    r_sorted = torch.gather(torch.reshape(r, (batch, channel, -1,)),2, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, (batch, channel, -1,)),2, ind)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[:,:,1:] - r_int[:,:,:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[2], (batch, -1))    # location of changes in radius\n",
    "    rind=torch.unsqueeze(rind,1)\n",
    "    nr = (rind[:,:,1:] - rind[:,:,:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "\n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "#     print(csum.shape,rind.shape,nr.shape)\n",
    "\n",
    "    tbin = torch.gather(csum, 2, rind[:,:,1:]) - torch.gather(csum, 2, rind[:,:,:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "def f_get_rad(img):\n",
    "    ''' Get the radial tensor for use in f_torch_get_azimuthalAverage '''\n",
    "    \n",
    "    height,width=img.shape[-2:]\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "    \n",
    "    center=[]\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "    \n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "    \n",
    "    return r.detach(),ind.detach()\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage(image,r,ind):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "#     height, width = image.shape\n",
    "#     # Create a grid of points with x and y coordinates\n",
    "#     y, x = np.indices([height,width])\n",
    "\n",
    "#     if not center:\n",
    "#         center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "#     # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "#     r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "#     # Get sorted radii\n",
    "#     ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "\n",
    "    r_sorted = torch.gather(torch.reshape(r, ( -1,)),0, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, ( -1,)),0, ind)\n",
    "    \n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[0], (-1,))    # location of changes in radius\n",
    "    nr = (rind[1:] - rind[:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    \n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    tbin = torch.gather(csum, 0, rind[1:]) - torch.gather(csum, 0, rind[:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "def f_torch_fftshift(real, imag):\n",
    "    for dim in range(0, len(real.size())):\n",
    "        real = torch.roll(real, dims=dim, shifts=real.size(dim)//2)\n",
    "        imag = torch.roll(imag, dims=dim, shifts=imag.size(dim)//2)\n",
    "    return real, imag\n",
    "\n",
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    y1=torch.rfft(arr,signal_ndim=2,onesided=False)\n",
    "    real,imag=f_torch_fftshift(y1[:,:,0],y1[:,:,1])    ## last index is real/imag part\n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    \n",
    "#     print(y2.shape)\n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    \n",
    "    return z1\n",
    "\n",
    "def f_torch_compute_batch_spectrum(arr,r,ind):\n",
    "    \n",
    "    batch_pk=torch.stack([f_torch_compute_spectrum(i,r,ind) for i in arr])\n",
    "    \n",
    "    return batch_pk\n",
    "\n",
    "def f_torch_image_spectrum(x,num_channels,r,ind):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    sdev=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "        batch_pk=f_torch_compute_batch_spectrum(arr,r,ind)\n",
    "        mean[i]=torch.mean(batch_pk,axis=0)\n",
    "#         sdev[i]=torch.std(batch_pk,axis=0)/np.sqrt(batch_pk.shape[0])\n",
    "#         sdev[i]=torch.std(batch_pk,axis=0)\n",
    "        sdev[i]=torch.var(batch_pk,axis=0)\n",
    "    \n",
    "    mean=torch.stack(mean)\n",
    "    sdev=torch.stack(sdev)\n",
    "        \n",
    "    return mean,sdev\n",
    "\n",
    "def f_compute_hist(data,bins):\n",
    "    \n",
    "    try: \n",
    "        hist_data=torch.histc(data,bins=bins)\n",
    "        ## A kind of normalization of histograms: divide by total sum\n",
    "        hist_data=(hist_data*bins)/torch.sum(hist_data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        hist_data=torch.zeros(bins)\n",
    "\n",
    "    return hist_data\n",
    "\n",
    "### Losses \n",
    "def loss_spectrum(spec_mean,spec_mean_ref,spec_std,spec_std_ref,image_size,lambda1):\n",
    "    ''' Loss function for the spectrum : mean + variance \n",
    "    Log(sum( batch value - expect value) ^ 2 )) '''\n",
    "    \n",
    "    idx=int(image_size/2) ### For the spectrum, use only N/2 indices for loss calc.\n",
    "    ### Warning: the first index is the channel number.For multiple channels, you are averaging over them, which is fine.\n",
    "        \n",
    "    spec_mean=torch.log(torch.mean(torch.pow(spec_mean[:,:idx]-spec_mean_ref[:,:idx],2)))\n",
    "    spec_sdev=torch.log(torch.mean(torch.pow(spec_std[:,:idx]-spec_std_ref[:,:idx],2)))\n",
    "    \n",
    "    lambda1=lambda1;\n",
    "    lambda2=lambda1;\n",
    "    ans=lambda1*spec_mean+lambda2*spec_sdev\n",
    "    \n",
    "    if torch.isnan(spec_sdev).any():    print(\"spec loss with nan\",ans)\n",
    "    \n",
    "    return ans\n",
    "    \n",
    "def loss_hist(hist_sample,hist_ref):\n",
    "    \n",
    "    lambda1=1.0\n",
    "    return lambda1*torch.log(torch.mean(torch.pow(hist_sample-hist_ref,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read input\n",
    "ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/3d_data/full_1.npy'\n",
    "img=np.load(ip_fname,mmap_mode='r')[:20].transpose(0,1,2,3)\n",
    "img=np.expand_dims(img,axis=1).astype(float)\n",
    "t_img=torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9749e+01, 1.4340e-01, 4.4575e-02, 2.1524e-02, 1.2398e-02, 7.7057e-03,\n",
       "        5.0068e-03, 3.5572e-03, 2.8324e-03, 2.2221e-03, 1.6308e-03, 1.2302e-03,\n",
       "        8.7738e-04, 8.6784e-04, 5.4359e-04, 4.3869e-04, 3.7193e-04, 3.4332e-04,\n",
       "        2.1935e-04, 2.1935e-04, 1.6212e-04, 1.4305e-04, 1.0490e-04, 7.6294e-05,\n",
       "        7.6294e-05, 8.5831e-05, 8.5831e-05, 6.6757e-05, 6.6757e-05, 0.0000e+00,\n",
       "        3.8147e-05, 9.5367e-06, 2.8610e-05, 1.9073e-05, 1.9073e-05, 3.8147e-05,\n",
       "        2.8610e-05, 3.8147e-05, 1.9073e-05, 9.5367e-06, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 9.5367e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 9.5367e-06], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_compute_hist(t_img,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.1213, 2.1213, 2.1213, 2.1213],\n",
      "         [1.5811, 1.5811, 1.5811, 1.5811],\n",
      "         [1.5811, 1.5811, 1.5811, 1.5811],\n",
      "         [2.1213, 2.1213, 2.1213, 2.1213]],\n",
      "\n",
      "        [[1.5811, 1.5811, 1.5811, 1.5811],\n",
      "         [0.7071, 0.7071, 0.7071, 0.7071],\n",
      "         [0.7071, 0.7071, 0.7071, 0.7071],\n",
      "         [1.5811, 1.5811, 1.5811, 1.5811]],\n",
      "\n",
      "        [[1.5811, 1.5811, 1.5811, 1.5811],\n",
      "         [0.7071, 0.7071, 0.7071, 0.7071],\n",
      "         [0.7071, 0.7071, 0.7071, 0.7071],\n",
      "         [1.5811, 1.5811, 1.5811, 1.5811]],\n",
      "\n",
      "        [[2.1213, 2.1213, 2.1213, 2.1213],\n",
      "         [1.5811, 1.5811, 1.5811, 1.5811],\n",
      "         [1.5811, 1.5811, 1.5811, 1.5811],\n",
      "         [2.1213, 2.1213, 2.1213, 2.1213]]], dtype=torch.float64)\n",
      "20 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[20, 1, -1]' is invalid for input of size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a0c864945c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mf_torch_get_azimuthalAverage_with_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a0c864945c83>\u001b[0m in \u001b[0;36mf_torch_get_azimuthalAverage_with_batch\u001b[0;34m(image, center)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Get sorted radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mr_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mi_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[20, 1, -1]' is invalid for input of size 64"
     ]
    }
   ],
   "source": [
    "def f_torch_get_azimuthalAverage_with_batch(image, center=None): ### Not used in this code.\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile. Only use if you need to combine batches\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, channel, height, width,depth = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    x,y,z = np.indices([height,width,depth])\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0,(z.max()-z.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1],z-center[2]))\n",
    "    \n",
    "    print(r)\n",
    "    # Get sorted radii\n",
    "    print(batch,channel)\n",
    "    ind = torch.argsort(torch.reshape(r, (batch, channel,-1)))\n",
    "    r_sorted = torch.gather(torch.reshape(r, (batch, channel, -1,)),2, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, (batch, channel, -1,)),2, ind)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[:,:,1:] - r_int[:,:,:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[2], (batch, -1))    # location of changes in radius\n",
    "    rind=torch.unsqueeze(rind,1)\n",
    "    nr = (rind[:,:,1:] - rind[:,:,:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "\n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "#     print(csum.shape,rind.shape,nr.shape)\n",
    "\n",
    "    tbin = torch.gather(csum, 2, rind[:,:,1:]) - torch.gather(csum, 2, rind[:,:,:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "f_torch_get_azimuthalAverage_with_batch(t_img[:,:,:4,:4,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "img=t_img[0,0,:,:,:]\n",
    "print(img.shape)\n",
    "r,ind=f_get_rad(t_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1=torch.rfft(t_img[0,0,:,:,:],signal_ndim=3,onesided=False)\n",
    "# y1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[44.5477, 43.8463, 43.1567,  ..., 43.1567, 43.8463, 44.5477],\n",
       "         [43.8463, 43.1335, 42.4323,  ..., 42.4323, 43.1335, 43.8463],\n",
       "         [43.1567, 42.4323, 41.7193,  ..., 41.7193, 42.4323, 43.1567],\n",
       "         ...,\n",
       "         [43.1567, 42.4323, 41.7193,  ..., 41.7193, 42.4323, 43.1567],\n",
       "         [43.8463, 43.1335, 42.4323,  ..., 42.4323, 43.1335, 43.8463],\n",
       "         [44.5477, 43.8463, 43.1567,  ..., 43.1567, 43.8463, 44.5477]],\n",
       "        dtype=torch.float64),\n",
       " tensor([2016, 2079, 2015,  ..., 4032,   63, 4095]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r,ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_torch_image_spectrum(t_img,1,r,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_torch_get_azimuthalAverage(image,r,ind):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "#     height, width = image.shape\n",
    "#     # Create a grid of points with x and y coordinates\n",
    "#     y, x = np.indices([height,width])\n",
    "\n",
    "#     if not center:\n",
    "#         center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "#     # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "#     r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "#     # Get sorted radii\n",
    "#     ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "\n",
    "    r_sorted = torch.gather(torch.reshape(r, ( -1,)),0, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, ( -1,)),0, ind)\n",
    "    \n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[0], (-1,))    # location of changes in radius\n",
    "    nr = (rind[1:] - rind[:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    \n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    tbin = torch.gather(csum, 0, rind[1:]) - torch.gather(csum, 0, rind[:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "def f_torch_fftshift(real, imag):\n",
    "    for dim in range(0, len(real.size())):\n",
    "        real = torch.roll(real, dims=dim, shifts=real.size(dim)//2)\n",
    "        imag = torch.roll(imag, dims=dim, shifts=imag.size(dim)//2)\n",
    "    return real, imag\n",
    "\n",
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    y1=torch.rfft(arr,signal_ndim=3,onesided=False)\n",
    "    print(y1.shape)\n",
    "    real,imag=f_torch_fftshift(y1[:,:,:,0],y1[:,:,:,1])    ## last index is real/imag part\n",
    "    print(real.shape,imag.shape)\n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    print(y2.shape)\n",
    "#     print(y2.shape)\n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    print(z1.shape)\n",
    "    return z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 64, 2])\n",
      "torch.Size([64, 64, 64]) torch.Size([64, 64, 64])\n",
      "torch.Size([64, 64, 64])\n",
      "torch.Size([43])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2508273.9225,  7070027.4958,  6802440.1899, 10405998.4226,\n",
       "        10110390.1638,  8101516.8540,  5885862.6172,  5022353.3353,\n",
       "         4669633.9063,  5994386.0244,  5980273.9324,  5358895.7123,\n",
       "         5097610.9158,  4571598.5829,  3101416.3273,  3909796.4399,\n",
       "         3754593.0063,  3764176.7559,  3314507.3260,  3643855.6688,\n",
       "         3397347.0271,  2734598.3531,  2899227.8991,  2708118.4934,\n",
       "         2183583.3825,  2235347.4285,  1958966.0722,  2510536.4087,\n",
       "         2259801.8579,  2138486.3777,  1844594.8609,  1890788.9211,\n",
       "         1733705.2404,  1583946.6509,  1464912.0189,  1459921.3987,\n",
       "         1524975.7922,  1520010.0394,   923301.4526,   780980.9213,\n",
       "          945995.0148,   696427.8134,  1537155.3631], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_torch_compute_spectrum(t_img[0,0,:,:,:],r,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 64]) torch.Size([262144])\n"
     ]
    }
   ],
   "source": [
    "def f_get_rad(img):\n",
    "    ''' Get the radial tensor for use in f_torch_get_azimuthalAverage '''\n",
    "    \n",
    "    height,width,depth=img.shape[-3:]\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    x, y, z = np.indices([height,width,depth])\n",
    "    \n",
    "    center=[]\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0, (z.max()-z.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1], z-center[2]))\n",
    "    \n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "    \n",
    "    return r.detach(),ind.detach()\n",
    "\n",
    "r,ind=f_get_rad(t_img)\n",
    "print(r.shape,ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.5477, dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0469977912076"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array([63,63,63])-np.array([0,0,0]))\n",
    "np.sqrt(63**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mCall signature:\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            ufunc\n",
       "\u001b[0;31mString form:\u001b[0m     <ufunc 'hypot'>\n",
       "\u001b[0;31mFile:\u001b[0m            ~/.conda/envs/v3/lib/python3.8/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      \n",
       "hypot(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n",
       "\n",
       "Given the \"legs\" of a right triangle, return its hypotenuse.\n",
       "\n",
       "Equivalent to ``sqrt(x1**2 + x2**2)``, element-wise.  If `x1` or\n",
       "`x2` is scalar_like (i.e., unambiguously cast-able to a scalar type),\n",
       "it is broadcast for use with each element of the other argument.\n",
       "(See Examples)\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x1, x2 : array_like\n",
       "    Leg of the triangle(s).\n",
       "    If ``x1.shape != x2.shape``, they must be broadcastable to a common\n",
       "    shape (which becomes the shape of the output).\n",
       "out : ndarray, None, or tuple of ndarray and None, optional\n",
       "    A location into which the result is stored. If provided, it must have\n",
       "    a shape that the inputs broadcast to. If not provided or None,\n",
       "    a freshly-allocated array is returned. A tuple (possible only as a\n",
       "    keyword argument) must have length equal to the number of outputs.\n",
       "where : array_like, optional\n",
       "    This condition is broadcast over the input. At locations where the\n",
       "    condition is True, the `out` array will be set to the ufunc result.\n",
       "    Elsewhere, the `out` array will retain its original value.\n",
       "    Note that if an uninitialized `out` array is created via the default\n",
       "    ``out=None``, locations within it where the condition is False will\n",
       "    remain uninitialized.\n",
       "**kwargs\n",
       "    For other keyword-only arguments, see the\n",
       "    :ref:`ufunc docs <ufuncs.kwargs>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "z : ndarray\n",
       "    The hypotenuse of the triangle(s).\n",
       "    This is a scalar if both `x1` and `x2` are scalars.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> np.hypot(3*np.ones((3, 3)), 4*np.ones((3, 3)))\n",
       "array([[ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.]])\n",
       "\n",
       "Example showing broadcast of scalar_like argument:\n",
       "\n",
       ">>> np.hypot(3*np.ones((3, 3)), [4])\n",
       "array([[ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.]])\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Functions that operate element by element on whole arrays.\n",
       "\n",
       "To see the documentation for a specific ufunc, use `info`.  For\n",
       "example, ``np.info(np.sin)``.  Because ufuncs are written in C\n",
       "(for speed) and linked into Python with NumPy's ufunc facility,\n",
       "Python's help() function finds this page whenever help() is called\n",
       "on a ufunc.\n",
       "\n",
       "A detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.\n",
       "\n",
       "Calling ufuncs:\n",
       "===============\n",
       "\n",
       "op(*x[, out], where=True, **kwargs)\n",
       "Apply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n",
       "\n",
       "The broadcasting rules are:\n",
       "\n",
       "* Dimensions of length 1 may be prepended to either array.\n",
       "* Arrays may be repeated along dimensions of length 1.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*x : array_like\n",
       "    Input arrays.\n",
       "out : ndarray, None, or tuple of ndarray and None, optional\n",
       "    Alternate array object(s) in which to put the result; if provided, it\n",
       "    must have a shape that the inputs broadcast to. A tuple of arrays\n",
       "    (possible only as a keyword argument) must have length equal to the\n",
       "    number of outputs; use None for uninitialized outputs to be\n",
       "    allocated by the ufunc.\n",
       "where : array_like, optional\n",
       "    This condition is broadcast over the input. At locations where the\n",
       "    condition is True, the `out` array will be set to the ufunc result.\n",
       "    Elsewhere, the `out` array will retain its original value.\n",
       "    Note that if an uninitialized `out` array is created via the default\n",
       "    ``out=None``, locations within it where the condition is False will\n",
       "    remain uninitialized.\n",
       "**kwargs\n",
       "    For other keyword-only arguments, see the :ref:`ufunc docs <ufuncs.kwargs>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "r : ndarray or tuple of ndarray\n",
       "    `r` will have the shape that the arrays in `x` broadcast to; if `out` is\n",
       "    provided, it will be returned. If not, `r` will be allocated and\n",
       "    may contain uninitialized values. If the function has more than one\n",
       "    output, then the result will be a tuple of arrays.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? np.hypot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
