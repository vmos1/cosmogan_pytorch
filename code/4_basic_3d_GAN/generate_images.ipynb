{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images 3D\n",
    "Jan 22, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/4_basic_3d_GAN/1_main_code/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_load_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    return config\n",
    "\n",
    "def f_init_gdict(gdict,config_dict):\n",
    "    ''' Initialize the global dictionary gdict with values in config file'''\n",
    "    keys1=['workers','nc','nz','ngf','ndf','beta1','kernel_size','stride','g_padding','d_padding','flip_prob']\n",
    "    keys2=['image_size','checkpoint_size','num_imgs','ip_fname','op_loc']\n",
    "    for key in keys1: gdict[key]=config_dict['training'][key]\n",
    "    for key in keys2: gdict[key]=config_dict['data'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inf_img_',op_size=500):\n",
    "    '''Generate images for best saved models\n",
    "     Arguments: gdict, netG, optimizerG, \n",
    "                 ip_fname: name of input file\n",
    "                op_strg: [string name for output file]\n",
    "                op_size: Number of images to generate\n",
    "    '''\n",
    "\n",
    "    nz,device=gdict['nz'],gdict['device']\n",
    "\n",
    "    try:\n",
    "        if torch.cuda.is_available(): checkpoint=torch.load(ip_fname)\n",
    "        else: checkpoint=torch.load(ip_fname,map_location=torch.device('cpu'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        return\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "    \n",
    "    ## Load other stuff\n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(op_size, 1, 1, 1, nz, device=device)\n",
    "    # Generate fake image batch with G\n",
    "    netG.eval() ## This is required before running inference\n",
    "    gen = netG(noise)\n",
    "    gen_images=gen.detach().cpu().numpy()\n",
    "    print(gen_images.shape)\n",
    "    \n",
    "    op_fname='%s_epoch-%s_step-%s.npy'%(op_strg,epoch,iters)\n",
    "\n",
    "    np.save(op_loc+op_fname,gen_images)\n",
    "\n",
    "    print(\"Image saved in \",op_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GAN networks\n",
      "Number of GPUs used 0\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    t0=time.time()\n",
    "    #################################\n",
    "#     args=f_parse_args()\n",
    "    # Manually add args ( different for jupyter notebook)\n",
    "    args=argparse.Namespace()\n",
    "    args.config='1_main_code/config_3d.yaml'\n",
    "    args.ngpu=1\n",
    "    args.batchsize=128\n",
    "#     args.spec_loss_flag=True\n",
    "#     args.checkpoint_size=50\n",
    "    args.epochs=1\n",
    "    args.learn_rate=0.0002\n",
    "#     args.mode='fresh'\n",
    "#     args.run_suffix='_nb_test'\n",
    "#     args.deterministic=False\n",
    "#     args.seed='36723705'\n",
    "#     args.lambda1=5.0\n",
    "#     args.save_steps_list=[5,10]\n",
    "\n",
    "    ### Set up ###\n",
    "    config_file=args.config\n",
    "    config_dict=f_load_config(config_file)\n",
    "\n",
    "    # Initilize variables    \n",
    "    gdict={}\n",
    "    f_init_gdict(gdict,config_dict)\n",
    "    \n",
    "    ## Add args variables to gdict\n",
    "    for key in ['ngpu','batchsize','epochs','learn_rate']:\n",
    "        gdict[key]=vars(args)[key]\n",
    "    \n",
    "    gdict['device']=torch.device(\"cuda\" if (torch.cuda.is_available() and gdict['ngpu'] > 0) else \"cpu\")\n",
    "    gdict['ngpu']=torch.cuda.device_count()\n",
    "    gdict['multi-gpu']=True if (gdict['device'].type == 'cuda') and (gdict['ngpu'] > 1) else False \n",
    "\n",
    "    print(\"Building GAN networks\")\n",
    "    # Create Generator\n",
    "    netG = Generator(gdict).to(gdict['device'])\n",
    "    netG.apply(weights_init)\n",
    "    #     print(netG)\n",
    "    # summary(netG,(1,1,64))\n",
    "    \n",
    "    print(\"Number of GPUs used %s\"%(gdict['ngpu']))\n",
    "    if (gdict['multi-gpu']):\n",
    "        netG = nn.DataParallel(netG, list(range(gdict['ngpu'])))\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=gdict['learn_rate'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m20210223_210217_3dcgan_predict_0.8_m2\u001b[0m/  \u001b[01;34m20210227_050213_3dcgan_predict_0.65_m2\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210121_133144_3d_l0.5/models/checkpoint_22010.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210121_133144_3d_l0.5/models/checkpoint_22010.tar\n"
     ]
    }
   ],
   "source": [
    "# main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/'\n",
    "# fldr='20210227_050213_3dcgan_predict_0.65_m2'\n",
    "# op_loc=main_dir+fldr+'/images/'\n",
    "# ip_fname=main_dir+fldr+'/models/checkpoint_22010.tar'\n",
    "# f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inference_spec',op_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_27600.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_27600.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_27600.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_27600.tar\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  30950\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  30950\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  42620\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  42620\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  43830\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  43830\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  50440\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  50440\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  58320\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  58320\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  58330\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  58330\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_59500.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_59500.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_59500.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_59500.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_64670.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_64670.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_64670.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/20210227_050213_3dcgan_predict_0.65_m2/models/checkpoint_64670.tar\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  65600\n",
      "Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for main.0.weight: copying a param with shape torch.Size([32768, 65]) from checkpoint, the shape in current model is torch.Size([32768, 64]).\n",
      "skipping  65600\n"
     ]
    }
   ],
   "source": [
    "## For multiple steps \n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/'\n",
    "fldr='20210227_050213_3dcgan_predict_0.65_m2'\n",
    "\n",
    "step_list=[27600, 30950, 42620, 43830, 50440, 58320, 58330, 59500, 64670,65600]\n",
    "for step in step_list:\n",
    "    for count in range(2): # Repeat inference\n",
    "        try: \n",
    "            op_loc=main_dir+fldr+'/images/'\n",
    "            ip_fname=main_dir+fldr+'/models/checkpoint_{0}.tar'.format(step)\n",
    "            f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inference_%s'%(count),op_size=1000)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"skipping \",step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname=op_loc+'inference_spec_epoch-11_step-37040.npy'\n",
    "# a1=np.load(fname)\n",
    "# print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
