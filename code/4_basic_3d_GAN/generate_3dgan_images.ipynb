{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images 3D\n",
    "Jan 22, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/4_basic_3d_GAN/1_main_code/DDP/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_load_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    return config\n",
    "\n",
    "# def f_init_gdict(gdict,config_dict):\n",
    "#     ''' Initialize the global dictionary gdict with values in config file'''\n",
    "#     keys1=['workers','nc','nz','ngf','ndf','beta1','kernel_size','stride','g_padding','d_padding','flip_prob']\n",
    "#     keys2=['image_size','checkpoint_size','num_imgs','ip_fname','op_loc']\n",
    "#     for key in keys1: gdict[key]=config_dict['training'][key]\n",
    "#     for key in keys2: gdict[key]=config_dict['data'][key]\n",
    "        \n",
    "        \n",
    "def f_manual_add_argparse():\n",
    "    ''' use only in jpt notebook'''\n",
    "    args=argparse.Namespace()\n",
    "    args.config='config_3dgan.yaml'\n",
    "    args.mode='fresh'\n",
    "    args.ip_fldr=''\n",
    "#     args.local_rank=0\n",
    "    args.facility='cori'\n",
    "    args.distributed=False\n",
    "#     args.mode='continue'\n",
    "#     args.ip_fldr='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20201211_093818_nb_test/'\n",
    "    \n",
    "    return args\n",
    "        \n",
    "# def f_init_gdict(gdict,config_file):\n",
    "#     ''' Create global dictionary gdict from args and config file'''\n",
    "    \n",
    "#     ## read config file\n",
    "#     with open(config_file) as f:\n",
    "#         config_dict= yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        \n",
    "#     gdict=config_dict['parameters']\n",
    "    \n",
    "#     args_dict=vars(args)\n",
    "#     ## Add args variables to gdict\n",
    "#     for key in args_dict.keys():\n",
    "#         gdict[key]=args_dict[key]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def f_init_gdict(args,gdict):\n",
    "    ''' Create global dictionary gdict from args and config file'''\n",
    "    \n",
    "    ## read config file\n",
    "    config_file=args.config\n",
    "    with open(config_file) as f:\n",
    "        config_dict= yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        \n",
    "    gdict=config_dict['parameters']\n",
    "\n",
    "    args_dict=vars(args)\n",
    "    ## Add args variables to gdict\n",
    "    for key in args_dict.keys():\n",
    "        gdict[key]=args_dict[key]\n",
    "    return gdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inf_img_',op_size=500):\n",
    "    '''Generate images for best saved models\n",
    "     Arguments: gdict, netG, optimizerG, \n",
    "                 ip_fname: name of input file\n",
    "                op_strg: [string name for output file]\n",
    "                op_size: Number of images to generate\n",
    "    '''\n",
    "\n",
    "    nz,device=gdict['nz'],gdict['device']\n",
    "\n",
    "    try:# handling cpu vs gpu\n",
    "        if torch.cuda.is_available(): checkpoint=torch.load(ip_fname)\n",
    "        else: checkpoint=torch.load(ip_fname,map_location=torch.device('cpu'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        return\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "    \n",
    "    ## Load other stuff\n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(op_size, 1, 1, 1, nz, device=device)\n",
    "    # Generate fake image batch with G\n",
    "    netG.eval() ## This is required before running inference\n",
    "    with torch.no_grad(): ## This is important. fails without it for multi-gpu\n",
    "        gen = netG(noise)\n",
    "        gen_images=gen.detach().cpu().numpy()\n",
    "        print(gen_images.shape)\n",
    "    \n",
    "    op_fname='%s_epoch-%s_step-%s.npy'%(op_strg,epoch,iters)\n",
    "    np.save(op_loc+op_fname,gen_images)\n",
    "\n",
    "    print(\"Image saved in \",op_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ip_fname': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/raw_data/3d_data/64cube/dataset1_smoothing_const_params_64cube_100k/norm_1_train_val.npy',\n",
       " 'op_loc': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/results_pytorch/3d/',\n",
       " 'image_size': 64,\n",
       " 'num_imgs': 90000,\n",
       " 'workers': 2,\n",
       " 'nc': 1,\n",
       " 'nz': 64,\n",
       " 'ngf': 64,\n",
       " 'ndf': 64,\n",
       " 'beta1': 0.5,\n",
       " 'kernel_size': 5,\n",
       " 'stride': 2,\n",
       " 'g_padding': 2,\n",
       " 'd_padding': 2,\n",
       " 'flip_prob': 0.01,\n",
       " 'bns': 50,\n",
       " 'checkpoint_size': 1,\n",
       " 'batch_size': 8,\n",
       " 'epochs': 1,\n",
       " 'learn_rate': 0.0002,\n",
       " 'op_size': 32,\n",
       " 'deterministic': False,\n",
       " 'seed': 234373,\n",
       " 'lambda_spec_mean': 0.1,\n",
       " 'lambda_spec_var': 0.1,\n",
       " 'lambda_fm': 0.0,\n",
       " 'lambda_gp': 0.0,\n",
       " 'grad_clip': 1.0,\n",
       " 'save_steps_list': [5, 10],\n",
       " 'run_suffix': 'bs8_lr0.0001_nodes8',\n",
       " 'description': '3d GAN: DDP with new loss',\n",
       " 'config': '1_main_code/DDP/config_3dgan_summit.yaml',\n",
       " 'ngpu': 0,\n",
       " 'batchsize': 128,\n",
       " 'device': device(type='cpu'),\n",
       " 'multi-gpu': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ip_fname': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/raw_data/3d_data/64cube/dataset1_smoothing_const_params_64cube_100k/norm_1_train_val.npy', 'op_loc': '/gpfs/alpine/ast153/proj-shared/venkitesh/Cosmogan/data/results_pytorch/3d/', 'image_size': 64, 'num_imgs': 90000, 'workers': 2, 'nc': 1, 'nz': 64, 'ngf': 64, 'ndf': 64, 'beta1': 0.5, 'kernel_size': 5, 'stride': 2, 'g_padding': 2, 'd_padding': 2, 'flip_prob': 0.01, 'bns': 50, 'checkpoint_size': 1, 'batch_size': 8, 'epochs': 1, 'learn_rate': 0.0001, 'op_size': 32, 'deterministic': False, 'seed': 234373, 'lambda_spec_mean': 0.1, 'lambda_spec_var': 0.1, 'lambda_fm': 0.0, 'lambda_gp': 0.0, 'grad_clip': 1.0, 'save_steps_list': [5, 10], 'run_suffix': 'bs8_lr0.0001_nodes8', 'description': '3d GAN: DDP with new loss', 'config': '1_main_code/DDP/config_3dgan_summit.yaml', 'ngpu': 1, 'batchsize': 128}\n",
      "Building GAN networks\n",
      "Number of GPUs used 0\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    t0=time.time()\n",
    "    #################################\n",
    "    f_manual_add_argparse()\n",
    "    ### Set up ###\n",
    "\n",
    "    # Initilize variables    \n",
    "    gdict={}\n",
    "    gdict=f_init_gdict(args,gdict)\n",
    "    print(gdict)\n",
    "    ## Add args variables to gdict\n",
    "    for key in ['ngpu']:\n",
    "        gdict[key]=vars(args)[key]\n",
    "    gdict['device']=torch.device(\"cuda\" if (torch.cuda.is_available() and gdict['ngpu'] > 0) else \"cpu\")\n",
    "    gdict['ngpu']=torch.cuda.device_count()\n",
    "    gdict['multi-gpu']=True if (gdict['device'].type == 'cuda') and (gdict['ngpu'] > 1) else False \n",
    "\n",
    "    print(\"Building GAN networks\")\n",
    "    # Create Generator\n",
    "    netG = Generator(gdict).to(gdict['device'])\n",
    "    netG.apply(weights_init)\n",
    "    #     print(netG)\n",
    "    # summary(netG,(1,1,64))\n",
    "    \n",
    "    print(\"Number of GPUs used %s\"%(gdict['ngpu']))\n",
    "    if (gdict['multi-gpu']):\n",
    "        netG = nn.DataParallel(netG, list(range(gdict['ngpu'])))\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=gdict['learn_rate'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m20210122_061039_3d_l0.1_80k\u001b[0m/\n",
      "\u001b[01;34m20210123_050147_3d_l0.5_80k\u001b[0m/\n",
      "\u001b[01;34m20210123_050147_3d_l2.0_80k\u001b[0m/\n",
      "\u001b[01;34m20210128_200536_3d_l0.5_80k\u001b[0m/\n",
      "\u001b[01;34m20210421_135443_bs64_lr0.0002_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210422_123705_bs4_lr0.00004_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210422_125528_bs8_lr0.00004_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210422_73038_bs64_lr0.00008_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210422_92518_bs32_lr0.00004_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210422_92953_bs64_lr0.00004_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210426_83932_bs8_lr0.0002_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210426_85259_bs8_lr0.0008_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210426_85502_bs8_lr0.0016_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210427_103955_bs8_lr0.0001_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210427_105753_bs8_lr0.001_nodes8_spec10.0\u001b[0m/\n",
      "\u001b[01;34m20210427_134632_bs8_lr0.0003_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210427_140553_bs16_lr0.0003_nodes8\u001b[0m/\n",
      "\u001b[01;34m20210428_62843_bs8_lr0.0003_nodes8\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210121_133144_3d_l0.5/models/checkpoint_22010.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210121_133144_3d_l0.5/models/checkpoint_22010.tar\n"
     ]
    }
   ],
   "source": [
    "# main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d_cGAN/'\n",
    "# fldr='20210227_050213_3dcgan_predict_0.65_m2'\n",
    "# op_loc=main_dir+fldr+'/images/'\n",
    "# ip_fname=main_dir+fldr+'/models/checkpoint_22010.tar'\n",
    "# f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inference_spec',op_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_10560.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_10560.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_10560.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_10560.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_11600.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_11600.tar\n",
      "[Errno 2] No such file or directory: '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_11600.tar'\n",
      "skipping generation of images for  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/20210427_103955_bs8_lr0.0001_nodes8/models/checkpoint_11600.tar\n"
     ]
    }
   ],
   "source": [
    "## For multiple steps \n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/3d/'\n",
    "fldr='20210227_050213_3dcgan_predict_0.65_m2'\n",
    "\n",
    "step_list=[27600, 30950, 42620, 43830, 50440, 58320, 58330, 59500, 64670,65600]\n",
    "for step in step_list:\n",
    "    for count in range(2): # Repeat inference\n",
    "        try: \n",
    "            op_loc=main_dir+fldr+'/images/'\n",
    "            ip_fname=main_dir+fldr+'/models/checkpoint_{0}.tar'.format(step)\n",
    "            f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inference_%s'%(count),op_size=1000)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"skipping \",step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname=op_loc+'inference_spec_epoch-11_step-37040.npy'\n",
    "# a1=np.load(fname)\n",
    "# print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
