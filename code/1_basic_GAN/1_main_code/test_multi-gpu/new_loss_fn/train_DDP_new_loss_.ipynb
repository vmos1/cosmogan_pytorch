{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing cosmogan\n",
    "Aug 25, 2020\n",
    "\n",
    "Borrowing pieces of code from : \n",
    "\n",
    "- https://github.com/pytorch/tutorials/blob/11569e0db3599ac214b03e01956c2971b02c64ce/beginner_source/dcgan_faces_tutorial.py\n",
    "- https://github.com/exalearn/epiCorvid/tree/master/cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "#from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "# import torch.fft\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections\n",
    "import socket\n",
    "import shutil\n",
    "\n",
    "# # Import modules from other files\n",
    "# from utils import *\n",
    "# from spec_loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4.) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s)\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        \n",
    "# Generator Code\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, gdict):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        ## Define new variables from dict\n",
    "        keys=['ngpu','nz','nc','ngf','kernel_size','stride','g_padding']\n",
    "        ngpu, nz,nc,ngf,kernel_size,stride,g_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "            nn.Linear(nz,nc*ngf*8*8*8),# 32768\n",
    "            nn.BatchNorm2d(nc,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            View(shape=[-1,ngf*8,8,8]),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, kernel_size, stride, g_padding, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, kernel_size, stride, g_padding, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, kernel_size, stride, g_padding, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, kernel_size, stride,g_padding, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, ip):\n",
    "        return self.main(ip)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, gdict):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        ## Define new variables from dict\n",
    "        keys=['ngpu','nz','nc','ndf','kernel_size','stride','d_padding']\n",
    "        ngpu, nz,nc,ndf,kernel_size,stride,d_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())        \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            # nn.Conv2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "            nn.Conv2d(nc, ndf,kernel_size, stride, d_padding,  bias=True),\n",
    "            nn.BatchNorm2d(ndf,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size, stride, d_padding, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 2,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size, stride, d_padding, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 4,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size, stride, d_padding, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nc*ndf*8*8*8, 1)\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, ip):\n",
    "#         print(ip.shape)\n",
    "        results=[ip]\n",
    "        lst_idx=[]\n",
    "        for i,submodel in enumerate(self.main.children()):\n",
    "            mid_output=submodel(results[-1])\n",
    "            results.append(mid_output)\n",
    "            ## Select indices in list corresponding to output of Conv layers\n",
    "            if submodel.__class__.__name__.startswith('Conv'):\n",
    "#                 print(submodel.__class__.__name__)\n",
    "#                 print(mid_output.shape)\n",
    "                lst_idx.append(i)\n",
    "\n",
    "        FMloss=True\n",
    "        if FMloss:\n",
    "            ans=[results[1:][i] for i in lst_idx + [-1]]\n",
    "        else :\n",
    "            ans=results[-1]\n",
    "        return ans\n",
    "\n",
    "def f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inf_img_',op_size=500):\n",
    "    '''Generate images for best saved models\n",
    "     Arguments: gdict, netG, optimizerG, \n",
    "                 ip_fname: name of input file\n",
    "                op_strg: [string name for output file]\n",
    "                op_size: Number of images to generate\n",
    "    '''\n",
    "\n",
    "    nz,device=gdict['nz'],gdict['device']\n",
    "\n",
    "    try:# handling cpu vs gpu\n",
    "        if torch.cuda.is_available(): checkpoint=torch.load(ip_fname)\n",
    "        else: checkpoint=torch.load(ip_fname,map_location=torch.device('cpu'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        return\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "    \n",
    "    ## Load other stuff\n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(op_size, 1, 1, nz, device=device)\n",
    "    # Generate fake image batch with G\n",
    "    netG.eval() ## This is required before running inference\n",
    "    with torch.no_grad(): ## This is important. fails without it for multi-gpu\n",
    "        gen = netG(noise)\n",
    "        gen_images=gen.detach().cpu().numpy()[:,:,:,:]\n",
    "        print(gen_images.shape)\n",
    "    \n",
    "    op_fname='%s_epoch-%s_step-%s.npy'%(op_strg,epoch,iters)\n",
    "    np.save(op_loc+op_fname,gen_images)\n",
    "\n",
    "    print(\"Image saved in \",op_fname)\n",
    "    \n",
    "def f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,netG,netD,optimizerG,optimizerD,save_loc):\n",
    "    ''' Checkpoint model '''\n",
    "    \n",
    "    if gdict['multi-gpu']: ## Dataparallel\n",
    "        torch.save({'epoch':epoch,'iters':iters,'best_chi1':best_chi1,'best_chi2':best_chi2,\n",
    "                'G_state':netG.module.state_dict(),'D_state':netD.module.state_dict(),'optimizerG_state_dict':optimizerG.state_dict(),\n",
    "                'optimizerD_state_dict':optimizerD.state_dict()}, save_loc) \n",
    "    else :\n",
    "        torch.save({'epoch':epoch,'iters':iters,'best_chi1':best_chi1,'best_chi2':best_chi2,\n",
    "                'G_state':netG.state_dict(),'D_state':netD.state_dict(),'optimizerG_state_dict':optimizerG.state_dict(),\n",
    "                'optimizerD_state_dict':optimizerD.state_dict()}, save_loc)\n",
    "    \n",
    "def f_load_checkpoint(ip_fname,netG,netD,optimizerG,optimizerD,gdict):\n",
    "    ''' Load saved checkpoint\n",
    "    Also loads step, epoch, best_chi1, best_chi2'''\n",
    "    \n",
    "    try:\n",
    "        checkpoint=torch.load(ip_fname)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        raise SystemError\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "        netD.module.load_state_dict(checkpoint['D_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "        netD.load_state_dict(checkpoint['D_state'])\n",
    "    \n",
    "    optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    best_chi1=checkpoint['best_chi1']\n",
    "    best_chi2=checkpoint['best_chi2']\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    \n",
    "    return iters,epoch,best_chi1,best_chi2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Pytorch code ###\n",
    "####################\n",
    "\n",
    "def f_torch_radial_profile(img, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image \n",
    "    Bincount causes issues with backprop, so not using this code\n",
    "    '''\n",
    "    \n",
    "    y,x=torch.meshgrid(torch.arange(0,img.shape[0]),torch.arange(0,img.shape[1])) # Get a grid of x and y values\n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = torch.Tensor([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "\n",
    "    # get radial values of every pair of points\n",
    "    r = torch.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r= r.int()\n",
    "    \n",
    "#     print(r.shape,img.shape)\n",
    "    # Compute histogram of r values\n",
    "    tbin=torch.bincount(torch.reshape(r,(-1,)),weights=torch.reshape(img,(-1,)).type(torch.DoubleTensor))\n",
    "    nr = torch.bincount(torch.reshape(r,(-1,)))\n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile[1:-1]\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage_with_batch(image, center=None): ### Not used in this code.\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile. Only use if you need to combine batches\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, channel, height, width = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (batch, channel,-1)))\n",
    "    r_sorted = torch.gather(torch.reshape(r, (batch, channel, -1,)),2, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, (batch, channel, -1,)),2, ind)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[:,:,1:] - r_int[:,:,:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[2], (batch, -1))    # location of changes in radius\n",
    "    rind=torch.unsqueeze(rind,1)\n",
    "    nr = (rind[:,:,1:] - rind[:,:,:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "\n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "#     print(csum.shape,rind.shape,nr.shape)\n",
    "\n",
    "    tbin = torch.gather(csum, 2, rind[:,:,1:]) - torch.gather(csum, 2, rind[:,:,:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "def f_get_rad(img):\n",
    "    ''' Get the radial tensor for use in f_torch_get_azimuthalAverage '''\n",
    "    \n",
    "    height,width=img.shape[-2:]\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "    \n",
    "    center=[]\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "    \n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "    \n",
    "    return r.detach(),ind.detach()\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage(image,r,ind):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "#     height, width = image.shape\n",
    "#     # Create a grid of points with x and y coordinates\n",
    "#     y, x = np.indices([height,width])\n",
    "\n",
    "#     if not center:\n",
    "#         center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "#     # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "#     r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "#     # Get sorted radii\n",
    "#     ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "\n",
    "    r_sorted = torch.gather(torch.reshape(r, ( -1,)),0, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, ( -1,)),0, ind)\n",
    "    \n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[0], (-1,))    # location of changes in radius\n",
    "    nr = (rind[1:] - rind[:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    \n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    tbin = torch.gather(csum, 0, rind[1:]) - torch.gather(csum, 0, rind[:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "def f_torch_fftshift(real, imag):\n",
    "    for dim in range(0, len(real.size())):\n",
    "        real = torch.roll(real, dims=dim, shifts=real.size(dim)//2)\n",
    "        imag = torch.roll(imag, dims=dim, shifts=imag.size(dim)//2)\n",
    "    return real, imag\n",
    "\n",
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    y1=torch.rfft(arr,signal_ndim=2,onesided=False)\n",
    "    real,imag=f_torch_fftshift(y1[:,:,0],y1[:,:,1])    ## last index is real/imag part\n",
    "    \n",
    "#     y1=torch.fft.fftn(arr,dim=(-2,-1))\n",
    "#     real,imag=f_torch_fftshift(y1.real,y1.imag)\n",
    "    \n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    \n",
    "#     print(y2.shape)\n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    \n",
    "    return z1\n",
    "\n",
    "def f_torch_compute_batch_spectrum(arr,r,ind):\n",
    "    \n",
    "    batch_pk=torch.stack([f_torch_compute_spectrum(i,r,ind) for i in arr])\n",
    "    \n",
    "    return batch_pk\n",
    "\n",
    "def f_torch_image_spectrum(x,num_channels,r,ind):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    sdev=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "        batch_pk=f_torch_compute_batch_spectrum(arr,r,ind)\n",
    "        mean[i]=torch.mean(batch_pk,axis=0)\n",
    "#         sdev[i]=torch.std(batch_pk,axis=0)/np.sqrt(batch_pk.shape[0])\n",
    "#         sdev[i]=torch.std(batch_pk,axis=0)\n",
    "        sdev[i]=torch.var(batch_pk,axis=0)\n",
    "    \n",
    "    mean=torch.stack(mean)\n",
    "    sdev=torch.stack(sdev)\n",
    "        \n",
    "    return mean,sdev\n",
    "\n",
    "def f_compute_hist(data,bins):\n",
    "    \n",
    "    try: \n",
    "        hist_data=torch.histc(data,bins=bins)\n",
    "        ## A kind of normalization of histograms: divide by total sum\n",
    "        hist_data=(hist_data*bins)/torch.sum(hist_data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        hist_data=torch.zeros(bins)\n",
    "\n",
    "    return hist_data\n",
    "\n",
    "### Losses \n",
    "def loss_spectrum(spec_mean,spec_mean_ref,spec_std,spec_std_ref,image_size,lambda_spec_mean,lambda_spec_var):\n",
    "    ''' Loss function for the spectrum : mean + variance \n",
    "    Log(sum( batch value - expect value) ^ 2 )) '''\n",
    "    \n",
    "    idx=int(image_size/2) ### For the spectrum, use only N/2 indices for loss calc.\n",
    "    ### Warning: the first index is the channel number.For multiple channels, you are averaging over them, which is fine.\n",
    "        \n",
    "    spec_mean=torch.log(torch.mean(torch.pow(spec_mean[:,:idx]-spec_mean_ref[:,:idx],2)))\n",
    "    spec_sdev=torch.log(torch.mean(torch.pow(spec_std[:,:idx]-spec_std_ref[:,:idx],2)))\n",
    "    \n",
    "    lambda1=lambda_spec_mean;\n",
    "    lambda2=lambda_spec_var;\n",
    "    ans=lambda1*spec_mean+lambda2*spec_sdev\n",
    "    \n",
    "    if torch.isnan(spec_sdev).any():    print(\"spec loss with nan\",ans)\n",
    "    \n",
    "    return ans\n",
    "    \n",
    "def loss_hist(hist_sample,hist_ref):\n",
    "    \n",
    "    lambda1=1.0\n",
    "    return lambda1*torch.log(torch.mean(torch.pow(hist_sample-hist_ref,2)))\n",
    "\n",
    "def f_FM_loss(real_output,fake_output,lambda_fm,gdict):\n",
    "    '''\n",
    "    Module to implement Feature-Matching loss. Reads all but last elements of Discriminator ouput\n",
    "    '''\n",
    "    FM=torch.Tensor([0.0]).to(gdict['device'])\n",
    "    for i,j in zip(real_output[:-1][0],fake_output[:-1][0]):\n",
    "        real_mean=torch.mean(i)\n",
    "        fake_mean=torch.mean(j)\n",
    "        FM=FM.clone()+torch.sum(torch.square(real_mean-fake_mean))\n",
    "    return lambda_fm*FM\n",
    "\n",
    "def f_gp_loss(grads,l=1.0):\n",
    "    '''\n",
    "    Module to implement gradient penalty loss.\n",
    "    '''\n",
    "    loss=torch.mean(torch.sum(torch.square(grads),dim=[1,2,3]))\n",
    "    return l*loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Train code ###\n",
    "def f_train_loop(dataloader,metrics_df,gdict,fixed_noise,mean_spec_val,sdev_spec_val,hist_val,r,ind):\n",
    "    ''' Train single epoch '''\n",
    "    print(\"Inside train loop\")\n",
    "\n",
    "    ## Define new variables from dict\n",
    "    keys=['image_size','start_epoch','epochs','iters','best_chi1','best_chi2','save_dir','device','flip_prob','nz','batch_size','bns']\n",
    "    image_size,start_epoch,epochs,iters,best_chi1,best_chi2,save_dir,device,flip_prob,nz,batchsize,bns=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "    for epoch in range(start_epoch,epochs):\n",
    "        t_epoch_start=time.time()\n",
    "        for count, data in enumerate(dataloader):\n",
    "\n",
    "            ####### Train GAN ########\n",
    "            netG.train(); netD.train();  ### Need to add these after inference and before training\n",
    "\n",
    "            tme1=time.time()\n",
    "            ### Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            netD.zero_grad()\n",
    "\n",
    "            real_cpu = data[0].to(device)\n",
    "            real_cpu.requires_grad=True\n",
    "            b_size = real_cpu.size(0)\n",
    "            real_label = torch.full((b_size,), 1, device=device,dtype=float)\n",
    "            fake_label = torch.full((b_size,), 0, device=device,dtype=float)\n",
    "            g_label = torch.full((b_size,), 1, device=device,dtype=float) ## No flipping for Generator labels\n",
    "            # Flip labels with probability flip_prob\n",
    "            for idx in np.random.choice(np.arange(b_size),size=int(np.ceil(b_size*flip_prob))):\n",
    "                real_label[idx]=0; fake_label[idx]=1\n",
    "\n",
    "            # Generate fake image batch with G\n",
    "            noise = torch.randn(b_size, 1, 1, nz, device=device)\n",
    "            fake = netG(noise)            \n",
    "\n",
    "            # Forward pass real batch through D\n",
    "            real_output = netD(real_cpu)\n",
    "            errD_real = criterion(real_output[-1].view(-1), real_label.float())\n",
    "            errD_real.backward(retain_graph=True)\n",
    "            D_x = real_output[-1].mean().item()\n",
    "\n",
    "            # Forward pass fake batch through D\n",
    "            fake_output = netD(fake.detach())   # The detach is important\n",
    "            errD_fake = criterion(fake_output[-1].view(-1), fake_label.float())\n",
    "            errD_fake.backward(retain_graph=True)\n",
    "            D_G_z1 = fake_output[-1].mean().item()\n",
    "            \n",
    "            grads=torch.autograd.grad(outputs=real_output[-1],inputs=real_cpu,grad_outputs=torch.ones_like(real_output[-1]),allow_unused=False,create_graph=True)[0]\n",
    "            errD = errD_real + errD_fake \n",
    "\n",
    "            if gdict['lambda_gp']: ## Add gradient - penalty loss\n",
    "                gp_loss=f_gp_loss(grads,gdict['lambda_gp'])\n",
    "                errD = errD + gp_loss\n",
    "            else:\n",
    "                gp_loss=torch.Tensor([np.nan])\n",
    "\n",
    "            ###Update G network: maximize log(D(G(z)))\n",
    "            netG.zero_grad()\n",
    "            output = netD(fake)\n",
    "            errG_adv = criterion(output[-1].view(-1), g_label.float())\n",
    "            # Histogram pixel intensity loss\n",
    "            hist_gen=f_compute_hist(fake,bins=bns)\n",
    "            hist_loss=loss_hist(hist_gen,hist_val.to(device))\n",
    "\n",
    "            # Add spectral loss\n",
    "            mean,sdev=f_torch_image_spectrum(f_invtransform(fake),1,r.to(device),ind.to(device))\n",
    "            spec_loss=loss_spectrum(mean,mean_spec_val.to(device),sdev,sdev_spec_val.to(device),image_size,gdict['lambda_spec_mean'],gdict['lambda_spec_var'])\n",
    "\n",
    "            errG=errG_adv\n",
    "            if gdict['lambda_spec_mean']: errG = errG+ spec_loss \n",
    "            if gdict['lambda_fm']:## Add feature matching loss\n",
    "                fm_loss=f_FM_loss(real_output,fake_output,gdict['lambda_fm'],gdict)\n",
    "                errG= errG+ fm_loss\n",
    "            else: \n",
    "                fm_loss=torch.Tensor([np.nan])\n",
    "\n",
    "            if torch.isnan(errG).any():\n",
    "                logging.info(errG)\n",
    "                raise SystemError\n",
    "            \n",
    "            # Calculate gradients for G\n",
    "            errG.backward()\n",
    "            D_G_z2 = output[-1].mean().item()\n",
    "            \n",
    "            ### Implement Gradient clipping\n",
    "            nn.utils.clip_grad_norm_(netG.parameters(),gdict['grad_clip'])\n",
    "            nn.utils.clip_grad_norm_(netD.parameters(),gdict['grad_clip'])\n",
    "                \n",
    "            optimizerG.step()\n",
    "            optimizerD.step()\n",
    "\n",
    "            tme2=time.time()\n",
    "            ####### Store metrics ########\n",
    "            # Output training stats\n",
    "            if gdict['world_rank']==0:\n",
    "                if ((count % gdict['checkpoint_size'] == 0)):\n",
    "                    logging.info('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_adv: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                          % (epoch, epochs, count, len(dataloader), errD.item(), errG_adv.item(),errG.item(), D_x, D_G_z1, D_G_z2)),\n",
    "                    logging.info(\"Spec loss: %s,\\t hist loss: %s\"%(spec_loss.item(),hist_loss.item())),\n",
    "                    logging.info(\"Training time for step %s : %s\"%(iters, tme2-tme1))\n",
    "\n",
    "                # Save metrics\n",
    "                cols=['step','epoch','Dreal','Dfake','Dfull','G_adv','G_full','spec_loss','hist_loss','fm_loss','gp_loss','D(x)','D_G_z1','D_G_z2','time']\n",
    "                vals=[iters,epoch,errD_real.item(),errD_fake.item(),errD.item(),errG_adv.item(),errG.item(),spec_loss.item(),hist_loss.item(),fm_loss.item(),gp_loss.item(),D_x,D_G_z1,D_G_z2,tme2-tme1]\n",
    "                for col,val in zip(cols,vals):  metrics_df.loc[iters,col]=val\n",
    "\n",
    "                ### Checkpoint the best model\n",
    "                checkpoint=True\n",
    "                iters += 1  ### Model has been updated, so update iters before saving metrics and model.\n",
    "\n",
    "                ### Compute validation metrics for updated model\n",
    "                netG.eval()\n",
    "                with torch.no_grad():\n",
    "                    #fake = netG(fixed_noise).detach().cpu()\n",
    "                    fake = netG(fixed_noise)\n",
    "                    hist_gen=f_compute_hist(fake,bins=bns)\n",
    "                    hist_chi=loss_hist(hist_gen,hist_val.to(device))\n",
    "                    mean,sdev=f_torch_image_spectrum(f_invtransform(fake),1,r.to(device),ind.to(device))\n",
    "                    spec_chi=loss_spectrum(mean,mean_spec_val.to(device),sdev,sdev_spec_val.to(device),image_size,gdict['lambda_spec_mean'],gdict['lambda_spec_var'])      \n",
    "                # Storing chi for next step\n",
    "                for col,val in zip(['spec_chi','hist_chi'],[spec_chi.item(),hist_chi.item()]):  metrics_df.loc[iters,col]=val            \n",
    "\n",
    "                # Checkpoint model for continuing run\n",
    "                if count == len(dataloader)-1: ## Check point at last step of epoch\n",
    "                    f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,netG,netD,optimizerG,optimizerD,save_loc=save_dir+'/models/checkpoint_last.tar')  \n",
    "\n",
    "                if (checkpoint and (epoch > 1)): # Choose best models by metric\n",
    "                    if hist_chi< best_chi1:\n",
    "                        f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,netG,netD,optimizerG,optimizerD,save_loc=save_dir+'/models/checkpoint_best_hist.tar')\n",
    "                        best_chi1=hist_chi.item()\n",
    "                        logging.info(\"Saving best hist model at epoch %s, step %s.\"%(epoch,iters))\n",
    "\n",
    "                    if  spec_chi< best_chi2:\n",
    "                        f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,netG,netD,optimizerG,optimizerD,save_loc=save_dir+'/models/checkpoint_best_spec.tar')\n",
    "                        best_chi2=spec_chi.item()\n",
    "                        logging.info(\"Saving best spec model at epoch %s, step %s\"%(epoch,iters))\n",
    "\n",
    "                    if iters in gdict['save_steps_list']:\n",
    "                        f_save_checkpoint(gdict,epoch,iters,best_chi1,best_chi2,netG,netD,optimizerG,optimizerD,save_loc=save_dir+'/models/checkpoint_{0}.tar'.format(iters))\n",
    "                        logging.info(\"Saving given-step at epoch %s, step %s.\"%(epoch,iters))\n",
    "\n",
    "                # Save G's output on fixed_noise\n",
    "                if ((iters % gdict['checkpoint_size'] == 0) or ((epoch == epochs-1) and (count == len(dataloader)-1))):\n",
    "                    netG.eval()\n",
    "                    with torch.no_grad():\n",
    "                        fake = netG(fixed_noise).detach().cpu()\n",
    "                        img_arr=np.array(fake[:,:,:,:])\n",
    "                        fname='gen_img_epoch-%s_step-%s'%(epoch,iters)\n",
    "                        np.save(save_dir+'/images/'+fname,img_arr)\n",
    "        \n",
    "                t_epoch_end=time.time()\n",
    "                logging.info(\"Time taken for epoch %s: %s for rank %s\"%(epoch,t_epoch_end-t_epoch_start,gdict['world_rank']))\n",
    "                # Save Metrics to file after each epoch\n",
    "                metrics_df.to_pickle(save_dir+'/df_metrics.pkle')\n",
    "\n",
    "                logging.info(\"best chis: {0}, {1}\".format(best_chi1,best_chi2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup modules ###\n",
    "def f_manual_add_argparse():\n",
    "    ''' use only in jpt notebook'''\n",
    "    args=argparse.Namespace()\n",
    "    args.config='config_2dgan.yaml'\n",
    "    args.mode='fresh'\n",
    "    args.ip_fldr=''\n",
    "    args.local_rank=0\n",
    "#     args.mode='continue'\n",
    "#     args.ip_fldr='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20201211_093818_nb_test/'\n",
    "    \n",
    "    return args\n",
    "\n",
    "def f_parse_args():\n",
    "    \"\"\"Parse command line arguments.Only for .py file\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Run script to train GAN using pytorch\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    add_arg = parser.add_argument\n",
    "    \n",
    "    add_arg('--config','-cfile',  type=str, default='config_2dgan.yaml', help='Whether to start fresh run or continue previous run')\n",
    "    add_arg('--mode','-m',  type=str, choices=['fresh','continue'],default='fresh', help='Whether to start fresh run or continue previous run')\n",
    "    add_arg('--ip_fldr','-ip',  type=str, default='', help='The input folder for resuming a checkpointed run')\n",
    "    add_arg(\"--local_rank\", default=0, type=int,help='Local rank of GPU on node. Using for pytorch DDP. ')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def try_barrier(rank):\n",
    "    \"\"\"\n",
    "    Used in Distributed data parallel\n",
    "    Attempt a barrier but ignore any exceptions\n",
    "    \"\"\"\n",
    "    print('BAR %d'%rank)\n",
    "    try:\n",
    "        dist.barrier()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def f_init_gdict(args,gdict):\n",
    "    ''' Create global dictionary gdict from args and config file'''\n",
    "    \n",
    "    ## read config file\n",
    "    config_file=args.config\n",
    "    with open(config_file) as f:\n",
    "        config_dict= yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        \n",
    "    gdict=config_dict['parameters']\n",
    "\n",
    "    ## Add args variables to gdict\n",
    "    for key in ['mode','config','ip_fldr']:\n",
    "        gdict[key]=vars(args)[key]\n",
    "        \n",
    "    return gdict\n",
    "\n",
    "def f_sample_data(ip_tensor,rank=0,num_ranks=1):\n",
    "    '''\n",
    "    Module to load part of dataset depending on world_rank.\n",
    "    '''\n",
    "    data_size=ip_tensor.shape[0]\n",
    "    size=data_size//num_ranks\n",
    "    print(\"Using data indices %s-%s for rank %s\"%(rank*(size),(rank+1)*size,rank))\n",
    "    dataset=TensorDataset(ip_tensor[rank*(size):(rank+1)*size])\n",
    "    ### \n",
    "    if gdict['batch_size']>size:\n",
    "        print(\"Caution: batchsize %s is less than samples per GPU.\"%(gdict['batch_size'],size))\n",
    "        raise SystemExit\n",
    "    \n",
    "    data_loader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def f_load_data_precompute(gdict):\n",
    "    #################################\n",
    "    ####### Read data and precompute ######\n",
    "    img=np.load(gdict['ip_fname'],mmap_mode='r')[:gdict['num_imgs']].transpose(0,1,2,3).copy()\n",
    "    t_img=torch.from_numpy(img)\n",
    "    print(\"%s, %s\"%(img.shape,t_img.shape))\n",
    "\n",
    "#     dataset=TensorDataset(t_img)\n",
    "#     data_loader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)\n",
    "\n",
    "    data_loader=f_sample_data(t_img,gdict['world_rank'],gdict['world_size'])\n",
    "    print(\"Size of dataset for GPU %s : %s\"%(gdict['world_rank'],len(data_loader.dataset)))\n",
    "    \n",
    "    # Precompute metrics with validation data for computing losses\n",
    "    with torch.no_grad():\n",
    "        val_img=np.load(gdict['ip_fname'])[-30:].transpose(0,1,2,3).copy()\n",
    "        t_val_img=torch.from_numpy(val_img).to(gdict['device'])\n",
    "\n",
    "        # Precompute radial coordinates\n",
    "        r,ind=f_get_rad(img)\n",
    "        r=r.to(gdict['device']); ind=ind.to(gdict['device'])\n",
    "        # Stored mean and std of spectrum for full input data once\n",
    "        mean_spec_val,sdev_spec_val=f_torch_image_spectrum(f_invtransform(t_val_img),1,r,ind)\n",
    "        hist_val=f_compute_hist(t_val_img,bins=gdict['bns'])\n",
    "        del val_img; del t_val_img; del img; del t_img\n",
    "\n",
    "    return data_loader,mean_spec_val,sdev_spec_val,hist_val,r,ind\n",
    "\n",
    "def f_init_GAN(gdict,print_model=False):\n",
    "    # Define Models\n",
    "    logging.info(\"Building GAN networks\")\n",
    "    # Create Generator\n",
    "    netG = Generator(gdict).to(gdict['device'])\n",
    "    netG.apply(weights_init)\n",
    "    # Create Discriminator\n",
    "    netD = Discriminator(gdict).to(gdict['device'])\n",
    "    netD.apply(weights_init)\n",
    "    \n",
    "    if print_model:\n",
    "        if gdict['world_rank']==0:\n",
    "            print(netG)\n",
    "        #     summary(netG,(1,1,64))\n",
    "            print(netD)\n",
    "        #     summary(netD,(1,128,128))\n",
    "            print(\"Number of GPUs used %s\"%(gdict['ngpu']))\n",
    "\n",
    "    if (gdict['multi-gpu']):\n",
    "        if not gdict['distributed']:\n",
    "            netG = nn.DataParallel(netG, list(range(gdict['ngpu'])))\n",
    "            netD = nn.DataParallel(netD, list(range(gdict['ngpu'])))\n",
    "        else:\n",
    "            netG=DistributedDataParallel(netG,device_ids=[gdict['local_rank']],output_device=[gdict['local_rank']])\n",
    "            netD=DistributedDataParallel(netD,device_ids=[gdict['local_rank']],output_device=[gdict['local_rank']])\n",
    "    \n",
    "    #### Initialize networks ####\n",
    "    # criterion = nn.BCELoss()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    if gdict['mode']=='fresh':\n",
    "        optimizerD = optim.Adam(netD.parameters(), lr=gdict['learn_rate'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n",
    "        optimizerG = optim.Adam(netG.parameters(), lr=gdict['learn_rate'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n",
    "        ### Initialize variables      \n",
    "        iters,start_epoch,best_chi1,best_chi2=0,0,1e10,1e10    \n",
    "\n",
    "    ### Load network weights for continuing run\n",
    "    elif gdict['mode']=='continue':\n",
    "        iters,start_epoch,best_chi1,best_chi2=f_load_checkpoint(gdict['save_dir']+'/models/checkpoint_last.tar',netG,netD,optimizerG,optimizerD,gdict) \n",
    "        logging.info(\"Continuing existing run. Loading checkpoint with epoch {0} and step {1}\".format(start_epoch,iters))\n",
    "        start_epoch+=1  ## Start with the next epoch  \n",
    "\n",
    "    ## Add to gdict\n",
    "    for key,val in zip(['best_chi1','best_chi2','iters','start_epoch'],[best_chi1,best_chi2,iters,start_epoch]): gdict[key]=val\n",
    "\n",
    "    return netG,netD,criterion,optimizerD,optimizerG\n",
    "\n",
    "def f_setup(gdict,log):\n",
    "    ''' \n",
    "    Set up directories, Initialize random seeds, add GPU info, add logging info.\n",
    "    '''\n",
    "    \n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    ########################\n",
    "    ###### Set up Distributed Data parallel ######\n",
    "    if gdict['distributed']:\n",
    "        gdict['local_rank']=args.local_rank    \n",
    "        gdict['world_size']=int(os.environ['WORLD_SIZE'])\n",
    "        torch.cuda.set_device(args.local_rank) ## Very important\n",
    "        dist.init_process_group(backend='nccl', init_method=\"env://\")  \n",
    "        gdict['world_rank']= dist.get_rank()\n",
    "        \n",
    "        print(\"World size %s, world rank %s, local rank %s, hostname %s\\n\"%(gdict['world_size'],gdict['world_rank'],gdict['local_rank'],socket.gethostname()))\n",
    "        device = torch.cuda.current_device()\n",
    "    else:\n",
    "        gdict['world_size'],gdict['world_rank'],gdict['local_rank']=1,0,0\n",
    "    \n",
    "    ########################\n",
    "    ###### Set up directories #######\n",
    "    ### sync up so that time is the same for each GPU for DDP\n",
    "    if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "    if gdict['mode']=='fresh':\n",
    "        # Create prefix for foldername        \n",
    "        fldr_name=datetime.now().strftime('%Y%m%d_%H%M%S') ## time format\n",
    "        gdict['save_dir']=gdict['op_loc']+fldr_name+'_'+gdict['run_suffix']\n",
    "        if gdict['world_rank']==0:\n",
    "            if not os.path.exists(gdict['save_dir']):\n",
    "                os.makedirs(gdict['save_dir']+'/models')\n",
    "                os.makedirs(gdict['save_dir']+'/images')\n",
    "                shutil.copy(gdict['config'],gdict['save_dir'])\n",
    "\n",
    "    elif gdict['mode']=='continue': ## For checkpointed runs\n",
    "        gdict['save_dir']=args.ip_fldr\n",
    "        ### Read loss data\n",
    "        with open (gdict['save_dir']+'df_metrics.pkle','rb') as f:\n",
    "            metrics_dict=pickle.load(f)\n",
    "    \n",
    "    ########################\n",
    "    ### Initialize random seed\n",
    "    \n",
    "    manualSeed = np.random.randint(1, 10000) if gdict['seed']=='random' else int(gdict['seed'])\n",
    "#     print(\"Seed\",manualSeed,gdict['world_rank'])\n",
    "    random.seed(manualSeed)\n",
    "    np.random.seed(manualSeed)\n",
    "    torch.manual_seed(manualSeed)\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "    \n",
    "    if gdict['deterministic']:\n",
    "        logging.info(\"Running with deterministic sequence. Performance will be slower\")\n",
    "        torch.backends.cudnn.deterministic=True\n",
    "#         torch.backends.cudnn.enabled = False\n",
    "        torch.backends.cudnn.benchmark = False        \n",
    "\n",
    "    ## Special declarations\n",
    "    gdict['ngpu']=torch.cuda.device_count()\n",
    "    gdict['device']=torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "    gdict['multi-gpu']=True if (gdict['device'].type == 'cuda') and (gdict['ngpu'] > 1) else False \n",
    "\n",
    "    if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "    \n",
    "    ########################\n",
    "    if log:\n",
    "        ### Write all logging.info statements to stdout and log file\n",
    "        logfile=gdict['save_dir']+'/log.log'\n",
    "        if gdict['world_rank']==0:\n",
    "            logging.basicConfig(level=logging.DEBUG, filename=logfile, filemode=\"a+\", format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n",
    "            Lg = logging.getLogger()\n",
    "            Lg.setLevel(logging.DEBUG)\n",
    "            lg_handler_file = logging.FileHandler(logfile)\n",
    "            lg_handler_stdout = logging.StreamHandler(sys.stdout)\n",
    "            Lg.addHandler(lg_handler_file)\n",
    "            Lg.addHandler(lg_handler_stdout)\n",
    "\n",
    "            logging.info('Args: {0}'.format(args))\n",
    "            logging.info('Start: %s'%(datetime.now().strftime('%Y-%m-%d  %H:%M:%S')))\n",
    "        \n",
    "        if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "\n",
    "        if gdict['world_rank']!=0:\n",
    "                logging.basicConfig(level=logging.DEBUG, filename=logfile, filemode=\"a+\", format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32768, bias=True)\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): View()\n",
      "    (4): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (14): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=32768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of GPUs used 1\n",
      "(400, 1, 128, 128), torch.Size([400, 1, 128, 128])\n",
      "Using data indices 0-400 for rank 0\n",
      "Size of dataset for GPU 0 : 400\n",
      "Inside train loop\n",
      "(200, 1, 128, 128)\n",
      "Image saved in  best_spec_epoch-3_step-10.npy\n",
      "(200, 1, 128, 128)\n",
      "Image saved in  best_hist_epoch-4_step-15.npy\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "### Main code #######\n",
    "#########################\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "#     jpt=False\n",
    "    jpt=True ##(different for jupyter notebook)\n",
    "    t0=time.time()\n",
    "    args=f_parse_args() if not jpt else f_manual_add_argparse()\n",
    "\n",
    "    #################################\n",
    "    ### Set up global dictionary###\n",
    "    gdict={}\n",
    "    gdict=f_init_gdict(args,gdict)\n",
    "    gdict['num_imgs']=1200\n",
    "\n",
    "    if jpt: ## override for jpt nbks\n",
    "        gdict['num_imgs']=400\n",
    "        gdict['run_suffix']='nb_test'\n",
    "        \n",
    "    f_setup(gdict,log=(not jpt))\n",
    "\n",
    "    ## Build GAN\n",
    "    netG,netD,criterion,optimizerD,optimizerG=f_init_GAN(gdict,print_model=True)\n",
    "    fixed_noise = torch.randn(gdict['batch_size'], 1, 1, gdict['nz'], device=gdict['device']) #Latent vectors to view G progress    \n",
    "    if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "\n",
    "    ## Load data and precompute\n",
    "    dataloader,mean_spec_val,sdev_spec_val,hist_val,r,ind=f_load_data_precompute(gdict)\n",
    "\n",
    "    #################################\n",
    "    ########## Train loop and save metrics and images ######\n",
    "    ### Set up metrics dataframe\n",
    "    cols=['step','epoch','Dreal','Dfake','Dfull','G_adv','G_full','spec_loss','hist_loss','spec_chi','hist_chi','gp_loss','fm_loss','D(x)','D_G_z1','D_G_z2','time']\n",
    "    metrics_df=pd.DataFrame(columns=cols)\n",
    "    if gdict['distributed']:  try_barrier(gdict['world_rank'])\n",
    "\n",
    "    logging.info(\"Starting Training Loop...\")\n",
    "    f_train_loop(dataloader,metrics_df,gdict,fixed_noise,mean_spec_val,sdev_spec_val,hist_val,r,ind)\n",
    "    \n",
    "    if gdict['world_rank']==0: ## Generate images for best saved models ######\n",
    "        op_loc=gdict['save_dir']+'/images/'\n",
    "        ip_fname=gdict['save_dir']+'/models/checkpoint_best_spec.tar'\n",
    "        f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='best_spec',op_size=200)\n",
    "        ip_fname=gdict['save_dir']+'/models/checkpoint_best_hist.tar'\n",
    "        f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='best_hist',op_size=200)\n",
    "    \n",
    "    tf=time.time()\n",
    "    logging.info(\"Total time %s\"%(tf-t0))\n",
    "    logging.info('End: %s'%(datetime.now().strftime('%Y-%m-%d  %H:%M:%S')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Dreal</th>\n",
       "      <th>Dfake</th>\n",
       "      <th>Dfull</th>\n",
       "      <th>G_adv</th>\n",
       "      <th>G_full</th>\n",
       "      <th>spec_loss</th>\n",
       "      <th>hist_loss</th>\n",
       "      <th>spec_chi</th>\n",
       "      <th>hist_chi</th>\n",
       "      <th>gp_loss</th>\n",
       "      <th>fm_loss</th>\n",
       "      <th>D(x)</th>\n",
       "      <th>D_G_z1</th>\n",
       "      <th>D_G_z2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159.534</td>\n",
       "      <td>8987.3</td>\n",
       "      <td>14776.2</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.99148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5629.38</td>\n",
       "      <td>0.00201901</td>\n",
       "      <td>10235</td>\n",
       "      <td>9077.92</td>\n",
       "      <td>9077.92</td>\n",
       "      <td>4.88362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173.078</td>\n",
       "      <td>8727.17</td>\n",
       "      <td>14634.2</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.00608</td>\n",
       "      <td>41.8083</td>\n",
       "      <td>2.15863</td>\n",
       "      <td>5733.94</td>\n",
       "      <td>0.00198632</td>\n",
       "      <td>10201</td>\n",
       "      <td>8813.99</td>\n",
       "      <td>8813.99</td>\n",
       "      <td>2.50519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74.3979</td>\n",
       "      <td>8726.87</td>\n",
       "      <td>14574.4</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5365</td>\n",
       "      <td>37.5345</td>\n",
       "      <td>1.91153</td>\n",
       "      <td>39.3527</td>\n",
       "      <td>2.00964</td>\n",
       "      <td>5773.16</td>\n",
       "      <td>0.00203368</td>\n",
       "      <td>10183.3</td>\n",
       "      <td>8766.89</td>\n",
       "      <td>8766.89</td>\n",
       "      <td>2.49101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>160.401</td>\n",
       "      <td>7756.97</td>\n",
       "      <td>13715.4</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7864</td>\n",
       "      <td>33.7844</td>\n",
       "      <td>1.94413</td>\n",
       "      <td>33.7931</td>\n",
       "      <td>1.88528</td>\n",
       "      <td>5798.05</td>\n",
       "      <td>0.00198787</td>\n",
       "      <td>10176.7</td>\n",
       "      <td>7864.22</td>\n",
       "      <td>7864.22</td>\n",
       "      <td>3.56536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>157.372</td>\n",
       "      <td>8340.92</td>\n",
       "      <td>14315.6</td>\n",
       "      <td>0</td>\n",
       "      <td>35.8525</td>\n",
       "      <td>35.8506</td>\n",
       "      <td>1.85463</td>\n",
       "      <td>35.1495</td>\n",
       "      <td>1.96287</td>\n",
       "      <td>5817.26</td>\n",
       "      <td>0.00194456</td>\n",
       "      <td>10140</td>\n",
       "      <td>8407.52</td>\n",
       "      <td>8407.52</td>\n",
       "      <td>2.47221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>150.497</td>\n",
       "      <td>8562.87</td>\n",
       "      <td>14554.5</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6211</td>\n",
       "      <td>33.6192</td>\n",
       "      <td>1.83511</td>\n",
       "      <td>34.0323</td>\n",
       "      <td>1.80356</td>\n",
       "      <td>5841.14</td>\n",
       "      <td>0.00183303</td>\n",
       "      <td>10113.4</td>\n",
       "      <td>8650.38</td>\n",
       "      <td>8650.38</td>\n",
       "      <td>2.48615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>182.588</td>\n",
       "      <td>7992.94</td>\n",
       "      <td>14298</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.84981</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.77088</td>\n",
       "      <td>6122.51</td>\n",
       "      <td>0.00166446</td>\n",
       "      <td>10095.6</td>\n",
       "      <td>8214.49</td>\n",
       "      <td>8214.49</td>\n",
       "      <td>2.48943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>167.025</td>\n",
       "      <td>7824.63</td>\n",
       "      <td>13897.4</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.84116</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.81433</td>\n",
       "      <td>5905.76</td>\n",
       "      <td>0.00151732</td>\n",
       "      <td>10136.3</td>\n",
       "      <td>8107.5</td>\n",
       "      <td>8107.5</td>\n",
       "      <td>2.47516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>141.7</td>\n",
       "      <td>7714.16</td>\n",
       "      <td>14174.7</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.856</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.79039</td>\n",
       "      <td>6318.85</td>\n",
       "      <td>0.00135775</td>\n",
       "      <td>10086.7</td>\n",
       "      <td>7770.85</td>\n",
       "      <td>7770.85</td>\n",
       "      <td>2.48975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>167.562</td>\n",
       "      <td>7706.47</td>\n",
       "      <td>14238.6</td>\n",
       "      <td>0</td>\n",
       "      <td>37.9709</td>\n",
       "      <td>37.9697</td>\n",
       "      <td>1.85316</td>\n",
       "      <td>33.9819</td>\n",
       "      <td>1.83093</td>\n",
       "      <td>6364.55</td>\n",
       "      <td>0.0012388</td>\n",
       "      <td>10068.7</td>\n",
       "      <td>7851.89</td>\n",
       "      <td>7851.89</td>\n",
       "      <td>2.48612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>143.864</td>\n",
       "      <td>7812.11</td>\n",
       "      <td>14370.5</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7167</td>\n",
       "      <td>33.7156</td>\n",
       "      <td>1.82112</td>\n",
       "      <td>33.6843</td>\n",
       "      <td>1.80211</td>\n",
       "      <td>6414.53</td>\n",
       "      <td>0.0011177</td>\n",
       "      <td>10086.1</td>\n",
       "      <td>7872.89</td>\n",
       "      <td>7872.89</td>\n",
       "      <td>2.47704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>147.667</td>\n",
       "      <td>7588.18</td>\n",
       "      <td>14468.5</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.84112</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.80479</td>\n",
       "      <td>6732.7</td>\n",
       "      <td>0.000985596</td>\n",
       "      <td>10071.9</td>\n",
       "      <td>7750.85</td>\n",
       "      <td>7750.85</td>\n",
       "      <td>2.52245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>164.466</td>\n",
       "      <td>6362.88</td>\n",
       "      <td>13408.4</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.86253</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.78374</td>\n",
       "      <td>6881.05</td>\n",
       "      <td>0.000927587</td>\n",
       "      <td>10034.4</td>\n",
       "      <td>7126.8</td>\n",
       "      <td>7126.8</td>\n",
       "      <td>2.48371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>153.268</td>\n",
       "      <td>7150.07</td>\n",
       "      <td>14330</td>\n",
       "      <td>0</td>\n",
       "      <td>40.999</td>\n",
       "      <td>40.9981</td>\n",
       "      <td>1.82861</td>\n",
       "      <td>43.0776</td>\n",
       "      <td>1.79495</td>\n",
       "      <td>7026.65</td>\n",
       "      <td>0.000921806</td>\n",
       "      <td>10022.6</td>\n",
       "      <td>7202.06</td>\n",
       "      <td>7202.06</td>\n",
       "      <td>2.54385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>136.52</td>\n",
       "      <td>7002.63</td>\n",
       "      <td>14340.7</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7099</td>\n",
       "      <td>33.7091</td>\n",
       "      <td>1.78578</td>\n",
       "      <td>34.2319</td>\n",
       "      <td>1.79038</td>\n",
       "      <td>7201.59</td>\n",
       "      <td>0.000848967</td>\n",
       "      <td>10033.2</td>\n",
       "      <td>7171.8</td>\n",
       "      <td>7171.8</td>\n",
       "      <td>2.45772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.7133</td>\n",
       "      <td>1.7788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step epoch    Dreal    Dfake    Dfull G_adv   G_full spec_loss hist_loss  \\\n",
       "0     0     0  159.534   8987.3  14776.2     0      inf       inf   1.99148   \n",
       "1     1     0  173.078  8727.17  14634.2     0      inf       inf   2.00608   \n",
       "2     2     0  74.3979  8726.87  14574.4     0  37.5365   37.5345   1.91153   \n",
       "3     3     1  160.401  7756.97  13715.4     0  33.7864   33.7844   1.94413   \n",
       "4     4     1  157.372  8340.92  14315.6     0  35.8525   35.8506   1.85463   \n",
       "5     5     1  150.497  8562.87  14554.5     0  33.6211   33.6192   1.83511   \n",
       "6     6     2  182.588  7992.94    14298     0      inf       inf   1.84981   \n",
       "7     7     2  167.025  7824.63  13897.4     0      inf       inf   1.84116   \n",
       "8     8     2    141.7  7714.16  14174.7     0      inf       inf     1.856   \n",
       "9     9     3  167.562  7706.47  14238.6     0  37.9709   37.9697   1.85316   \n",
       "10   10     3  143.864  7812.11  14370.5     0  33.7167   33.7156   1.82112   \n",
       "11   11     3  147.667  7588.18  14468.5     0      inf       inf   1.84112   \n",
       "12   12     4  164.466  6362.88  13408.4     0      inf       inf   1.86253   \n",
       "13   13     4  153.268  7150.07    14330     0   40.999   40.9981   1.82861   \n",
       "14   14     4   136.52  7002.63  14340.7     0  33.7099   33.7091   1.78578   \n",
       "15  NaN   NaN      NaN      NaN      NaN   NaN      NaN       NaN       NaN   \n",
       "\n",
       "   spec_chi hist_chi  gp_loss      fm_loss     D(x)   D_G_z1   D_G_z2     time  \n",
       "0       NaN      NaN  5629.38   0.00201901    10235  9077.92  9077.92  4.88362  \n",
       "1   41.8083  2.15863  5733.94   0.00198632    10201  8813.99  8813.99  2.50519  \n",
       "2   39.3527  2.00964  5773.16   0.00203368  10183.3  8766.89  8766.89  2.49101  \n",
       "3   33.7931  1.88528  5798.05   0.00198787  10176.7  7864.22  7864.22  3.56536  \n",
       "4   35.1495  1.96287  5817.26   0.00194456    10140  8407.52  8407.52  2.47221  \n",
       "5   34.0323  1.80356  5841.14   0.00183303  10113.4  8650.38  8650.38  2.48615  \n",
       "6       inf  1.77088  6122.51   0.00166446  10095.6  8214.49  8214.49  2.48943  \n",
       "7       inf  1.81433  5905.76   0.00151732  10136.3   8107.5   8107.5  2.47516  \n",
       "8       inf  1.79039  6318.85   0.00135775  10086.7  7770.85  7770.85  2.48975  \n",
       "9   33.9819  1.83093  6364.55    0.0012388  10068.7  7851.89  7851.89  2.48612  \n",
       "10  33.6843  1.80211  6414.53    0.0011177  10086.1  7872.89  7872.89  2.47704  \n",
       "11      inf  1.80479   6732.7  0.000985596  10071.9  7750.85  7750.85  2.52245  \n",
       "12      inf  1.78374  6881.05  0.000927587  10034.4   7126.8   7126.8  2.48371  \n",
       "13  43.0776  1.79495  7026.65  0.000921806  10022.6  7202.06  7202.06  2.54385  \n",
       "14  34.2319  1.79038  7201.59  0.000848967  10033.2   7171.8   7171.8  2.45772  \n",
       "15  33.7133   1.7788      NaN          NaN      NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics_df.plot('step','time')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ip_fname': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy',\n",
       " 'op_loc': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/',\n",
       " 'image_size': 128,\n",
       " 'num_imgs': 400,\n",
       " 'workers': 2,\n",
       " 'nc': 1,\n",
       " 'nz': 64,\n",
       " 'ngf': 64,\n",
       " 'ndf': 64,\n",
       " 'beta1': 0.5,\n",
       " 'kernel_size': 5,\n",
       " 'stride': 2,\n",
       " 'g_padding': 2,\n",
       " 'd_padding': 2,\n",
       " 'flip_prob': 0.01,\n",
       " 'checkpoint_size': 10,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 25,\n",
       " 'learn_rate': 0.0002,\n",
       " 'bns': 50,\n",
       " 'deterministic': False,\n",
       " 'distributed': False,\n",
       " 'seed': 234373,\n",
       " 'lambda_spec_mean': 1.0,\n",
       " 'lambda_spec_var': 0.1,\n",
       " 'lambda_fm': False,\n",
       " 'lambda_gp': False,\n",
       " 'grad_clip': 1.0,\n",
       " 'save_steps_list': [5, 10],\n",
       " 'run_suffix': 'nb_test',\n",
       " 'description': '2d GAN: new loss',\n",
       " 'mode': 'fresh',\n",
       " 'config': 'config_2dgan.yaml',\n",
       " 'ip_fldr': '',\n",
       " 'save_dir': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20210330_133549_nb_test',\n",
       " 'ngpu': 1,\n",
       " 'device': device(type='cuda'),\n",
       " 'multi-gpu': False,\n",
       " 'best_chi1': 10000000000.0,\n",
       " 'best_chi2': 10000000000.0,\n",
       " 'iters': 0,\n",
       " 'start_epoch': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matching loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, gdict):\n",
    "#         super(Generator, self).__init__()\n",
    "\n",
    "#         ## Define new variables from dict\n",
    "#         keys=['ngpu','nz','nc','ngf','kernel_size','stride','g_padding']\n",
    "#         ngpu, nz,nc,ngf,kernel_size,stride,g_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())\n",
    "\n",
    "#         self.main = nn.Sequential(\n",
    "#             # nn.ConvTranspose2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "#             nn.Linear(nz,nc*ngf*8*8*8),# 32768\n",
    "#             nn.BatchNorm2d(nc,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             View(shape=[-1,ngf*8,8,8]),\n",
    "#             nn.ConvTranspose2d(ngf * 8, ngf * 4, kernel_size, stride, g_padding, output_padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf*4,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             # state size. (ngf*4) x 8 x 8\n",
    "#             nn.ConvTranspose2d( ngf * 4, ngf * 2, kernel_size, stride, g_padding, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf*2,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             # state size. (ngf*2) x 16 x 16\n",
    "#             nn.ConvTranspose2d( ngf * 2, ngf, kernel_size, stride, g_padding, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             # state size. (ngf) x 32 x 32\n",
    "#             nn.ConvTranspose2d( ngf, nc, kernel_size, stride,g_padding, 1, bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, ip):\n",
    "#         return self.main(ip)\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, gdict):\n",
    "#         super(Discriminator, self).__init__()\n",
    "        \n",
    "#         ## Define new variables from dict\n",
    "#         keys=['ngpu','nz','nc','ndf','kernel_size','stride','d_padding']\n",
    "#         ngpu, nz,nc,ndf,kernel_size,stride,d_padding=list(collections.OrderedDict({key:gdict[key] for key in keys}).values())        \n",
    "\n",
    "#         self.main = nn.Sequential(\n",
    "#             # input is (nc) x 64 x 64\n",
    "#             # nn.Conv2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "#             nn.Conv2d(nc, ndf,kernel_size, stride, d_padding,  bias=True),\n",
    "#             nn.BatchNorm2d(ndf,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf) x 32 x 32\n",
    "#             nn.Conv2d(ndf, ndf * 2, kernel_size, stride, d_padding, bias=True),\n",
    "#             nn.BatchNorm2d(ndf * 2,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*2) x 16 x 16\n",
    "#             nn.Conv2d(ndf * 2, ndf * 4, kernel_size, stride, d_padding, bias=True),\n",
    "#             nn.BatchNorm2d(ndf * 4,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*4) x 8 x 8\n",
    "#             nn.Conv2d(ndf * 4, ndf * 8, kernel_size, stride, d_padding, bias=True),\n",
    "#             nn.BatchNorm2d(ndf * 8,eps=1e-05, momentum=0.9, affine=True),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*8) x 4 x 4\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(nc*ndf*8*8*8, 1)\n",
    "# #             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, ip):\n",
    "# #         print(ip.shape)\n",
    "#         results=[ip]\n",
    "#         lst_idx=[]\n",
    "#         for i,submodel in enumerate(self.main.children()):\n",
    "#             mid_output=submodel(results[-1])\n",
    "#             results.append(mid_output)\n",
    "#             ## Select indices in list corresponding to output of Conv layers\n",
    "#             if submodel.__class__.__name__.startswith('Conv'):\n",
    "# #                 print(submodel.__class__.__name__)\n",
    "# #                 print(mid_output.shape)\n",
    "#                 lst_idx.append(i)\n",
    "\n",
    "#         FMloss=True\n",
    "#         if FMloss:\n",
    "#             ans=[results[1:][i] for i in lst_idx + [-1]]\n",
    "#         else :\n",
    "#             ans=results[-1]\n",
    "#         return ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netG = Generator(gdict).to(gdict['device'])\n",
    "# netG.apply(weights_init)\n",
    "# # # #     print(netG)\n",
    "# # summary(netG,(1,1,64))\n",
    "# # Create Discriminator\n",
    "# netD = Discriminator(gdict).to(gdict['device'])\n",
    "# netD.apply(weights_init)\n",
    "# #     print(netD)\n",
    "# summary(netD,(1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = torch.randn(gdict['batchsize'], 1, 1, gdict['nz'], device=gdict['device'])\n",
    "# fake = netG(noise)            \n",
    "# # Forward pass real batch through D\n",
    "# output = netD(fake)\n",
    "# print([i.shape for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1, 128, 128), torch.Size([400, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "####### Read data and precompute ######\n",
    "img=np.load(gdict['ip_fname'],mmap_mode='r')[:gdict['num_imgs']].transpose(0,1,2,3).copy()\n",
    "t_img=torch.from_numpy(img)\n",
    "print(\"%s, %s\"%(img.shape,t_img.shape))\n",
    "\n",
    "dataset=TensorDataset(t_img)\n",
    "data_loader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "240 320\n",
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2aab3e00f070>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_sample_data(ip_tensor,rank=0,num_ranks=1):\n",
    "    \n",
    "    data_size=ip_tensor.shape[0]\n",
    "    size=data_size//num_ranks\n",
    "    print(size)\n",
    "    print(rank*(size),(rank+1)*size)\n",
    "    dataset=TensorDataset(ip_tensor[rank*(size):(rank+1)*size])\n",
    "    data_loader=DataLoader(dataset,batch_size=gdict['batch_size'],shuffle=True,num_workers=0,drop_last=True)\n",
    "    print(len(data_loader.dataset))\n",
    "    return data_loader\n",
    "\n",
    "f_sample_data(t_img,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_index_sampler',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'pin_memory',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1, 128, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 128, 128])\n",
      "torch.Size([128, 1, 128, 128])\n",
      "torch.Size([128, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.5.0-gpu",
   "language": "python",
   "name": "pytorch-v1.5.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
