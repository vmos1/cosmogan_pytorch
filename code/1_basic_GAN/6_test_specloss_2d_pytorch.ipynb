{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the issue with losses not matching in 2 codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pickle \n",
    "\n",
    "from matplotlib.colors import LogNorm, PowerNorm, Normalize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from scipy import fftpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchsummary import summary\n",
    "# import torchvision.datasets as dset\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "import torch.fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/cosmogan/1_main_code/')\n",
    "# import spec_loss as spc\n",
    "# import post_analysis_pandas as post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### Numpy functions ### Not used in the code. Just to test the pytorch functions\n",
    "############\n",
    "def f_radial_profile(data, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image '''\n",
    "    y, x = np.indices((data.shape)) # Get a grid of x and y values\n",
    "    \n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "        \n",
    "    # get radial values of every pair of points\n",
    "    r = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r = r.astype(np.int)\n",
    "    \n",
    "    # Compute histogram of r values\n",
    "    tbin = np.bincount(r.ravel(), data.ravel())\n",
    "    nr = np.bincount(r.ravel()) \n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile[1:-1]\n",
    "\n",
    "def f_compute_spectrum(arr,GLOBAL_MEAN=1.0):\n",
    "    \n",
    "    arr=((arr - GLOBAL_MEAN)/GLOBAL_MEAN)\n",
    "    y1=np.fft.fft2(arr)\n",
    "    y1=fftpack.fftshift(y1)\n",
    "\n",
    "    y2=abs(y1)**2\n",
    "    z1=f_radial_profile(y2)\n",
    "    return(z1)\n",
    "\n",
    "    \n",
    "def f_compute_batch_spectrum(arr):\n",
    "    batch_pk=np.array([f_compute_spectrum(i) for i in arr])\n",
    "    return batch_pk\n",
    "\n",
    "\n",
    "def f_image_spectrum(x,num_channels):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    print(x.shape)\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    var=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "#         print(i,arr.shape)\n",
    "        batch_pk=f_compute_batch_spectrum(arr)\n",
    "#         print(batch_pk)\n",
    "        mean[i]=np.mean(batch_pk,axis=0)\n",
    "        var[i]=np.var(batch_pk,axis=0)\n",
    "    mean=np.array(mean)\n",
    "    var=np.array(var)\n",
    "    return mean,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_torch_radial_profile(img, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image \n",
    "    Bincount causes issues with backprop, so not using this code\n",
    "    '''\n",
    "    \n",
    "    y,x=torch.meshgrid(torch.arange(0,img.shape[0]),torch.arange(0,img.shape[1])) # Get a grid of x and y values\n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = torch.Tensor([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "\n",
    "    # get radial values of every pair of points\n",
    "    r = torch.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r= r.int()\n",
    "    \n",
    "#     print(r.shape,img.shape)\n",
    "    # Compute histogram of r values\n",
    "    tbin=torch.bincount(torch.reshape(r,(-1,)),weights=torch.reshape(img,(-1,)).type(torch.DoubleTensor))\n",
    "    nr = torch.bincount(torch.reshape(r,(-1,)))\n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile[1:-1]\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage_with_batch(image, center=None): ### Not used in this code.\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile. Only use if you need to combine batches\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, channel, height, width = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (batch, channel,-1)))\n",
    "    r_sorted = torch.gather(torch.reshape(r, (batch, channel, -1,)),2, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, (batch, channel, -1,)),2, ind)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[:,:,1:] - r_int[:,:,:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[2], (batch, -1))    # location of changes in radius\n",
    "    rind=torch.unsqueeze(rind,1)\n",
    "    nr = (rind[:,:,1:] - rind[:,:,:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "\n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "#     print(csum.shape,rind.shape,nr.shape)\n",
    "\n",
    "    tbin = torch.gather(csum, 2, rind[:,:,1:]) - torch.gather(csum, 2, rind[:,:,:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "def f_get_rad(img):\n",
    "    ''' Get the radial tensor for use in f_torch_get_azimuthalAverage '''\n",
    "    \n",
    "    height,width=img.shape[-2:]\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "    \n",
    "    center=[]\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "    \n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "    \n",
    "    return r.detach(),ind.detach()\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage(image,r,ind):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "#     height, width = image.shape\n",
    "#     # Create a grid of points with x and y coordinates\n",
    "#     y, x = np.indices([height,width])\n",
    "\n",
    "#     if not center:\n",
    "#         center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "#     # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "#     r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "#     # Get sorted radii\n",
    "#     ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "\n",
    "    r_sorted = torch.gather(torch.reshape(r, ( -1,)),0, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, ( -1,)),0, ind)\n",
    "    \n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[0], (-1,))    # location of changes in radius\n",
    "    nr = (rind[1:] - rind[:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    \n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    tbin = torch.gather(csum, 0, rind[1:]) - torch.gather(csum, 0, rind[:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "def f_torch_fftshift(real, imag):\n",
    "    for dim in range(0, len(real.size())):\n",
    "        real = torch.roll(real, dims=dim, shifts=real.size(dim)//2)\n",
    "        imag = torch.roll(imag, dims=dim, shifts=imag.size(dim)//2)\n",
    "    return real, imag\n",
    "\n",
    "# def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "#     GLOBAL_MEAN=1.0\n",
    "#     arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "#     y1=torch.rfft(arr,signal_ndim=2,onesided=False)\n",
    "#     real,imag=f_torch_fftshift(y1[:,:,0],y1[:,:,1])    ## last index is real/imag part\n",
    "#     y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    \n",
    "# #     print(y2.shape)\n",
    "#     z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    \n",
    "#     return z1\n",
    "\n",
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    \n",
    "    y1=torch.fft.fftn(arr,dim=(-2,-1))\n",
    "    real,imag=f_torch_fftshift(y1.real,y1.imag)    ## last index is real/imag part\n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    \n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    \n",
    "    return z1\n",
    "\n",
    "\n",
    "def f_torch_compute_batch_spectrum(arr,r,ind):\n",
    "    \n",
    "    batch_pk=torch.stack([f_torch_compute_spectrum(i,r,ind) for i in arr])\n",
    "    \n",
    "    return batch_pk\n",
    "\n",
    "def f_torch_image_spectrum(x,num_channels,r,ind):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    \n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    var=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "        batch_pk=f_torch_compute_batch_spectrum(arr,r,ind)\n",
    "        mean[i]=torch.mean(batch_pk,axis=0)\n",
    "#         sdev[i]=torch.std(batch_pk,axis=0)/np.sqrt(batch_pk.shape[0])\n",
    "#         sdev[i]=torch.std(batch_pk,axis=0)\n",
    "        var[i]=torch.var(batch_pk,axis=0)\n",
    "    \n",
    "    mean=torch.stack(mean)\n",
    "    var=torch.stack(var)\n",
    "        \n",
    "    return mean,var\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "img=np.load(ip_fname)[:1000].transpose(0,1,2,3)\n",
    "t_img=torch.from_numpy(img)\n",
    "img.shape,t_img.shape\n",
    "\n",
    "height,width=img.shape[-2:]\n",
    "height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "mean_np,var_np=f_image_spectrum(img,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.86095894e+04, 6.17923061e+04, 4.47503460e+04, 3.51597085e+04,\n",
       "        2.81154319e+04, 2.29919677e+04, 1.86727547e+04, 1.56106763e+04,\n",
       "        1.34797658e+04, 1.15257976e+04, 9.92852995e+03, 8.60875845e+03,\n",
       "        7.49414036e+03, 6.56703667e+03, 5.76027553e+03, 5.11176780e+03,\n",
       "        4.53719666e+03, 4.03557669e+03, 3.56441319e+03, 3.15770070e+03,\n",
       "        2.80859481e+03, 2.51905774e+03, 2.26498943e+03, 2.00323965e+03,\n",
       "        1.78629070e+03, 1.60299791e+03, 1.43996686e+03, 1.29375291e+03,\n",
       "        1.16713012e+03, 1.05542881e+03, 9.47136378e+02, 8.57164956e+02,\n",
       "        7.74504956e+02, 7.06768427e+02, 6.49635341e+02, 5.82564523e+02,\n",
       "        5.33945159e+02, 4.86425736e+02, 4.49577822e+02, 4.14241110e+02,\n",
       "        3.79101369e+02, 3.55290538e+02, 3.25002859e+02, 3.03822516e+02,\n",
       "        2.80719548e+02, 2.62327633e+02, 2.47110733e+02, 2.28833887e+02,\n",
       "        2.19269204e+02, 2.04426367e+02, 1.95022151e+02, 1.85564959e+02,\n",
       "        1.73076708e+02, 1.68424720e+02, 1.58666063e+02, 1.53504462e+02,\n",
       "        1.46079940e+02, 1.39311814e+02, 1.38672013e+02, 1.31348361e+02,\n",
       "        1.28457474e+02, 1.24944862e+02, 1.22014213e+02, 1.07805832e+02,\n",
       "        9.29372530e+01, 8.63006740e+01, 7.92018218e+01, 7.38961767e+01,\n",
       "        7.08721501e+01, 6.43073902e+01, 6.22762621e+01, 5.78825399e+01,\n",
       "        5.58016649e+01, 5.26959005e+01, 5.06223516e+01, 4.90362162e+01,\n",
       "        4.63899765e+01, 4.54573571e+01, 4.34381170e+01, 4.23245091e+01,\n",
       "        4.14703542e+01, 4.01951337e+01, 3.94094286e+01, 3.86136741e+01,\n",
       "        3.78656201e+01, 3.76166359e+01, 3.74954811e+01, 3.65873580e+01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,ind=f_get_rad(t_img)\n",
    "mean_torch,var_torch=f_torch_image_spectrum(t_img,1,r,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(mean_np,mean_torch,rtol=1e-2),np.allclose(var_np,var_torch,rtol=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy and pytorch match!\n",
    "Feb 4, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-f87a720c5d1e>:5: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370117127/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  y1=torch.rfft(arr,signal_ndim=2,onesided=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([7.9304e+04, 5.9219e+04, 2.9264e+04, 3.0270e+04, 2.3178e+04, 1.9839e+04,\n",
       "        1.8123e+04, 1.7181e+04, 1.2256e+04, 9.6649e+03, 1.0016e+04, 8.0696e+03,\n",
       "        7.3229e+03, 6.6355e+03, 5.8413e+03, 5.4688e+03, 4.1481e+03, 3.7668e+03,\n",
       "        4.0713e+03, 2.7787e+03, 2.0897e+03, 2.2245e+03, 2.3392e+03, 1.9583e+03,\n",
       "        1.6552e+03, 1.5430e+03, 1.2836e+03, 1.1684e+03, 1.2090e+03, 1.1141e+03,\n",
       "        1.0758e+03, 8.5231e+02, 8.9757e+02, 7.8943e+02, 7.4062e+02, 5.4846e+02,\n",
       "        4.7344e+02, 5.0072e+02, 4.4248e+02, 3.7514e+02, 3.4142e+02, 3.1127e+02,\n",
       "        3.0085e+02, 3.1910e+02, 3.3995e+02, 2.8937e+02, 2.7358e+02, 2.4691e+02,\n",
       "        2.5179e+02, 2.2854e+02, 2.0675e+02, 1.9259e+02, 2.0243e+02, 1.8627e+02,\n",
       "        1.6845e+02, 1.6462e+02, 1.5684e+02, 1.4855e+02, 1.4567e+02, 1.3912e+02,\n",
       "        1.3250e+02, 1.3640e+02, 1.2816e+02, 1.1948e+02, 1.0572e+02, 9.6471e+01,\n",
       "        8.2032e+01, 6.9333e+01, 6.7000e+01, 5.4456e+01, 5.8791e+01, 5.1200e+01,\n",
       "        4.6400e+01, 5.8057e+01, 4.9297e+01, 4.7429e+01, 5.0065e+01, 4.7360e+01,\n",
       "        4.2240e+01, 3.9273e+01, 4.0533e+01, 4.7238e+01, 4.5333e+01, 4.6118e+01,\n",
       "        2.9714e+01, 3.9111e+01, 4.0000e+01, 3.7333e+01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    y1=torch.rfft(arr,signal_ndim=2,onesided=False)\n",
    "    real,imag=f_torch_fftshift(y1[:,:,0],y1[:,:,1])    ## last index is real/imag part\n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    \n",
    "#     print(y2.shape)\n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    \n",
    "    return z1\n",
    "f_torch_compute_spectrum(t_img[0,0,:,:],r,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.93044775e+04, 5.92187458e+04, 2.92632039e+04, 3.02707217e+04,\n",
       "       2.31769514e+04, 1.98385587e+04, 1.81240268e+04, 1.71809762e+04,\n",
       "       1.22564506e+04, 9.66494253e+03, 1.00152396e+04, 8.06988950e+03,\n",
       "       7.32282024e+03, 6.63569950e+03, 5.84087104e+03, 5.46882685e+03,\n",
       "       4.14828832e+03, 3.76689817e+03, 4.07139020e+03, 2.77836809e+03,\n",
       "       2.08977916e+03, 2.22444531e+03, 2.33917623e+03, 1.95845573e+03,\n",
       "       1.65534980e+03, 1.54273280e+03, 1.28370677e+03, 1.16819342e+03,\n",
       "       1.20923744e+03, 1.11411874e+03, 1.07582188e+03, 8.52234765e+02,\n",
       "       8.97627462e+02, 7.89272089e+02, 7.40726941e+02, 5.48330201e+02,\n",
       "       4.73606804e+02, 5.00708671e+02, 4.42393397e+02, 3.75179676e+02,\n",
       "       3.41367374e+02, 3.11244553e+02, 3.00790316e+02, 3.19275384e+02,\n",
       "       3.39897092e+02, 2.89407527e+02, 2.73605269e+02, 2.46800690e+02,\n",
       "       2.51869766e+02, 2.28426231e+02, 2.06870006e+02, 1.92603530e+02,\n",
       "       2.02389322e+02, 1.86229348e+02, 1.68418124e+02, 1.64680112e+02,\n",
       "       1.56875834e+02, 1.48445738e+02, 1.45763735e+02, 1.39080094e+02,\n",
       "       1.32450178e+02, 1.36537161e+02, 1.28020344e+02, 1.19667825e+02,\n",
       "       1.05636895e+02, 9.65097819e+01, 8.20085431e+01, 6.93920982e+01,\n",
       "       6.70327547e+01, 5.44070846e+01, 5.87699621e+01, 5.11158296e+01,\n",
       "       4.64792570e+01, 5.81884009e+01, 4.91905245e+01, 4.76188995e+01,\n",
       "       4.98800098e+01, 4.72032005e+01, 4.23049143e+01, 3.89891474e+01,\n",
       "       4.12234933e+01, 4.70504845e+01, 4.59688435e+01, 4.57240015e+01,\n",
       "       2.94733254e+01, 3.99972278e+01, 3.81223084e+01, 3.89119614e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_compute_spectrum(img[0,0,:,:],GLOBAL_MEAN=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_torch_compute_spectrum(arr,r,ind):\n",
    "    \n",
    "    GLOBAL_MEAN=1.0\n",
    "    arr=(arr-GLOBAL_MEAN)/(GLOBAL_MEAN)\n",
    "    \n",
    "    y1=torch.fft.fftn(arr,dim=(-2,-1))\n",
    "#     print(y1.shape)\n",
    "    real,imag=f_torch_fftshift(y1.real,y1.imag)    ## last index is real/imag part\n",
    "    \n",
    "    y2=real**2+imag**2     ## Absolute value of each complex number\n",
    "    \n",
    "    z1=f_torch_get_azimuthalAverage(y2,r,ind)     ## Compute radial profile\n",
    "    \n",
    "    return z1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,ind=f_get_rad(t_img)\n",
    "mean2_torch,var2_torch=f_torch_image_spectrum(t_img,1,r,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
