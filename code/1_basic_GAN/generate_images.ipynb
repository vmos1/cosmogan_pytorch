{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images\n",
    "Sep 2, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/1_basic_GAN/1_main_code/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_load_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    return config\n",
    "\n",
    "def f_init_gdict(gdict,config_dict):\n",
    "    ''' Initialize the global dictionary gdict with values in config file'''\n",
    "    keys1=['workers','nc','nz','ngf','ndf','beta1','kernel_size','stride','g_padding','d_padding','flip_prob']\n",
    "    keys2=['image_size','checkpoint_size','num_imgs','ip_fname','op_loc']\n",
    "    for key in keys1: gdict[key]=config_dict['training'][key]\n",
    "    for key in keys2: gdict[key]=config_dict['data'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inf_img_',op_size=500):\n",
    "    '''Generate images for best saved models\n",
    "     Arguments: gdict, netG, optimizerG, \n",
    "                 ip_fname: name of input file\n",
    "                op_strg: [string name for output file]\n",
    "                op_size: Number of images to generate\n",
    "    '''\n",
    "\n",
    "    nz,device=gdict['nz'],gdict['device']\n",
    "\n",
    "    try:# handling cpu vs gpu\n",
    "        if torch.cuda.is_available(): checkpoint=torch.load(ip_fname)\n",
    "        else: checkpoint=torch.load(ip_fname,map_location=torch.device('cpu'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping generation of images for \",ip_fname)\n",
    "        return\n",
    "    \n",
    "    ## Load checkpoint\n",
    "    if gdict['multi-gpu']:\n",
    "        netG.module.load_state_dict(checkpoint['G_state'])\n",
    "    else:\n",
    "        netG.load_state_dict(checkpoint['G_state'])\n",
    "    \n",
    "    ## Load other stuff\n",
    "    iters=checkpoint['iters']\n",
    "    epoch=checkpoint['epoch']\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(op_size, 1, 1, nz, device=device)\n",
    "    # Generate fake image batch with G\n",
    "    netG.eval() ## This is required before running inference\n",
    "    gen = netG(noise)\n",
    "    gen_images=gen.detach().cpu().numpy()[:,0,:,:]\n",
    "    print(gen_images.shape)\n",
    "    \n",
    "    op_fname='%s_epoch-%s_step-%s.npy'%(op_strg,epoch,iters)\n",
    "\n",
    "    np.save(op_loc+op_fname,gen_images)\n",
    "\n",
    "    print(\"Image saved in \",op_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GAN networks\n",
      "Number of GPUs used 0\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    t0=time.time()\n",
    "    #################################\n",
    "#     args=f_parse_args()\n",
    "    # Manually add args ( different for jupyter notebook)\n",
    "    args=argparse.Namespace()\n",
    "    args.config='1_main_code/config_128.yaml'\n",
    "    args.ngpu=1\n",
    "    args.batchsize=128\n",
    "#     args.spec_loss_flag=True\n",
    "#     args.checkpoint_size=50\n",
    "    args.epochs=1\n",
    "    args.learn_rate=0.0002\n",
    "#     args.mode='fresh'\n",
    "#     args.run_suffix='_nb_test'\n",
    "#     args.deterministic=False\n",
    "#     args.seed='36723705'\n",
    "#     args.lambda1=5.0\n",
    "#     args.save_steps_list=[5,10]\n",
    "\n",
    "    ### Set up ###\n",
    "    config_file=args.config\n",
    "    config_dict=f_load_config(config_file)\n",
    "\n",
    "    # Initilize variables    \n",
    "    gdict={}\n",
    "    f_init_gdict(gdict,config_dict)\n",
    "    \n",
    "    ## Add args variables to gdict\n",
    "    for key in ['ngpu','batchsize','epochs','learn_rate']:\n",
    "        gdict[key]=vars(args)[key]\n",
    "    \n",
    "    gdict['device']=torch.device(\"cuda\" if (torch.cuda.is_available() and gdict['ngpu'] > 0) else \"cpu\")\n",
    "    gdict['ngpu']=torch.cuda.device_count()\n",
    "    gdict['multi-gpu']=True if (gdict['device'].type == 'cuda') and (gdict['ngpu'] > 1) else False \n",
    "\n",
    "    print(\"Building GAN networks\")\n",
    "    # Create Generator\n",
    "    netG = Generator(gdict).to(gdict['device'])\n",
    "    netG.apply(weights_init)\n",
    "    #     print(netG)\n",
    "    # summary(netG,(1,1,64))\n",
    "    \n",
    "    print(\"Number of GPUs used %s\"%(gdict['ngpu']))\n",
    "    if (gdict['multi-gpu']):\n",
    "        netG = nn.DataParallel(netG, list(range(gdict['ngpu'])))\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=gdict['learn_rate'], betas=(gdict['beta1'], 0.999),eps=1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m20201121_050116_full_loss_b64_lr0.0002_good_models\u001b[0m/\n",
      "\u001b[01;34m20201209_204849_lambda0.1\u001b[0m/\n",
      "\u001b[01;34m20201211_121146_lambda0.1\u001b[0m/\n",
      "\u001b[01;34m20201212_190922_cgan_long_run_model1\u001b[0m/\n",
      "\u001b[01;34m20201213_014829_lambda0.1\u001b[0m/\n",
      "\u001b[01;34m20201213_064819_cgan_long_run_model3\u001b[0m/\n",
      "\u001b[01;34m20201213_112641_lambda0.1\u001b[0m/\n",
      "\u001b[01;34m20201213_124441_cgan_long_run_model2\u001b[0m/\n",
      "\u001b[01;34m20201213_173446_lambda0.1_good_models\u001b[0m/\n",
      "\u001b[01;34m20201213_201451_cgan_long_run_model4\u001b[0m/\n",
      "\u001b[01;34m20201214_062259_cgan_long_run_model5\u001b[0m/\n",
      "\u001b[01;34m20201214_073135_lambda1.0\u001b[0m/\n",
      "\u001b[01;34m20201214_121039_lambda1.0\u001b[0m/\n",
      "\u001b[01;34m20201214_132105_nb_test\u001b[0m/\n",
      "\u001b[01;34m20201214_132537_nb_test\u001b[0m/\n",
      "\u001b[01;34m20201214_132932_nb_test\u001b[0m/\n",
      "\u001b[01;34m20201214_133441_nb_test\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 128, 128)\n",
      "Image saved in  inference_spec_epoch-3_step-11890.npy\n"
     ]
    }
   ],
   "source": [
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/'\n",
    "fldr='20201214_121039_lambda1.0'\n",
    "op_loc=main_dir+fldr+'/images/'\n",
    "ip_fname=main_dir+fldr+'/models/checkpoint_11890.tar'\n",
    "f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inference_spec',op_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128)\n",
      "Image saved in  inference_0_epoch-3_step-10460.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_1_epoch-3_step-10460.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_0_epoch-10_step-32880.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_1_epoch-10_step-32880.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_0_epoch-10_step-33230.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_1_epoch-10_step-33230.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_0_epoch-15_step-47070.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_1_epoch-15_step-47070.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_0_epoch-16_step-52700.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_1_epoch-16_step-52700.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_0_epoch-17_step-55860.npy\n",
      "(1000, 128, 128)\n",
      "Image saved in  inference_1_epoch-17_step-55860.npy\n"
     ]
    }
   ],
   "source": [
    "## For multiple steps \n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/'\n",
    "fldr='20201214_121039_lambda1.0'\n",
    "\n",
    "for step in [10460, 32880, 33230, 47070, 52700, 55860]:\n",
    "    for count in range(2): # Repeat inference\n",
    "        op_loc=main_dir+fldr+'/images/'\n",
    "        ip_fname=main_dir+fldr+'/models/checkpoint_{0}.tar'.format(step)\n",
    "        f_gen_images(gdict,netG,optimizerG,ip_fname,op_loc,op_strg='inference_%s'%(count),op_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname=op_loc+'inference_spec_epoch-11_step-37040.npy'\n",
    "# a1=np.load(fname)\n",
    "# print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
