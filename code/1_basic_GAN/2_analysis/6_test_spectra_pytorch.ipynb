{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the issue with losses not matching in 2 codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pickle \n",
    "\n",
    "from matplotlib.colors import LogNorm, PowerNorm, Normalize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from scipy import fftpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchsummary import summary\n",
    "# import torchvision.datasets as dset\n",
    "# import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/cosmogan/1_main_code/')\n",
    "import spec_loss as spc\n",
    "import post_analysis_pandas as post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1, 128, 128), torch.Size([1000, 1, 128, 128]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "img=np.load(ip_fname)[:1000].transpose(0,1,2,3)\n",
    "t_img=torch.from_numpy(img)\n",
    "img.shape,t_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height,width=img.shape[-2:]\n",
    "height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_azimuthalAverage(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    channel, height, width = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "    \n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = np.hypot(x - center[0], y - center[1])\n",
    "\n",
    "    ind = np.argsort(r.flat) ### Get indices that sort the \"r\" array in ascending order.\n",
    "\n",
    "    r_sorted = r.flat[ind]     ### Sort the \"r\" array\n",
    "    \n",
    "    i_sorted = image.flat[ind]   ### Sort the image points according to the radial coordinate\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int = r_sorted.astype(int)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = np.where(deltar)[0]       # location of changed radius\n",
    "    nr = rind[1:] - rind[:-1]        # number of radius bin\n",
    "    \n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    csim = np.cumsum(i_sorted, dtype=float)\n",
    "    tbin = csim[rind[1:]] - csim[rind[:-1]]\n",
    "\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_torch_get_azimuthalAverage_with_batch(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, channel, height, width = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (batch, channel,-1)))\n",
    "    r_sorted = torch.gather(torch.reshape(r, (batch, channel, -1,)),2, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, (batch, channel, -1,)),2, ind)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[:,:,1:] - r_int[:,:,:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[2], (batch, -1))    # location of changes in radius\n",
    "    rind=torch.unsqueeze(rind,1)\n",
    "    nr = (rind[:,:,1:] - rind[:,:,:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "\n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    print(csum.shape,rind.shape,nr.shape)\n",
    "\n",
    "    tbin = torch.gather(csum, 2, rind[:,:,1:]) - torch.gather(csum, 2, rind[:,:,:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "def f_torch_get_azimuthalAverage(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    source: https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = image.shape\n",
    "    # Create a grid of points with x and y coordinates\n",
    "    y, x = np.indices([height,width])\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    # Get the radial coordinate for every grid point. Array has the shape of image\n",
    "    r = torch.tensor(np.hypot(x - center[0], y - center[1]))\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = torch.argsort(torch.reshape(r, (-1,)))\n",
    "    r_sorted = torch.gather(torch.reshape(r, ( -1,)),0, ind)\n",
    "    i_sorted = torch.gather(torch.reshape(image, ( -1,)),0, ind)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int=r_sorted.to(torch.int32)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = torch.reshape(torch.where(deltar)[0], (-1,))    # location of changes in radius\n",
    "    nr = (rind[1:] - rind[:-1]).type(torch.float)       # number of radius bin\n",
    "\n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "\n",
    "    csum = torch.cumsum(i_sorted, axis=-1)\n",
    "    tbin = torch.gather(csum, 0, rind[1:]) - torch.gather(csum, 0, rind[:-1])\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_torch=f_torch_get_azimuthalAverage(t_img[4,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-88aa25a00ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf_torch_get_azimuthalAverage_with_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-cb5635435f9a>\u001b[0m in \u001b[0;36mf_torch_get_azimuthalAverage_with_batch\u001b[0;34m(image, center)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Create a grid of points with x and y coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "# f_torch_get_azimuthalAverage_with_batch(t_img[4,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_numpy=f_get_azimuthalAverage(img[4,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ans_numpy.shape[0]):\n",
    "    a,b=ans_torch[0,i].numpy(),ans_numpy[i]\n",
    "#     print(a,b)\n",
    "    if (np.around(a,4)-np.around(b,4)>1e-4):\n",
    "        print(i,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1, 128, 128]), (88,), torch.Size([88]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_img.shape,ans_numpy.shape,ans_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.8818, -0.8509, -0.7651, -0.7175, -0.6610, -0.6200, -0.7058, -0.7307,\n",
       "         -0.7219, -0.6810, -0.7214, -0.7372, -0.7409, -0.7078, -0.6914, -0.6791,\n",
       "         -0.6965, -0.6789, -0.7007, -0.6639, -0.5953, -0.6014, -0.6526, -0.6779,\n",
       "         -0.7132, -0.7611, -0.7752, -0.7931, -0.7643, -0.7670, -0.7665, -0.7709,\n",
       "         -0.7416, -0.7432, -0.7680, -0.7805, -0.7790, -0.7858, -0.7713, -0.7417,\n",
       "         -0.7357, -0.7360, -0.7490, -0.7813, -0.7864, -0.7880, -0.7626, -0.7332,\n",
       "         -0.7059, -0.7314, -0.7580, -0.7679, -0.7903, -0.7861, -0.7644, -0.7473,\n",
       "         -0.7007, -0.6825, -0.6788, -0.6964, -0.7341, -0.7191, -0.7534, -0.7738,\n",
       "         -0.7574, -0.7201, -0.7186, -0.7235, -0.7397, -0.7337, -0.7142, -0.7072,\n",
       "         -0.7056, -0.6642, -0.6480, -0.6505, -0.6692, -0.6775, -0.6213, -0.6602,\n",
       "         -0.6875, -0.6728, -0.6850, -0.7434, -0.7876, -0.8026, -0.7846, -0.7190]),\n",
       " array([-0.88175743, -0.85091213, -0.76513645, -0.71747654, -0.66103945,\n",
       "        -0.62000012, -0.70582073, -0.73071038, -0.72186795, -0.68096325,\n",
       "        -0.72136302, -0.73718148, -0.7409074 , -0.7078159 , -0.6914162 ,\n",
       "        -0.67907301, -0.69646345, -0.67886689, -0.70072186, -0.66392703,\n",
       "        -0.59534234, -0.60144377, -0.65260039, -0.67786265, -0.71321262,\n",
       "        -0.76107831, -0.77520874, -0.79307323, -0.76426579, -0.76696454,\n",
       "        -0.76650098, -0.77092372, -0.74160739, -0.74323099, -0.76796754,\n",
       "        -0.78051487, -0.77899135, -0.78578518, -0.77128501, -0.74165874,\n",
       "        -0.73574136, -0.73595012, -0.74900031, -0.78127897, -0.78642113,\n",
       "        -0.78801868, -0.76263412, -0.73322755, -0.7058864 , -0.73139031,\n",
       "        -0.75799981, -0.76793171, -0.79029421, -0.7860901 , -0.76443668,\n",
       "        -0.74727502, -0.70071644, -0.68253915, -0.67880527, -0.69637885,\n",
       "        -0.73407892, -0.71913253, -0.75340003, -0.77383124, -0.75740183,\n",
       "        -0.72013949, -0.71859843, -0.72353213, -0.7397259 , -0.73366114,\n",
       "        -0.71414814, -0.70715372, -0.70555191, -0.66419537, -0.64796717,\n",
       "        -0.65053843, -0.66915483, -0.67751225, -0.62127168, -0.66024919,\n",
       "        -0.6875408 , -0.67284623, -0.68500952, -0.74339081, -0.7876111 ,\n",
       "        -0.80261016, -0.78456534, -0.71902537]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_torch,ans_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
