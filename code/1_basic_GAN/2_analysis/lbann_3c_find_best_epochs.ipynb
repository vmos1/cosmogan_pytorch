{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020 \\\n",
    "April 6, 2020 : Major edit to store files in order of epochs \\\n",
    "April 21, 2020: Major edit, added jupyter widgets to compare pixel intensity plots\n",
    "\n",
    "May 8, 2020: Major edit, using all images for a given batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack\n",
    "# from ipywidgets import interact, interact_manual,fixed, SelectMultiple, IntText, IntSlider, FloatSlider,SelectionSlider,BoundedIntText\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 15101 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-8) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Other transformatino functinos\n",
    "# ### Transformation functions for image pixel values\n",
    "\n",
    "# def f_transform_new(x):\n",
    "#     if x<=50:\n",
    "#         a=0.03; b=-1.0\n",
    "#         return a*x+b\n",
    "#     elif x>50: \n",
    "#         a=0.5/np.log(300)\n",
    "#         b=0.5-a*np.log(50)\n",
    "#         return a*np.log(x)+b\n",
    "\n",
    "# def f_invtransform_new(y):\n",
    "#     if y<=0.5:\n",
    "#         a=0.03;b=-1.0\n",
    "#         return (y-b)/a\n",
    "#     elif y>0.5: \n",
    "#         a=0.5/np.log(300)\n",
    "#         b=0.5-a*np.log(50)\n",
    "#         return np.exp((y-b)/a)\n",
    "    \n",
    "\n",
    "# def f_transform(x):\n",
    "#     return np.vectorize(f_transform_new)(x)\n",
    "\n",
    "# def f_invtransform(s):\n",
    "#     return np.vectorize(f_invtransform_new)(s)\n",
    "\n",
    "# f_transform_new(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_files_df_sorted():\n",
    "    '''\n",
    "    Module to create Dataframe with filenames for each epoch and step\n",
    "    Sorts by step and epoch\n",
    "    '''\n",
    "    \n",
    "    ## Get images files and .npy arrays for each image in dump_outs folder\n",
    "    t1=time.time()\n",
    "    files_dict={}\n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "    for key,file_strg in zip(keys,file_strg_lst):\n",
    "        files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "        if files_dict[key].shape[0]>1000 : \n",
    "            print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "    df_files=pd.DataFrame([])\n",
    "    dict1={}\n",
    "    t1=time.time()\n",
    "    ### First get sorted Dataframe with file names\n",
    "    for key in keys: \n",
    "        files_arr=files_dict[key]  # Get array of files\n",
    "        print(key,len(files_arr))\n",
    "        for fname in files_arr:\n",
    "            ### Extract the Epoch number and step number from the file name\n",
    "            dict1['img_type']=key\n",
    "            dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "            dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "            dict1['fname']=fname\n",
    "\n",
    "            df_files=df_files.append(dict1,ignore_index=True)\n",
    "    ## Sort values\n",
    "    df_files=df_files.sort_values(by=['img_type','epoch','step']).reset_index(drop=True)\n",
    "    # df_files\n",
    "    t2=time.time()\n",
    "    print(\"Time for Sorting\",t2-t1)\n",
    "    \n",
    "    return df_files\n",
    "\n",
    "\n",
    "def f_filter_epoch(df_input,num_sliced=1):\n",
    "    '''\n",
    "    Get just the last few stored step images for each epoch\n",
    "    '''\n",
    "    print('Extracting last %s steps of each epoch'%(num_sliced))\n",
    "    df_output=pd.DataFrame([])\n",
    "    for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.img_type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "\n",
    "        for epoch in epochs:### Extract the last few steps in each epoch\n",
    "            df2=df1[df1.epoch==epoch]\n",
    "            df_output=df_output.append(df2.iloc[-num_sliced:])  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def f_get_images_df(df_files):\n",
    "    '''\n",
    "    Read dataframe with file names, read files and create new dataframe with images as numpy arrays\n",
    "    Also computes number of images with intensity beyond a cutoff\n",
    "    '''\n",
    "    \n",
    "    def f_row(df_row):\n",
    "        '''\n",
    "        Extract image\n",
    "        '''\n",
    "        fname,key=df_row.fname,df_row.img_type\n",
    "        a1=np.load(fname)\n",
    "        if key.endswith('input'): \n",
    "            size=np.int(np.sqrt(a1.shape[-1])) ### Extract size of images (=128)\n",
    "            batch_size=a1.shape[0] ### Number of batches\n",
    "            samples=a1.reshape(batch_size,size,size)\n",
    "        elif key.endswith('gen') : samples=a1[:,0,:,:]\n",
    "        else : raise SystemError\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def f_high_pixel(df_row,cutoff=0.9966):\n",
    "        '''\n",
    "        Get number of images with a pixel about max cut-off value\n",
    "        '''\n",
    "        max_arr=np.amax(df_row.images,axis=(1,2))\n",
    "        num_large=max_arr[max_arr>cutoff].shape[0]\n",
    "\n",
    "        return num_large\n",
    "    \n",
    "    t1=time.time()\n",
    "    ##### Create new Dataframe with sorted images\n",
    "    df=df_files.copy()\n",
    "    df['images']=df.apply(lambda row: f_row(row), axis=1)\n",
    "    t2=time.time()\n",
    "    print(\"Time for Reading images\",t2-t1)\n",
    "    \n",
    "    ### Store the number of images with large pixel value\n",
    "    cutoff=0.9966\n",
    "    df['num_large']=df.apply(lambda row: f_high_pixel(row,cutoff), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def f_get_sample_epochs(df,img_type,start_epoch=None,end_epoch=None):\n",
    "    '''\n",
    "    Module to extract images for a range of epochs given a dataframe\n",
    "    '''\n",
    "    if start_epoch==None and end_epoch==None:\n",
    "        max_epoch=np.int(np.max(df.epoch.values))\n",
    "        print(max_epoch)\n",
    "        start_epoch=0; end_epoch=max_epoch\n",
    "#     if end_epoch==None: end_epoch=start_epoch+1\n",
    "    \n",
    "    arr=df[(df.epoch>=start_epoch) & (df.epoch<=end_epoch) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def f_compute_chisqr(df):\n",
    "    ''' Compute chi-sqr of pixel intensity histogram for each row\n",
    "    Uses the module f_pixel_intensity to compute histograms\n",
    "    '''\n",
    "    \n",
    "    def f_chisqr(df_row,val_hist,val_err,max_val=2000):\n",
    "        ''' Compute chi-sqr of rows wrt to input data'''\n",
    "        \n",
    "        val_dr=val_hist.copy()\n",
    "        val_dr[val_dr<=0.]=1.0    ### Avoiding division by zero for zero bins\n",
    "#         print(val_dr)\n",
    "        sample=f_invtransform(df_row.images)[0]\n",
    "        ### Compute pixel histogram for row   ### !!! Ensure both pixel histograms have save bins and normalization !!! ###\n",
    "        gen_hist,gen_err=f_pixel_intensity(sample,plot=False,normalize=True,bins=50,hist_range=(0,max_val),mode='avg')\n",
    "        ### Compute chi-sqr\n",
    "        sq_diff=(gen_hist-val_hist)**2\n",
    "        ###  chi_sqr :: sum((Obs-Val)^2/(Val))\n",
    "        chi_sqr1=np.sum(np.divide(sq_diff[:25],val_dr[:25]**2))\n",
    "        chi_sqr2=np.sum(np.divide(sq_diff[:25],1.0))\n",
    "        chi_sqr3=np.sum(gen_err[:25])/np.sum(val_err[:25])  ## measures total spread in histograms wrt to input data\n",
    "        \n",
    "        return chi_sqr1,chi_sqr2,chi_sqr3\n",
    "    \n",
    "    ### Get pixel histogram of all input data\n",
    "    samples_input=f_invtransform(f_get_sample_epochs(df,'train_input'))    \n",
    "    max_val=np.max(samples_input)\n",
    "    val_hist,val_err=f_pixel_intensity(samples_input,plot=False,normalize=True,bins=50,hist_range=(0,max_val),mode='avg')\n",
    "    del samples_input\n",
    "    \n",
    "    ### Get chi-sqr for each row (step-epoch) for generated data\n",
    "    chi_sqrs=df.apply(lambda row: f_chisqr(row,val_hist=val_hist,val_err=val_err,max_val=2000), axis=1).values\n",
    "    chi_vals=np.array(list(zip(*chi_sqrs)))  ## transposing list of list \n",
    "\n",
    "    df['chi_sqr1'],df['chi_sqr2'],df['chi_sqr3']=chi_vals[0],chi_vals[1],chi_vals[2]\n",
    "    print(type(chi_sqrs))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200513_121910_peters_dataset/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200423_122631_exagan_modified_paddding'\n",
    "fldr_name='20200424_083456_exagan_modified_padding_2'\n",
    "fldr_name='20200506_121613_exagan_200k_samples'\n",
    "fldr_name='20200513_121910_peters_dataset'\n",
    "# fldr_name='20200526_131209_exagan'\n",
    "\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen 902\n",
      "train_input 902\n",
      "val_gen 226\n",
      "val_input 226\n",
      "Time for Sorting 6.9088966846466064\n",
      "Time for Reading images 203.20202088356018\n",
      "(2256, 6)\n"
     ]
    }
   ],
   "source": [
    "### Get dataframe with file names, sorted by epoch and step\n",
    "df_files=f_get_files_df_sorted()\n",
    "\n",
    "### Slice out rows to keep only the last few steps for each epoch.\n",
    "# df_files=f_filter_epoch(df_files,num_sliced=2)\n",
    "\n",
    "#############################################################\n",
    "### Read images one by one into a numpy array and create a new DataFrame\n",
    "df_full=f_get_images_df(df_files)\n",
    "print(df_full.shape)\n",
    "\n",
    "# ### Filter to keep just one step per epoch\n",
    "# df_full=f_filter_epoch(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>img_type</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>59.0</td>\n",
       "      <td>18368.0</td>\n",
       "      <td>val_input</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>59.0</td>\n",
       "      <td>18450.0</td>\n",
       "      <td>val_input</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch     step   img_type  \\\n",
       "0       0.0      0.0  train_gen   \n",
       "1       0.0     82.0  train_gen   \n",
       "2254   59.0  18368.0  val_input   \n",
       "2255   59.0  18450.0  val_input   \n",
       "\n",
       "                                                  fname  \n",
       "0     /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  \n",
       "1     /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  \n",
       "2254  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  \n",
       "2255  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_files.head(20)\n",
    "df_full[['epoch','step','img_type','fname']].iloc[[0,1,-2,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "<class 'numpy.ndarray'>\n",
      "Time to compute chi-sqr 118.07351684570312\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "# df1=f_compute_chisqr(df.loc[[0,1,2,3,100,200]])\n",
    "df_full=f_compute_chisqr(df_full)\n",
    "t2=time.time()\n",
    "print(\"Time to compute chi-sqr\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi_sqr1</th>\n",
       "      <th>chi_sqr2</th>\n",
       "      <th>chi_sqr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2256.000000</td>\n",
       "      <td>2.256000e+03</td>\n",
       "      <td>2.256000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1366.667909</td>\n",
       "      <td>4.176086e-05</td>\n",
       "      <td>8.698744e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14995.225498</td>\n",
       "      <td>3.929137e-07</td>\n",
       "      <td>4.720700e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.477720</td>\n",
       "      <td>4.122146e-05</td>\n",
       "      <td>1.737669e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.472812</td>\n",
       "      <td>4.148977e-05</td>\n",
       "      <td>5.370917e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.630380</td>\n",
       "      <td>4.167122e-05</td>\n",
       "      <td>7.903472e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.816087</td>\n",
       "      <td>4.194697e-05</td>\n",
       "      <td>1.103429e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>331934.253246</td>\n",
       "      <td>4.467162e-05</td>\n",
       "      <td>3.337995e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chi_sqr1      chi_sqr2      chi_sqr3\n",
       "count    2256.000000  2.256000e+03  2.256000e+03\n",
       "mean     1366.667909  4.176086e-05  8.698744e+01\n",
       "std     14995.225498  3.929137e-07  4.720700e+01\n",
       "min        18.477720  4.122146e-05  1.737669e-11\n",
       "25%        21.472812  4.148977e-05  5.370917e+01\n",
       "50%        22.630380  4.167122e-05  7.903472e+01\n",
       "75%        23.816087  4.194697e-05  1.103429e+02\n",
       "max    331934.253246  4.467162e-05  3.337995e+02"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[['chi_sqr1','chi_sqr2','chi_sqr3']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-520e13bd7da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sliced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi_sqr1\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi_sqr3\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chi_sqr1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chi_sqr2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chi_sqr3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'img_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_sliced=df[(df.chi_sqr1<30)&(df.chi_sqr3>88)][['epoch','step','chi_sqr1','chi_sqr2','chi_sqr3','img_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch plots\n",
    "fig=plt.figure(figsize=(10,3))\n",
    "# for img_type in ['val_input','val_gen','train_input','train_gen']:\n",
    "# for img_type in ['train_gen','train_input']:\n",
    "# for img_type in ['val_gen','val_input']:\n",
    "for img_type in ['train_gen']:\n",
    "    df_temp=df_sliced[df_sliced.img_type==img_type]\n",
    "    print(df_temp.shape)\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.plot(df_temp.epoch.values,df_temp['chi_sqr1'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('chisqr1')\n",
    "    \n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.plot(df_temp.epoch.values,df_temp['chi_sqr2'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('chisqr2')\n",
    "\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.plot(df_temp.epoch.values,df_temp['chi_sqr3'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('Deviation in histograms')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step plots\n",
    "fig=plt.figure(figsize=(10,3))\n",
    "# for img_type in ['val_input','val_gen','train_input','train_gen']:\n",
    "# for img_type in ['train_gen','train_input']:\n",
    "# for img_type in ['val_gen','val_input']:\n",
    "for img_type in ['train_gen']:\n",
    "    df_temp=df[df.img_type==img_type]\n",
    "    print(df_temp.shape)\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.plot(df_temp.step.values,df_temp['chi_sqr1'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('chisqr1')\n",
    "    \n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.plot(df_temp.step.values,df_temp['chi_sqr2'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('chisqr2')\n",
    "\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.plot(df_temp.step.values,df_temp['chi_sqr3'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('Deviation in histograms')\n",
    "\n",
    "plt.xlabel('Step')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Pixel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot number of high pixel images\n",
    "# df.plot('epoch','num_large',kind='scatter')\n",
    "# df=df_full.copy()\n",
    "plt.figure()\n",
    "plt.plot(df[df.img_type=='val_gen'].step,df[df.img_type=='val_gen'].num_large,linestyle='',marker='*')\n",
    "plt.xlabel('Steps in Epochs')\n",
    "plt.ylabel('Number of large pixel images from a batch set of 128 images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(samples2,'s2',normalize=True,mode='simple',bins=50)1\n",
    "# f_compare_pixel_intensity([samples2[20:60],samples4,['s2','s4'],normalize=normalize,log_scale=log_scale, mode=mode,bins=bins)\n",
    "# f_compute_spectrum(samples2)\n",
    "# f_compare_spectrum([samples2[20:60],samples4],['s2','s4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_individual(df,img_type='val_gen',idx_range=(0,50),Fig_type='pixel',normalize=True,log_scale=True,rescale=True,mode='avg'):\n",
    "    '''\n",
    "    Module to plot pixel intensity or power spectrum for a given sample set of images\n",
    "    Options for normalization, log-scal, and rescale\n",
    "    Rescale converts image pixel values from (-1,1) to the original pixel range\n",
    "    2 Fig_type: pixel-> pixel intensity and spectrum -> power spectrum\n",
    "    '''\n",
    "    \n",
    "    start,end=idx_range[0],idx_range[1]\n",
    "    print('Index Range %s - %s'%(start,end))\n",
    "    \n",
    "    try :\n",
    "        sliced_arr=f_get_sample_epochs(df,img_type=img_type,start_epoch=start,end_epoch=end)\n",
    "        if sliced_arr.shape[0]<1:\n",
    "            print('Input indices %s %s are invalid.\\nUsing full array'%(start,end))\n",
    "            start0,end=0,'end'\n",
    "            sliced_arr=f_get_sample_epochs(df,img_type=img_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    ### Crop out large pixel values\n",
    "    sliced_arr=np.array([arr for arr in sliced_arr if np.max(arr)<=0.994])\n",
    "\n",
    "    if rescale: ### Converting from pixel intensity range (-1,1) to original range\n",
    "        sliced_arr=f_invtransform(sliced_arr)\n",
    "    print('Array size used',sliced_arr.shape)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_pixel_intensity(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),normalize=normalize,log_scale=log_scale,mode=mode)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compute_spectrum(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),log_scale=log_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(f_widget_individual,df=fixed(df),img_type=fixed('val_gen'),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),mode=['avg','simple'],\n",
    "                idx_range=IntRangeSlider(value=(0,60),min=0,max=80,step=1),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_widget_compare(sample_names,sample_dict,Fig_type='pixel',rescale=True,log_scale=True,bins=25,mode='avg',normalize=True):\n",
    "    '''\n",
    "    Module to make widget plots for pixel intensity or spectrum comparison for multiple sample sets\n",
    "    '''\n",
    "    \n",
    "    ### Crop out large pixel values\n",
    "    for key in sample_names:\n",
    "        print(sample_dict[key].shape)\n",
    "        sample_dict[key]=np.array([arr for arr in sample_dict[key] if np.max(arr)<=0.994])\n",
    "        print(sample_dict[key].shape)\n",
    "    \n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "        \n",
    "    hist_range=(0,0.996)\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "        hist_range=(0,2000)\n",
    "\n",
    "    \n",
    "    assert Fig_type in ['pixel','spectrum'],\"Invalid mode %s\"%(mode)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins,hist_range=hist_range)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compare_spectrum(img_lst=img_list,label_lst=label_list,log_scale=log_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list,labels_list=f_get_sample_epochs(df,'val_gen',10)\n",
    "\n",
    "img_list,labels_list=[],[]\n",
    "# for epoch_range in [(0,4),(17,20),(25,27),(34,37),(44,51),(53,59)]:\n",
    "for epoch_range in [(i,i+2) for i in range(0,60,2)]:\n",
    "    start,end=epoch_range[0],epoch_range[1]\n",
    "    img_list.append(f_get_sample_epochs(df,'val_gen',start,end))\n",
    "    labels_list.append('%s:%s'%(str(start),str(end)))\n",
    "\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "### Compare with input\n",
    "dict_samples['val input']=f_get_sample_epochs(df,img_type='val_input')\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare image types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "start,end=56,57\n",
    "samples1=f_get_sample_epochs(df,'val_gen',start,end)\n",
    "samples2=f_get_sample_epochs(df,'val_input')\n",
    "samples3=f_get_sample_epochs(df,'train_gen',start,end)\n",
    "samples4=f_get_sample_epochs(df,'train_input')\n",
    "\n",
    "print(np.max(samples1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_samples={'s1':samples1, 's2': samples2, 's3': samples3, 's4':samples4}\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
