{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to explore structure of hdf5 data files\n",
    "\n",
    "June 9, 2020: Adding gaussian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from scipy.ndimage import gaussian_filter   ### For gausian filtering\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explore the hdf5 file\n",
    "def f_explore_file(fname):\n",
    "    '''\n",
    "    Explore the structure of the hdf5 file\n",
    "    Attributes are : ['dataset_tag','seed9','universe_tag']\n",
    "    The Keys are : ['full', 'namePar', 'physPar', 'redshifts', 'unitPar']\n",
    "    \n",
    "    'full' is an array of shape (512,512,512,4)\n",
    "    The last index 4 corresponds to red-shift. Eg. 0, 0.5, 1.5, 3.0\n",
    "    '''\n",
    "    dta=h5py.File(fname,'r') \n",
    "    \n",
    "    ### Attributes\n",
    "    attrs=dta.attrs\n",
    "    print('Attributes',[(i,attrs[i]) for i in attrs])\n",
    "    \n",
    "    ### Keys\n",
    "    keys=dta.keys()\n",
    "    print('\\nKeys',keys)\n",
    "    \n",
    "    print(\"\\nThe key: 'full' \")\n",
    "    print('Shape of the array',dta['full'].shape)\n",
    "    \n",
    "    print('\\nOther keys')\n",
    "    for key in ['namePar', 'physPar', 'redshifts', 'unitPar']:\n",
    "        print(key,dta[key][:])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample exploration of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes [('dataset_tag', b'4parE'), ('seed9', 16305120), ('universe_tag', b'4parE_33007379-11')]\n",
      "\n",
      "Keys <KeysViewHDF5 ['full', 'namePar', 'physPar', 'redshifts', 'unitPar']>\n",
      "\n",
      "The key: 'full' \n",
      "Shape of the array (512, 512, 512, 4)\n",
      "\n",
      "Other keys\n",
      "namePar [b'Omega_m' b'sigma_8' b'N_spec' b'H_0']\n",
      "physPar [  0.15   0.5    0.96 100.  ]\n",
      "redshifts [0.  0.5 1.5 3. ]\n",
      "unitPar [-0.5        -0.375       0.          0.42857143]\n"
     ]
    }
   ],
   "source": [
    "fname='/global/cfs/cdirs/m3363/www/cosmoUniverse_2020_11_4parE_cGAN/Sg0.5/univ_ics_2019-03_a10582192.hdf5'\n",
    "fname='/global/cfs/cdirs/m3363/www/cosmoUniverse_2020_08_4parEgrid/Om0.15_Sg0.5_H100.0/univ_ics_2019-03_a16305120.hdf5'\n",
    "f_explore_file(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512**3/(64**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in list of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Location of hdf5 files\n",
    "data_dir='/global/project/projectdirs/m3363/www/cosmoUniverse_2019_08_const/'\n",
    "### Extract list of hdf5 files\n",
    "f_list=glob.glob(data_dir+'*.hdf5')\n",
    "len(f_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.File(f_list[0],'r')['full'][:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in f_list[:5]:\n",
    "#     f_explore_file(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Gaussian filtering\n",
    "**Gaussian blurring**: https://en.wikipedia.org/wiki/Gaussian_blur#:~:text=In%20image%20processing%2C%20a%20Gaussian,image%20noise%20and%20reduce%20detail \\\n",
    "**Paper using it**: https://arxiv.org/abs/1801.09070\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta=h5py.File(fname,'r') \n",
    "arr=np.array(dta['full'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.9 s ± 1.38 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit filtered_arr=gaussian_filter(arr, sigma=0.5,mode='wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_compare_pixel_intensity(img_lst,label_lst=['img1','img2'],bkgnd_arr=None,log_scale=True, normalize=True, mode='avg',bins=25, hist_range=None):\n",
    "    '''\n",
    "    Module to compute and plot histogram for pixel intensity of images\n",
    "    Has 2 modes : simple and avg\n",
    "    simple mode: No errors. Just flatten the input image array and compute histogram of full data\n",
    "    avg mode(Default) : \n",
    "        - Compute histogram for each image in the image array\n",
    "        - Compute errors across each histogram \n",
    "    bkgnd_arr : histogram of this array is plotting with +/- sigma band\n",
    "    \n",
    "    '''\n",
    "\n",
    "    norm=normalize # Whether to normalize the histogram\n",
    "    \n",
    "    def f_batch_histogram(img_arr,bins,norm,hist_range):\n",
    "        ''' Compute histogram statistics for a batch of images'''\n",
    "        \n",
    "        ## Extracting the range. This is important to ensure that the different histograms are compared correctly\n",
    "        if hist_range==None : ulim,llim=np.max(img_arr),np.min(img_arr)\n",
    "        else: ulim,llim=hist_range[1],hist_range[0]\n",
    "#         print(ulim,llim)\n",
    "        ### array of histogram of each image\n",
    "        hist_arr=np.array([np.histogram(arr.flatten(), bins=bins, range=(llim,ulim), density=norm) for arr in img_arr]) ## range is important\n",
    "        hist=np.stack(hist_arr[:,0]) # First element is histogram array\n",
    "#         print(hist.shape)\n",
    "\n",
    "        bin_list=np.stack(hist_arr[:,1]) # Second element is bin value \n",
    "        ### Compute statistics over histograms of individual images\n",
    "        mean,err=np.mean(hist,axis=0),np.std(hist,axis=0)/np.sqrt(hist.shape[0])\n",
    "        bin_edges=bin_list[0]\n",
    "        centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "#         print(bin_edges,centers)\n",
    "\n",
    "        return mean,err,centers\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    ## Plot background distribution\n",
    "    if bkgnd_arr is not None:\n",
    "        if mode=='simple':\n",
    "            hist, bin_edges = np.histogram(bkgnd_arr.flatten(), bins=bins, density=norm, range=hist_range)\n",
    "            centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            plt.errorbar(centers, hist, color='k',marker='*',linestyle=':', label='bkgnd')\n",
    "\n",
    "        elif mode=='avg':\n",
    "            ### Compute histogram for each image. \n",
    "            mean,err,centers=f_batch_histogram(bkgnd_arr,bins,norm,hist_range)\n",
    "            plt.plot(centers,mean,linestyle=':',color='k',label='bkgnd')\n",
    "            plt.fill_between(centers, mean - err, mean + err, color='k', alpha=0.4)\n",
    "    \n",
    "    ### Plot the rest of the datasets\n",
    "    for img,label in zip(img_lst,label_lst):     \n",
    "        if mode=='simple':\n",
    "            hist, bin_edges = np.histogram(img.flatten(), bins=bins, density=norm, range=hist_range)\n",
    "            centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            plt.errorbar(centers, hist, fmt='o-', label=label)\n",
    "\n",
    "        elif mode=='avg':\n",
    "            ### Compute histogram for each image. \n",
    "            mean,err,centers=f_batch_histogram(img,bins,norm,hist_range)\n",
    "#             print('Centers',centers)\n",
    "            plt.errorbar(centers,mean,yerr=err,fmt='o-',label=label)\n",
    "\n",
    "    if log_scale: \n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Pixel value')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Pixel Intensity Histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dc5e7f984545a19318120773be44c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_compare_pixel_intensity([arr,filtered_arr],label_lst=['raw','filtered'],mode='simple',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/3d_data/dataset5_3dcgan_4univs_64cube_simple_splicing/Om0.3_Sg0.5_H70.0.npy'\n",
    "a1=np.load(fname,mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 1, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512**3/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
