{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch LBANN traing jobs\n",
    "Code to create a batch script for launching jobs on cori GPU\n",
    "\n",
    "Sep 1, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob,time\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/1_basic_GAN/new_run_scripts\n"
     ]
    }
   ],
   "source": [
    "start_dir=os.getcwd()\n",
    "print(start_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define machine and code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine='cori'\n",
    "img_size=128\n",
    "assert machine in ['cori','summit'], \"Error%s\"%(machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ref_launch.yaml and define dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_cfile=start_dir+'/ref_launch.yaml'\n",
    "\n",
    "with open(launch_cfile) as f:\n",
    "    config_dict= yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'install_loc': '/global/cfs/cdirs/m3363/lbann/tom_lbann_install_20210223', 'spack_loc': '/global/cfs/cdirs/m3363/lbann/tom_spack', 'code_dir': '/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/1_basic_GAN/1_main_code/DDP_new_loss/', 'config': 'config_2dgan.yaml', 'staging_loc': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/', 'nodes': 1, 'gpus_per_node': 8, 'time': '4:00:00', 'job_name': 'ddp_1node_2_basic_loss', 'cpus_per_node': 80}\n"
     ]
    }
   ],
   "source": [
    "## Read ref_launch.yaml\n",
    "dict_pars=config_dict[machine][img_size]\n",
    "dict_pars.update({'nodes':1,'gpus_per_node':8,'time':'4:00:00','job_name':'ddp_1node_2_basic_loss'})\n",
    "\n",
    "dict_pars['cpus_per_node']=dict_pars['gpus_per_node']*10\n",
    "print(dict_pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dict_pars['nodes']==1: \n",
    "    cori_strg='''#!/bin/bash\n",
    "#################\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --qos=regular\n",
    "#SBATCH --output=slurm-%x-%j.out\n",
    "#SBATCH --constraint=gpu\n",
    "#SBATCH --account=m3363\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task={cpus_per_node}\n",
    "#SBATCH --gpus-per-task={gpus_per_node}\n",
    "#SBATCH --time={time}\n",
    "#SBATCH --job-name={job_name}\n",
    "\n",
    "echo \"--start date\" `date` `date +%s`\n",
    "echo '--hostname ' $HOSTNAME\n",
    "\n",
    "### Initial setup\n",
    "module load cgpu\n",
    "module load pytorch/v1.6.0-gpu  \n",
    "\n",
    "### Run the main code\n",
    "code_dir={code_dir}\n",
    "\n",
    "srun -n1 python -m torch.distributed.launch --nproc_per_node={gpus_per_node} $code_dir/main.py --config $code_dir/{config}\n",
    "echo \"--end date\" `date` `date +%s`\n",
    "    '''\n",
    "else: \n",
    "    cori_strg='''#!/bin/bash -l\n",
    "#################\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --qos=regular\n",
    "#SBATCH --output=slurm-%x-%j.out\n",
    "#SBATCH --constraint=gpu\n",
    "#SBATCH --account=m3363\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task={cpus_per_node}\n",
    "#SBATCH --gpus-per-task={gpus_per_node}\n",
    "#SBATCH --time={time}\n",
    "#SBATCH --job-name={job_name}\n",
    "\n",
    "echo \"--start date\" `date` `date +%s`\n",
    "echo '--hostname ' $HOSTNAME\n",
    "\n",
    "### Set up\n",
    "# Configuration\n",
    "nproc_per_node={gpus_per_node}\n",
    "code_dir={code_dir}\n",
    "# Load software\n",
    "module load cgpu\n",
    "module load pytorch/1.7.0-gpu\n",
    "\n",
    "# Setup node list\n",
    "nodes=$(scontrol show hostnames $SLURM_JOB_NODELIST) # Getting the node names\n",
    "nodes_array=( $nodes )\n",
    "master_node=${{nodes_array[0]}}\n",
    "master_addr=$(srun --nodes=1 --ntasks=1 -w $master_node hostname --ip-address)\n",
    "worker_num=$(($SLURM_JOB_NUM_NODES))\n",
    "\n",
    "echo $nodes\n",
    "echo $master_addr\n",
    "echo $worker\n",
    "# Loop over nodes and submit training tasks\n",
    "for ((  node_rank=0; node_rank<$worker_num; node_rank++ ))\n",
    "do\n",
    "  node=${{nodes_array[$node_rank]}}\n",
    "  echo \"Submitting node # $node_rank, $node\"\n",
    "\n",
    "  # Launch one SLURM task per node, and use torch distributed launch utility\n",
    "  # to spawn training worker processes; one per GPU\n",
    "  srun -N 1 -n 1 -w $node python -m torch.distributed.launch \\\n",
    "    --nproc_per_node=$nproc_per_node --nnodes=$SLURM_JOB_NUM_NODES \\\n",
    "    --node_rank=$node_rank --master_addr=$master_addr \\\n",
    "    ${{code_dir}}/main.py --config ${{code_dir}}{config} &\n",
    "\n",
    "  pids[${{node_rank}}]=$!\n",
    "done\n",
    "\n",
    "# Wait for completion\n",
    "for pid in ${{pids[*]}}\n",
    "do\n",
    "    wait $pid\n",
    "done\n",
    "\n",
    "echo \"--end date\" `date` `date +%s`\n",
    "    '''\n",
    "\n",
    "### String for summit\n",
    "summit_strg='''\n",
    "\n",
    "echo \"--start date\" `date` `date +%s`\n",
    "echo '--hostname ' $HOSTNAME\n",
    "\n",
    "\n",
    "### Run the main code\n",
    "code_dir={code_dir}\n",
    "export config_file=$code_dir'/{config}'\n",
    "python $code_dir/train_exagan.py\n",
    "\n",
    "echo \"--end date\" `date` `date +%s`\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bash string\n",
    "if machine=='cori':\n",
    "    bash_strg=cori_strg.format(**dict_pars)\n",
    "elif machine=='summit':\n",
    "    bash_strg=summit_strg.format(**dict_pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/batch_train_ddptest.sh\n"
     ]
    }
   ],
   "source": [
    "fname='batch_train_ddptest.sh'\n",
    "filename=dict_pars['staging_loc']+fname\n",
    "with open (filename,'w') as f:\n",
    "    f.write(bash_strg)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Move to staging locations in project space:\n",
    "# os.chdir(dict_pars['staging_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#################\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --qos=regular\n",
      "#SBATCH --output=slurm-%x-%j.out\n",
      "#SBATCH --constraint=gpu\n",
      "#SBATCH --account=m3363\n",
      "#SBATCH --ntasks-per-node=1\n",
      "#SBATCH --cpus-per-task=80\n",
      "#SBATCH --gpus-per-task=8\n",
      "#SBATCH --time=4:00:00\n",
      "#SBATCH --job-name=ddp_1node_2_basic_loss\n",
      "\n",
      "echo \"--start date\" `date` `date +%s`\n",
      "echo '--hostname ' $HOSTNAME\n",
      "\n",
      "### Initial setup\n",
      "module load cgpu\n",
      "module load pytorch/v1.6.0-gpu  \n",
      "\n",
      "### Run the main code\n",
      "code_dir=/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/code/1_basic_GAN/1_main_code/DDP_new_loss/\n",
      "\n",
      "srun -n1 python -m torch.distributed.launch --nproc_per_node=8 $code_dir/main.py --config $code_dir/config_2dgan.yaml\n",
      "echo \"--end date\" `date` `date +%s`\n",
      "    "
     ]
    }
   ],
   "source": [
    "%%bash -s \"$filename\" ## Use python variable in bash\n",
    "cat $1\n",
    "chmod +x $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to cori GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s \"$filename\" ## Use python variable in bash\n",
    "# module load cgpu\n",
    "# sbatch $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3125.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200000*0.25/(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
