{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing cnn for classifying universes\n",
    "Nov 10, 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_load_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    return config\n",
    "\n",
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4.) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Generator Code\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, nz,nc,ndf,n_classes,kernel_size,stride,d_padding):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            # nn.Conv2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "            nn.Conv2d(nc, ndf,kernel_size, stride, d_padding,  bias=True),\n",
    "            nn.BatchNorm2d(ndf,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size, stride, d_padding, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 2,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size, stride, d_padding, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 4,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size, stride, d_padding, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8,eps=1e-05, momentum=0.9, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nc*ndf*8*8*8, n_classes)\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'GAN', 'data': {'ip_fname': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy', 'op_loc': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/', 'image_size': 128, 'checkpoint_size': 1, 'num_imgs': 200000}, 'training': {'workers': 2, 'nc': 1, 'nz': 64, 'ngf': 64, 'ndf': 64, 'lr': 0.0002, 'beta1': 0.5, 'kernel_size': 5, 'stride': 2, 'g_padding': 2, 'd_padding': 2, 'flip_prob': 0.01}}\n",
      "Random Seed:  21245\n",
      "Device: cuda\n",
      "Building CNN\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=32768, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,664\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "         LeakyReLU-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]         204,928\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "         LeakyReLU-6          [-1, 128, 32, 32]               0\n",
      "            Conv2d-7          [-1, 256, 16, 16]         819,456\n",
      "       BatchNorm2d-8          [-1, 256, 16, 16]             512\n",
      "         LeakyReLU-9          [-1, 256, 16, 16]               0\n",
      "           Conv2d-10            [-1, 512, 8, 8]       3,277,312\n",
      "      BatchNorm2d-11            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-12            [-1, 512, 8, 8]               0\n",
      "          Flatten-13                [-1, 32768]               0\n",
      "           Linear-14                    [-1, 6]         196,614\n",
      "================================================================\n",
      "Total params: 4,501,894\n",
      "Trainable params: 4,501,894\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 11.50\n",
      "Params size (MB): 17.17\n",
      "Estimated Total Size (MB): 28.74\n",
      "----------------------------------------------------------------\n",
      "Number of GPUs used 1\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark=True\n",
    "t0=time.time()\n",
    "#################################\n",
    "###### Initialize variables #######\n",
    "config_file='config_128.yaml'\n",
    "config_dict=f_load_config(config_file)\n",
    "print(config_dict)\n",
    "\n",
    "workers=config_dict['training']['workers']\n",
    "nc,nz,ngf,ndf=config_dict['training']['nc'],config_dict['training']['nz'],config_dict['training']['ngf'],config_dict['training']['ndf']\n",
    "lr,beta1=config_dict['training']['lr'],config_dict['training']['beta1']\n",
    "kernel_size,stride=config_dict['training']['kernel_size'],config_dict['training']['stride']\n",
    "g_padding,d_padding=config_dict['training']['g_padding'],config_dict['training']['d_padding']\n",
    "flip_prob=config_dict['training']['flip_prob']\n",
    "\n",
    "image_size=config_dict['data']['image_size']\n",
    "checkpoint_size=config_dict['data']['checkpoint_size']\n",
    "num_imgs=config_dict['data']['num_imgs']\n",
    "ip_fname=config_dict['data']['ip_fname']\n",
    "op_loc=config_dict['data']['op_loc']\n",
    "\n",
    "# Overriding configs in .yaml file (different for jupyter notebook)\n",
    "ngpu=1\n",
    "batch_size=128\n",
    "spec_loss_flag=True\n",
    "checkpoint_size=50\n",
    "num_imgs=2000 # Number of images to use \n",
    "num_epochs=4\n",
    "lr=0.0002\n",
    "n_classes=6\n",
    "\n",
    "### Initialize random seed (different for Jpt notebook)\n",
    "manualSeed=21245\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print('Device:',device)\n",
    "\n",
    "#     #################################\n",
    "#     ####### Read data and precompute ######\n",
    "#     # ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "#     ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_4_four_universes_6k_cnn/data_x.npy'\n",
    "#     labels='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_4_four_universes_6k_cnn/data_y.npy'\n",
    "\n",
    "#     img=np.load(ip_fname)[:num_imgs].transpose(0,1,2,3)\n",
    "#     t_img=torch.from_numpy(img)\n",
    "#     print(img.shape,t_img.shape)\n",
    "\n",
    "#     dataset=TensorDataset(t_img)\n",
    "#     dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=1,drop_last=True)\n",
    "\n",
    "#################################\n",
    "###### Build Networks ###\n",
    "print(\"Building CNN\")\n",
    "# Create Discriminator\n",
    "netD = Discriminator(ngpu, nz,nc,ndf,n_classes,kernel_size,stride,g_padding).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "summary(netD,(1,128,128))\n",
    "# Handle multi-gpu if desired\n",
    "ngpu=torch.cuda.device_count()\n",
    "\n",
    "print(\"Number of GPUs used\",ngpu)\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Initialize BCELoss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(netD.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#     fixed_noise = torch.randn(batch_size, 1, 1, nz, device=device) #Latent vectors to view G progress\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "#     optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999),eps=1e-7)\n",
    "\n",
    "#################################    \n",
    "###### Set up directories ####### (different for Jpt notebook)\n",
    "#     run_suffix='_nb_test'\n",
    "#     ### Create prefix for foldername \n",
    "#     now=datetime.now()\n",
    "#     fldr_name=now.strftime('%Y%m%d_%H%M%S') ## time format\n",
    "#     # print(fldr_name)\n",
    "#     save_dir=op_loc+fldr_name+run_suffix\n",
    "\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir+'/models')\n",
    "#         os.makedirs(save_dir+'/images')\n",
    "\n",
    "# Fresh start    \n",
    "#     iters = 0; start_epoch=0\n",
    "#     best_chi1,best_chi2=1e10,1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_4_four_universes_6k_cnn/data_x.npy'\n",
    "# labels_file='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_4_four_universes_6k_cnn/data_y.npy'\n",
    "# ids_file='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_4_four_universes_6k_cnn/data_id.npy'\n",
    "\n",
    "# img=np.load(ip_fname)\n",
    "# labels=np.load(labels_file)\n",
    "# ids=np.load(ids_file)\n",
    "\n",
    "# t_img=torch.from_numpy(img)\n",
    "# print(img.shape,t_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data from dataframe\n",
    "data_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_4_four_universes_6k_cnn/'\n",
    "df_data=pd.read_pickle(data_dir+'/df_data.pkle')\n",
    "df_data=df_data.sample(frac=1,random_state=20).reset_index(drop=True)\n",
    "train_size,val_size,test_size=0.7,0.1,0.1\n",
    "data_size=df_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30513</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27797</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label\n",
       "0  30513      4\n",
       "1  27797      4\n",
       "2   4772      0\n",
       "3   3405      0\n",
       "4  13219      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[['ID','label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25804 29491 33177\n"
     ]
    }
   ],
   "source": [
    "idx1,idx2,idx3=int(train_size*data_size),int((train_size+val_size)*data_size),int((train_size+val_size+test_size)*data_size)\n",
    "print(idx1,idx2,idx3)\n",
    "\n",
    "df_temp=df_data.loc[np.arange(0,idx1)]\n",
    "dataset=TensorDataset(torch.Tensor(np.stack(df_temp.img.values)),torch.Tensor(df_temp.label.values))\n",
    "train_loader=DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=1,drop_last=True)\n",
    "\n",
    "df_temp=df_data.loc[np.arange(idx1,idx2)]\n",
    "dataset=TensorDataset(torch.Tensor(np.stack(df_temp.img.values)),torch.Tensor(df_temp.label.values))\n",
    "val_loader=DataLoader(dataset,batch_size=16,shuffle=True,num_workers=1,drop_last=True)\n",
    "\n",
    "df_temp=df_data.loc[np.arange(idx2,idx3)]\n",
    "dataset=TensorDataset(torch.Tensor(np.stack(df_temp.img.values)),torch.Tensor(df_temp.label.values))\n",
    "test_loader=DataLoader(dataset,batch_size=8,shuffle=True,num_workers=1,drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model\n",
    "def f_test(data_loader,netD):\n",
    "    netD.eval()\n",
    "    correct,total=0,0\n",
    "    with torch.no_grad():\n",
    "        for count,data in enumerate(data_loader):\n",
    "            images,labels=data[0].to(device),data[1].to(device)\n",
    "            outputs=netD(images)\n",
    "            _,predictions=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predictions==labels).sum().item()\n",
    "\n",
    "    accuracy=(correct/total)*100\n",
    "#     print(\"Accuracy %\",accuracy)\n",
    "#     print(correct,total)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n"
     ]
    }
   ],
   "source": [
    "accuracy=[]\n",
    "for epoch in range(0,4):\n",
    "    running_loss=0.0\n",
    "    print(\"Epoch\",epoch)\n",
    "    for i, data in enumerate(train_loader):\n",
    "    #     print(images.shape,labels.shape)\n",
    "        images,labels=data[0].to(device),data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    #     netD.train();  ### Need to add these after inference and before training\n",
    "        netD.zero_grad()\n",
    "        labels=labels.long()\n",
    "        output = netD(images)\n",
    "\n",
    "        loss= criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "        if i%10==0: accuracy.append(f_test(val_loader,netD))\n",
    "        netD.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302e467da9244217bd32fc4970dca174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab3a50d670>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.1086956521739"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test model\n",
    "f_test(test_loader,netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
