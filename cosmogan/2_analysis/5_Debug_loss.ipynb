{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the issue with losses not matching in 2 codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import sys\n",
    "import      os\n",
    "import glob\n",
    "import pickle \n",
    "\n",
    "from matplotlib.colors import LogNorm, PowerNorm, Normalize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/cosmogan_pytorch/cosmogan/1_main_code/')\n",
    "import spec_loss as spc\n",
    "import post_analysis_pandas as post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4.) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1, 128, 128), torch.Size([1000, 1, 128, 128]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "img=np.load(ip_fname,mmap_mode='r')[:1000].transpose(0,1,2,3)\n",
    "t_img=torch.from_numpy(img)\n",
    "img.shape,t_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_pytorch_analyze-results.ipynb\n",
      "2_analyze_pytorch_without_precompute-.ipynb\n",
      "3_pytorch_compare_data_keras_pytorch.ipynb\n",
      "5_Debug_loss.ipynb\n",
      "6_test_spectra_pytorch.ipynb\n",
      "6_test_spectra_tensorflow.ipynb\n",
      "lbann_3c_find_best_epochs.ipynb\n",
      "lbann_4b_lbann_analyze_chisqrs.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to use fftpack for pytorch : https://github.com/locuslab/pytorch_fft/issues/9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean,sdev=f_torch_image_spectrum(f_invtransform(fake),1,r.to(device),ind.to(device))\n",
    "r,ind=spc.f_get_rad(img)\n",
    "mean,sdev=spc.f_torch_image_spectrum(t_img,1,r,ind)\n",
    "\n",
    "dict_sample=post.f_compute_hist_spect(img[:,0,:,:],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sample['spec_val'].shape,mean[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test mean \n",
    "ans1=mean[0,:]\n",
    "ans2=dict_sample['spec_val']\n",
    "\n",
    "for i in range(len(ans2)):\n",
    "    a,b=ans1[i].item(),ans2[i]\n",
    "    if ((a-b)>1e-2):\n",
    "        print(i,a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test stderr\n",
    "ans1=sdev[0,:]\n",
    "ans2=dict_sample['spec_err']\n",
    "\n",
    "for i in range(len(ans2)):\n",
    "    a,b=ans1[i].item(),ans2[i]\n",
    "    if ((a-b)>1e-2):\n",
    "        print(i,a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: \n",
    "Oct 22, 2020 (Bday!) \\\n",
    "The spectra match. \\\n",
    "The stderr matches less, but it's still in the ballpark. deviation probably due to rounding off errors.\n",
    "\n",
    "Oct 29, 2022. \\\n",
    "Modified pytorch radial profile code to remove bincount to help with backprop. code taken from tensorflow. \\\n",
    "Results agree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "img=np.load(ip_fname,mmap_mode='r')[-3000:].transpose(0,1,2,3)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "f1='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/exagan1/run5_fixed_cosmology/models/gen_imgs.npy'\n",
    "f1='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20201110_072035_full_loss_b64_with-invtransform/images/gen_img_epoch-14_step-44862.npy'\n",
    "img_1=np.expand_dims(np.load(f1)[-3000:],axis=1)\n",
    "\n",
    "# f2=''\n",
    "# img_2=np.expand_dims(np.load(f2)[:1000],axis=1)\n",
    "\n",
    "# ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "# img_1=np.load(ip_fname,mmap_mode='r')[5000:6000].transpose(0,1,2,3)\n",
    "\n",
    "print(img_1.shape)\n",
    "# img_1=f_invtransform(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss from pytorch training code\n",
    "r,ind=spc.f_get_rad(img)\n",
    "mean_spec_data,sdev_spec_data=spc.f_torch_image_spectrum(torch.from_numpy(img),1,r,ind)\n",
    "m1,s1=spc.f_torch_image_spectrum(torch.from_numpy(img_1),1,r,ind)\n",
    "print(spc.loss_spectrum(m1,mean_spec_data,s1,sdev_spec_data,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss from post_analysis code\n",
    "dict_val=post.f_compute_hist_spect(img[:,0,:,:],bins=50)\n",
    "dict_sample=post.f_compute_hist_spect(img_1[:,0,:,:],bins=50)\n",
    "post.f_compute_chisqr(dict_val,dict_sample)['chi_spec3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1,mean_spec_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "Nov 6, 2020.\n",
    "Added a new spectrum metric 'chi_spec3' that computes the loss.\n",
    "The results match very well !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_batch_histogram(img_arr,bins,norm,hist_range):\n",
    "    ''' Compute histogram statistics for a batch of images'''\n",
    "\n",
    "    ## Extracting the range. This is important to ensure that the different histograms are compared correctly\n",
    "    if hist_range==None : ulim,llim=np.max(img_arr),np.min(img_arr)\n",
    "    else: ulim,llim=hist_range[1],hist_range[0]\n",
    "#         print(ulim,llim)\n",
    "    ### array of histogram of each image\n",
    "    hist_arr=np.array([np.histogram(arr.flatten(), bins=bins, range=(llim,ulim), density=norm) for arr in img_arr]) ## range is important\n",
    "    hist=np.stack(hist_arr[:,0]) # First element is histogram array\n",
    "#         print(hist.shape)\n",
    "    bin_list=np.stack(hist_arr[:,1]) # Second element is bin value \n",
    "    ### Compute statistics over histograms of individual images\n",
    "    mean,err=np.mean(hist,axis=0),np.std(hist,axis=0)/np.sqrt(hist.shape[0])\n",
    "    bin_edges=bin_list[0]\n",
    "    centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    return mean,err,centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_compute_hist(data,bins):\n",
    "    hist_data=torch.histc(data,bins=bins)\n",
    "    hist_data=(hist_data*bins)/torch.sum(hist_data)\n",
    "    \n",
    "    return hist_data\n",
    "\n",
    "a=f_compute_hist(torch.from_numpy(img),10)\n",
    "b=f_batch_histogram(img,10,True,None)[0]\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a,linestyle='',marker='*')\n",
    "plt.plot(b,linestyle='',marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the loss functions on results and keras results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/exagan1/run5_fixed_cosmology/models/gen_imgs.npy'\n",
    "img_1=np.expand_dims(np.load(f1)[:500],axis=1)\n",
    "\n",
    "f2=''\n",
    "img_2=np.expand_dims(np.load(f2)[:1000],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,ind=spc.f_get_rad(img)\n",
    "mean_spec_data,sdev_spec_data=spc.f_torch_image_spectrum(t_img[:1000],1,r,ind)\n",
    "m1,s1=spc.f_torch_image_spectrum(torch.from_numpy(img_1),1,r,ind)\n",
    "m2,s2=spc.f_torch_image_spectrum(torch.from_numpy(img_2),1,r,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spc.loss_spectrum(m1,mean_spec_data,s1,sdev_spec_data,128))\n",
    "print(spc.loss_spectrum(m2,mean_spec_data,s2,sdev_spec_data,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data=torch.histc(t_img[:1000],bins=50)\n",
    "print(spc.loss_hist(t_img[5000:7000],hist_data))\n",
    "print(spc.loss_hist(torch.from_numpy(img_1),hist_data),spc.loss_hist(torch.from_numpy(img_2),hist_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Oct 20, 2020\n",
    "There are variations in the spectrum functions in pytorch and numpy.\n",
    "1. fftshit\n",
    "2. abs()**2\n",
    "\n",
    "However, the loss is computed with the same function for input and generated images, so it should not matter.\n",
    "The comparison with pytorch and keras data shows that keras is doing better (for some reason).\n",
    "\n",
    "Nov 6, 2020\n",
    "Modifications have been made to incorporate the variations mentioned above.\n",
    "But, keras still better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
