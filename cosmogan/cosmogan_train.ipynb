{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing cosmogan\n",
    "Aug 25, 2020\n",
    "\n",
    "Borrowing pieces of code from : \n",
    "\n",
    "- https://github.com/pytorch/tutorials/blob/11569e0db3599ac214b03e01956c2971b02c64ce/beginner_source/dcgan_faces_tutorial.py\n",
    "- https://github.com/exalearn/epiCorvid/tree/master/cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchsummary import summary\n",
    "# import torchvision.datasets as dset\n",
    "# import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_load_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1_main_code\u001b[0m/        cosmogan_train.ipynb         launch_train_pytorch.ipynb\n",
      "\u001b[01;34m2_analysis\u001b[0m/         generate_images.ipynb\n",
      "\u001b[01;32mbatch_analysis.sh\u001b[0m*  launch_compute_chisqr.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'GAN', 'data': {'ip_fname': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy', 'op_loc': '/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/'}, 'training': {'workers': 2, 'nc': 1, 'nz': 64, 'ngf': 64, 'ndf': 64, 'lr': 0.0002, 'beta1': 0.5, 'kernel_size': 5, 'stride': 2, 'g_padding': 2, 'd_padding': 2, 'image_size': 128, 'flip_prob': 0.01}}\n"
     ]
    }
   ],
   "source": [
    "config_file='1_main_code/config_128.yaml'\n",
    "config_dict=f_load_config(config_file)\n",
    "print(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workers=config_dict['training']['workers']\n",
    "nc=config_dict['training']['nc']\n",
    "nc,nz,ngf,ndf=config_dict['training']['nc'],config_dict['training']['nz'],config_dict['training']['ngf'],config_dict['training']['ndf']\n",
    "lr,beta1=config_dict['training']['lr'],config_dict['training']['beta1']\n",
    "kernel_size,stride=config_dict['training']['kernel_size'],config_dict['training']['stride']\n",
    "g_padding,d_padding=config_dict['training']['g_padding'],config_dict['training']['d_padding']\n",
    "image_size=config_dict['training']['image_size']\n",
    "ip_fname=config_dict['data']['ip_fname']\n",
    "op_loc=config_dict['data']['op_loc']\n",
    "\n",
    "ngpu=1\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  2120\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "manualSeed=2120\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set random seed for reproducibility\n",
    "# manualSeed = 999\n",
    "# #manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "# print(\"Random Seed: \", manualSeed)\n",
    "# random.seed(manualSeed)\n",
    "# torch.manual_seed(manualSeed)\n",
    "\n",
    "# # Root directory for dataset\n",
    "# dataroot = \"data/celeba\"\n",
    "# # Number of workers for dataloader\n",
    "# workers = 2\n",
    "# # Batch size during training\n",
    "# batch_size = 50\n",
    "# # Spatial size of training images. All images will be resized to this\n",
    "# #   size using a transformer.\n",
    "# image_size = 128\n",
    "\n",
    "# nc = 1 # Number of channels in the training images. For color images this is 3\n",
    "# nz = 64 # Size of z latent vector (i.e. size of generator input)\n",
    "# ngf = 64 # Size of feature maps in generator\n",
    "# ndf = 64 # Size of feature maps in discriminator\n",
    "# num_epochs = 40 # Number of training epochs\n",
    "\n",
    "# lr = 0.0002 # Learning rate for optimizers\n",
    "# beta1 = 0.5 # Beta1 hyperparam for Adam optimizers\n",
    "# ngpu = 1 # Number of GPUs available. Use 0 for CPU mode.\n",
    "\n",
    "# device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "# print(device)\n",
    "\n",
    "# kernel_size,stride=5,2\n",
    "# g_padding,d_padding=2,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1, 128, 128), torch.Size([10000, 1, 128, 128]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ip_fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/128_square/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "img=np.load(ip_fname)[:10000].transpose(0,1,2,3)\n",
    "t_img=torch.from_numpy(img)\n",
    "img.shape,t_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, torch.Size([1, 128, 128]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=TensorDataset(torch.Tensor(img))\n",
    "dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=1,drop_last=True)\n",
    "\n",
    "len(dataset),(dataset[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1, 128, 128), torch.Size([10000, 1, 128, 128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape,t_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "            nn.Linear(nz,nc*ngf*8*8*8),# 32768\n",
    "            nn.BatchNorm2d(nc),\n",
    "            nn.ReLU(True),\n",
    "            View(shape=[-1,ngf*8,8,8]),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, kernel_size, stride, g_padding, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, kernel_size, stride, g_padding, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, kernel_size, stride, g_padding, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, kernel_size, stride,g_padding, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# Discriminator Code\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            # nn.Conv2d(in_channels, out_channels, kernel_size,stride,padding,output_padding,groups,bias, Dilation,padding_mode)\n",
    "            nn.Conv2d(nc, ndf,kernel_size, stride, d_padding,  bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size, stride, d_padding, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size, stride, d_padding, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size, stride, d_padding, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nc*ndf*8*8*8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32768, bias=True)\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): View()\n",
      "    (4): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
      "    (14): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=32768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)\n",
    "\n",
    "\n",
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "    \n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1          [-1, 1, 1, 32768]       2,129,920\n",
      "       BatchNorm2d-2          [-1, 1, 1, 32768]               2\n",
      "              ReLU-3          [-1, 1, 1, 32768]               0\n",
      "              View-4            [-1, 512, 8, 8]               0\n",
      "   ConvTranspose2d-5          [-1, 256, 16, 16]       3,276,800\n",
      "       BatchNorm2d-6          [-1, 256, 16, 16]             512\n",
      "              ReLU-7          [-1, 256, 16, 16]               0\n",
      "   ConvTranspose2d-8          [-1, 128, 32, 32]         819,200\n",
      "       BatchNorm2d-9          [-1, 128, 32, 32]             256\n",
      "             ReLU-10          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-11           [-1, 64, 64, 64]         204,800\n",
      "      BatchNorm2d-12           [-1, 64, 64, 64]             128\n",
      "             ReLU-13           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-14          [-1, 1, 128, 128]           1,600\n",
      "             Tanh-15          [-1, 1, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 6,433,218\n",
      "Trainable params: 6,433,218\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 11.75\n",
      "Params size (MB): 24.54\n",
      "Estimated Total Size (MB): 36.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(netG,(1,1,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,600\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "         LeakyReLU-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]         204,800\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "         LeakyReLU-6          [-1, 128, 32, 32]               0\n",
      "            Conv2d-7          [-1, 256, 16, 16]         819,200\n",
      "       BatchNorm2d-8          [-1, 256, 16, 16]             512\n",
      "         LeakyReLU-9          [-1, 256, 16, 16]               0\n",
      "           Conv2d-10            [-1, 512, 8, 8]       3,276,800\n",
      "      BatchNorm2d-11            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-12            [-1, 512, 8, 8]               0\n",
      "          Flatten-13                [-1, 32768]               0\n",
      "           Linear-14                    [-1, 1]          32,769\n",
      "================================================================\n",
      "Total params: 4,337,089\n",
      "Trainable params: 4,337,089\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 11.50\n",
      "Params size (MB): 16.54\n",
      "Estimated Total Size (MB): 28.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(netD,(1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f_size(ip):\n",
    "#     p=2;s=2\n",
    "# #     return (ip + 2 * 0 - 1 * (p-1) -1 )/ s + 1\n",
    "\n",
    "#     return (ip-1)*s - 2 * p + 1 *(5-1)+ 1 + 1\n",
    "\n",
    "# f_size(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(batch_size, 1, 1, nz, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spectrum code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_radial_profile(data, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image '''\n",
    "    y, x = np.indices((data.shape)) # Get a grid of x and y values\n",
    "    \n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "        \n",
    "    # get radial values of every pair of points\n",
    "    r = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r = r.astype(np.int)\n",
    "    \n",
    "    # Compute histogram of r values\n",
    "    tbin = np.bincount(r.ravel(), data.ravel())\n",
    "    nr = np.bincount(r.ravel()) \n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile\n",
    "\n",
    "def f_compute_spectrum(arr):\n",
    "    y1=np.fft.fft2(arr)\n",
    "    y2=abs(y1)\n",
    "    z1=f_radial_profile(y2)\n",
    "    return(z1)\n",
    "    \n",
    "def f_compute_batch_spectrum(arr):\n",
    "    batch_pk=np.array([f_compute_spectrum(i) for i in arr])\n",
    "    return batch_pk\n",
    "\n",
    "\n",
    "### Code ###\n",
    "def f_image_spectrum(x,num_channels):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    print(x.shape)\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    sdev=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "#         print(i,arr.shape)\n",
    "        batch_pk=f_compute_batch_spectrum(arr)\n",
    "#         print(batch_pk)\n",
    "        mean[i]=np.mean(batch_pk,axis=0)\n",
    "        sdev[i]=np.std(batch_pk,axis=0)\n",
    "    mean=np.array(mean)\n",
    "    sdev=np.array(sdev)\n",
    "    return mean,sdev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_torch_radial_profile(img, center=(None,None)):\n",
    "    ''' Module to compute radial profile of a 2D image '''\n",
    "    \n",
    "    y,x=torch.meshgrid(torch.arange(0,img.shape[0]),torch.arange(0,img.shape[1])) # Get a grid of x and y values\n",
    "    if center[0]==None and center[1]==None:\n",
    "        center = torch.Tensor([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0]) # compute centers\n",
    "\n",
    "    # get radial values of every pair of points\n",
    "    r = torch.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "    r= r.int()\n",
    "\n",
    "#     print(r.shape,img.shape)\n",
    "    # Compute histogram of r values\n",
    "    tbin=torch.bincount(torch.reshape(r,(-1,)),weights=torch.reshape(img,(-1,)).type(torch.DoubleTensor))\n",
    "    nr = torch.bincount(torch.reshape(r,(-1,)))\n",
    "    radialprofile = tbin / nr\n",
    "    \n",
    "    return radialprofile\n",
    "\n",
    "\n",
    "def f_torch_compute_spectrum(arr):\n",
    "    y1=torch.rfft(arr,signal_ndim=2,onesided=False)\n",
    "    ## Absolute value of each complex number (last index is real/imag part)\n",
    "    y2=torch.sqrt(y1[:,:,0]**2+y1[:,:,1]**2)\n",
    "    z1=f_torch_radial_profile(y2)\n",
    "    return(z1)\n",
    "\n",
    "\n",
    "def f_torch_compute_batch_spectrum(arr):\n",
    "    \n",
    "    batch_pk=torch.stack([f_torch_compute_spectrum(i) for i in arr])\n",
    "    \n",
    "    return batch_pk\n",
    "\n",
    "\n",
    "### Code ###\n",
    "def f_torch_image_spectrum(x,num_channels):\n",
    "    '''\n",
    "    Data has to be in the form (batch,channel,x,y)\n",
    "    '''\n",
    "    mean=[[] for i in range(num_channels)]    \n",
    "    sdev=[[] for i in range(num_channels)]    \n",
    "\n",
    "    for i in range(num_channels):\n",
    "        arr=x[:,i,:,:]\n",
    "#         print(i,arr.shape)\n",
    "        batch_pk=f_torch_compute_batch_spectrum(arr)\n",
    "#         print(batch_pk.shape)\n",
    "        mean[i]=torch.mean(batch_pk,axis=0)\n",
    "        sdev[i]=torch.std(batch_pk,axis=0)\n",
    "        \n",
    "    mean=torch.stack(mean)\n",
    "    sdev=torch.stack(sdev)\n",
    "    return mean,sdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stored mean and std of spectrum for full input data once\n",
    "mean_spec_data,sdev_spec_data=f_torch_image_spectrum(t_img[:1000],1)\n",
    "hist_data=torch.histc(t_img[:1000],bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_cpu = data[0].to(device)\n",
    "# f_torch_radial_profile(real_cpu[0,0,:,:])\n",
    "# f_torch_compute_spectrum(real_cpu[0,0,:,:])\n",
    "# f_torch_compute_batch_spectrum(real_cpu[:,0,:,:]).shape\n",
    "# mean,sdev=f_torch_image_spectrum(real_cpu,1)\n",
    "\n",
    "# mean2,sdev2=f_image_spectrum(real_cpu.cpu().numpy(),1)\n",
    "# for i in range(len(mean.numpy())):\n",
    "#     print (abs(mean.numpy()[i]-mean2[i]) <=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_spectrum(spec_mean,spec_mean_ref,spec_std,spec_std_ref,image_size):\n",
    "    ''' Loss function for the spectrum : mean + variance '''\n",
    "    \n",
    "    # Log ( sum( batch value - expect value) ^ 2 ))\n",
    "    \n",
    "    idx=int(image_size/2) ### For the spectrum, use only N/2 indices for loss calc.\n",
    "    \n",
    "    spec_mean=torch.log(torch.mean(torch.pow(spec_mean[:,idx]-spec_mean_ref[:,idx],2)))\n",
    "    spec_sdev=torch.log(torch.mean(torch.pow(spec_std[:,idx]-spec_std_ref[:,idx],2)))\n",
    "    \n",
    "    lambda1=1.0;lambda2=1.0;\n",
    "    ans=lambda1*spec_mean+lambda2*spec_sdev\n",
    "    return ans.item()\n",
    "\n",
    "\n",
    "def loss_hist(data,hist_data):\n",
    "    \n",
    "    hist_sample=torch.histc(data,bins=50)\n",
    "    ## A kind of normalization of histograms: divide by total sum\n",
    "    hist_sample=hist_sample/torch.sum(hist_sample)\n",
    "    hist_data=hist_data/torch.sum(hist_data)\n",
    "\n",
    "    return torch.log(torch.mean(torch.pow(hist_sample-hist_data,2))).item()\n",
    "\n",
    "# loss_spectrum(mean,mean_spec_data,sdev,sdev_spec_data,128)\n",
    "# loss_hist(fake,hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create prefix for foldername \n",
    "now=datetime.now()\n",
    "fldr_name=now.strftime('%Y%m%d_%H%M%S') ## time format\n",
    "# print(fldr_name)\n",
    "save_dir=op_loc+fldr_name\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir+'/models')\n",
    "    os.makedirs(save_dir+'/images')\n",
    "    \n",
    "    \n",
    "keys=['Dreal','Dfake','Dfull','G','spec_chi','hist_chi']\n",
    "size=len(dataset)/batch_size * num_epochs\n",
    "metric_dict=dict(zip(keys,[np.empty((int(np.ceil(size))))*np.nan for i in range(len(keys))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "\n",
    "iters = 0\n",
    "best_chi1,best_chi2=1e10,1e10\n",
    "flip_prob=0.01\n",
    "\n",
    "\n",
    "t0=time.time()\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for count, data in enumerate(dataloader, 0):\n",
    "        tme1=time.time()\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        real_label = torch.full((b_size,), 1, device=device)\n",
    "        fake_label = torch.full((b_size,), 0, device=device)\n",
    "        \n",
    "        ## Flip labels with probability flip_prob\n",
    "#         for count,i in enumerate(real_label):\n",
    "#             if torch.rand(1)[0] < flip_prob:\n",
    "#                 real_label[count]=0\n",
    "#                 fake_label[count]=1\n",
    "        \n",
    "        for idx in np.random.choice(np.arange(b_size),size=int(np.ceil(b_size*flip_prob))):\n",
    "            real_label[idx]=0;\n",
    "            fake_label[idx]=1;\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, real_label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, 1, 1, nz, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        real_label = torch.full((b_size,), 1, device=device) ## No flipping for Generator labels\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, real_label)\n",
    "        # Add spectral loss\n",
    "        mean,sdev=f_torch_image_spectrum(fake,1)  ### compute spectral mean,std for fake images for batch\n",
    "        spec_loss=loss_spectrum(mean,mean_spec_data,sdev,sdev_spec_data,image_size)\n",
    "        \n",
    "        # Combine losses\n",
    "        errG+=spec_loss\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        tme2=time.time()\n",
    "        # Output training stats\n",
    "        if count % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, count, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)),\n",
    "            print(\"Time taken for step %s : %s\"%(iters, tme2-tme1))\n",
    "\n",
    "        \n",
    "        # Histogram pixel intensity metric\n",
    "        hist_metric=loss_hist(fake,hist_data.to(device))\n",
    "        \n",
    "        # Save metrics\n",
    "        for key,val in zip(['Dreal','Dfake','Dfull','G','spec_chi','hist_chi'],[errD_real.item(),errD_fake.item(),errD.item(),errG.item(),spec_loss,hist_metric]):\n",
    "            metric_dict[key][iters]=val\n",
    "        \n",
    "        ### Checkpoint the best model\n",
    "        checkpoint=True\n",
    "        if checkpoint and epoch > 3:\n",
    "            # Choose best models by metric\n",
    "            if hist_metric< best_chi1:\n",
    "                torch.save({'epoch':epoch,'iters':iters,'G_state':netG.state_dict(),'D_state':netD.state_dict(),\n",
    "               'optimizerG_state_dict':optimizerG.state_dict(),'optimizerD_state_dict':optimizerD.state_dict()}\n",
    "              , save_dir+'/models/checkpoint_best_hist.tar')\n",
    "                best_chi1=hist_metric\n",
    "            \n",
    "            if spec_loss< best_chi2:\n",
    "                torch.save({'epoch':epoch,'iters':iters,'G_state':netG.state_dict(),'D_state':netD.state_dict(),\n",
    "               'optimizerG_state_dict':optimizerG.state_dict(),'optimizerD_state_dict':optimizerD.state_dict()}\n",
    "              , save_dir+'/models/checkpoint_best_spec.tar')\n",
    "                best_chi2=spec_loss\n",
    "        \n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 50 == 0) or ((epoch == num_epochs-1) and (count == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "                img_arr=np.array(fake[:,0,:,:])\n",
    "                fname='gen_img_epoch-%s_step-%s'%(epoch,iters)\n",
    "                np.save(save_dir+'/images/'+fname,img_arr)\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "tf=time.time()\n",
    "print(\"Total time\",tf-t0)\n",
    "\n",
    "### Save Losses to files\n",
    "with open (save_dir+'/metrics.pickle', 'wb') as f:\n",
    "    pickle.dump(metric_dict,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to script cosmogan_test.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_dict.keys())\n",
    "metric_dict['spec_chi']\n",
    "# metric_dict['hist_chi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the loss functions on results and keras results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/exagan1/run5_fixed_cosmology/models/gen_imgs.npy'\n",
    "img_1=np.expand_dims(np.load(f1)[:500],axis=1)\n",
    "\n",
    "f2='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20201015_072548/images/gen_img_epoch-2_step-3150.npy'\n",
    "f2='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20201015_072548/images/best_-hist_gen_img_epoch-4_step-7002.npy'\n",
    "# f2='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_from_other_code/pytorch/results/128sq/20201015_072548/images/best_-spec_gen_img_epoch-5_step-8012.npy'\n",
    "img_2=np.expand_dims(np.load(f2)[:500],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'hist_data' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-4b3f74ef42f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-4b5102be7a2b>\u001b[0m in \u001b[0;36mloss_hist\u001b[0;34m(data, hist_da)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m## A kind of normalization of histograms: divide by total sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mhist_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist_sample\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mhist_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_sample\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'hist_data' referenced before assignment"
     ]
    }
   ],
   "source": [
    "loss_hist(torch.from_numpy(img_1),hist_data),loss_hist(torch.from_numpy(img_2),hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07428026933517742, 0.096091710887477)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean1,sdev1=f_torch_image_spectrum(torch.from_numpy(img_1),1)  ### compute spectral mean,std for fake images for batch\n",
    "mean2,sdev2=f_torch_image_spectrum(torch.from_numpy(img_2),1)  ### compute spectral mean,std for fake images for batch\n",
    "loss_spectrum(mean1,mean_spec_data,sdev1,sdev_spec_data,128),loss_spectrum(mean2,mean_spec_data,sdev2,sdev_spec_data,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3180e-02, 1.4124e-01, 1.5408e-01, 1.1212e-01, 7.6473e-02, 7.2860e-02,\n",
       "        7.0680e-02, 5.5724e-02, 4.0763e-02, 3.2159e-02, 2.7141e-02, 2.2514e-02,\n",
       "        1.8430e-02, 1.5644e-02, 1.3373e-02, 1.1398e-02, 9.9565e-03, 8.6518e-03,\n",
       "        7.6531e-03, 6.7343e-03, 5.9770e-03, 5.3076e-03, 4.7750e-03, 4.2794e-03,\n",
       "        3.8366e-03, 3.4656e-03, 3.1497e-03, 2.8642e-03, 2.6256e-03, 2.3782e-03,\n",
       "        2.1692e-03, 2.0018e-03, 1.8183e-03, 1.6394e-03, 1.5142e-03, 1.3965e-03,\n",
       "        1.2879e-03, 1.1665e-03, 1.0861e-03, 9.8065e-04, 8.9984e-04, 8.2343e-04,\n",
       "        7.4542e-04, 6.7346e-04, 6.0468e-04, 5.4163e-04, 4.6198e-04, 3.8287e-04,\n",
       "        2.7393e-04, 9.9731e-05])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_data/torch.sum(hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07428026933517742"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_hist(hist_data,hist_data)\n",
    "loss_spectrum(mean1,mean_spec_data,sdev1,sdev_spec_data,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.0747e+05, 2.3141e+06, 2.5244e+06, 1.8370e+06, 1.2529e+06, 1.1937e+06,\n",
       "        1.1580e+06, 9.1298e+05, 6.6787e+05, 5.2690e+05, 4.4467e+05, 3.6887e+05,\n",
       "        3.0196e+05, 2.5632e+05, 2.1910e+05, 1.8674e+05, 1.6313e+05, 1.4175e+05,\n",
       "        1.2539e+05, 1.1033e+05, 9.7927e+04, 8.6959e+04, 7.8233e+04, 7.0113e+04,\n",
       "        6.2859e+04, 5.6780e+04, 5.1605e+04, 4.6927e+04, 4.3018e+04, 3.8964e+04,\n",
       "        3.5540e+04, 3.2798e+04, 2.9791e+04, 2.6860e+04, 2.4808e+04, 2.2881e+04,\n",
       "        2.1101e+04, 1.9112e+04, 1.7794e+04, 1.6067e+04, 1.4743e+04, 1.3491e+04,\n",
       "        1.2213e+04, 1.1034e+04, 9.9070e+03, 8.8740e+03, 7.5690e+03, 6.2730e+03,\n",
       "        4.4880e+03, 1.6340e+03])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_spectrum(spec_mean,spec_mean_ref,spec_std,spec_std_ref,image_size):\n",
    "    ''' Loss function for the spectrum : mean + variance '''\n",
    "    \n",
    "    # Log ( sum( batch value - expect value) ^ 2 ))\n",
    "    \n",
    "    idx=int(image_size/2) ### For the spectrum, use only N/2 indices for loss calc.\n",
    "    \n",
    "    spec_mean=torch.mean(torch.pow(spec_mean[:,idx]-spec_mean_ref[:,idx],2))\n",
    "    spec_sdev=torch.mean(torch.pow(spec_std[:,idx]-spec_std_ref[:,idx],2))\n",
    "    \n",
    "    \n",
    "    lambda1=1.0;lambda2=1.0;\n",
    "    ans=lambda1*spec_mean+lambda2*spec_sdev\n",
    "    return ans.item()\n",
    "\n",
    "\n",
    "def loss_hist(data,hist_da):\n",
    "    \n",
    "    hist_sample=torch.histc(data,bins=50)\n",
    "    ## A kind of normalization of histograms: divide by total sum\n",
    "    hist_sample=hist_sample/torch.sum(hist_sample)\n",
    "    hist_data=hist_data/torch.sum(hist_data)\n",
    "\n",
    "    return torch.log(torch.mean(torch.pow(hist_sample-hist_data,2))).item()\n",
    "#     return torch.mean(torch.pow(hist_sample-hist_data,2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
